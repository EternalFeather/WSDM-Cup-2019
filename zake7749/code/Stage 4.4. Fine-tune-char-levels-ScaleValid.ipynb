{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import pandas as pd\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from iwillwin.trainer.supervised_trainer import KerasModelTrainer\n",
    "from iwillwin.data_utils.data_helpers import CharDataTransformer, DataTransformer, DataLoader\n",
    "from iwillwin.model.sim_zoos import *\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, MaxPooling1D, CuDNNLSTM, Embedding, Add, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from iwillwin.config import dataset_config, model_config\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.legacy.layers import Highway\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 5000\n",
    "EMBEDDING_DIM = 150\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "OUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataHelper] Apply normalization on value-type columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Kaggle\\WSDM-zh\\code\\iwillwin\\data_utils\\data_helpers.py:132: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_df = pd.concat((train_df, test_df))\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing preprocessing...\n",
      "Transforming words to indices...\n",
      "Shape of data tensor: (320552, 50) (320552, 50)\n",
      "Shape of label tensor: (320552,)\n",
      "Preprocessed.\n",
      "Number of unique words 5196\n"
     ]
    }
   ],
   "source": [
    "data_transformer = CharDataTransformer(max_num_words=NB_WORDS, max_sequence_length=MAX_SEQUENCE_LENGTH, char_level=False,\n",
    "                                   normalization=True, features_processed=True)\n",
    "trains, tests, labels = data_transformer.prepare_data(dual=False)\n",
    "print(\"Number of unique words\", len(data_transformer.tokenizer.index_docs))\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "['.gitkeep', 'fasttext-50-win3.vec', 'zh-wordvec-50-cbow-windowsize50.vec', 'zh-wordvec-50-skipgram-windowsize7.vec']\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings\")\n",
    "print(os.listdir(\"../data/wordvec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "skip_gram_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-skipgram-windowsize7.vec')\n",
    "cbow_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-cbow-windowsize50.vec')\n",
    "fasttext_embeddings = data_loader.load_embedding('../data/wordvec/fasttext-50-win3.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(embeddings_index, nb_words=NB_WORDS, word_index=data_transformer.tokenizer.word_index):\n",
    "    #nb_words = min(nb_words, len(embeddings_index))\n",
    "    embedding_matrix = np.random.rand(nb_words, 50)\n",
    "    embedding_matrix = np.zeros((nb_words, 50))\n",
    "    \n",
    "    word_index = data_transformer.tokenizer.word_index\n",
    "    null_words = open('null-word.txt', 'w', encoding='utf-8')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words:\n",
    "            null_words.write(word + '\\n')\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            null_words.write(word + '\\n')\n",
    "    print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n"
     ]
    }
   ],
   "source": [
    "cbow_matrix = build_embedding_matrix(cbow_embeddings)\n",
    "skipgram_matrix = build_embedding_matrix(skip_gram_embeddings)\n",
    "fasttext_matrix = build_embedding_matrix(fasttext_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings = np.concatenate((cbow_matrix, skipgram_matrix, fasttext_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings[0] = np.array([0] * 150) # zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tricky features\n",
    "\n",
    "## Rumor words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/dataset/train.csv')\n",
    "test_df = pd.read_csv('../data/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "rumor_words = ['辟谣', '谣言', '勿传', '假的']\n",
    "\n",
    "def is_rumor(text):\n",
    "    if type(text) != str:\n",
    "        print(text, type(text))\n",
    "        return 0\n",
    "    for rumor_word in rumor_words:\n",
    "        if rumor_word in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def has_split_symbol(text):\n",
    "    if type(text) != str:\n",
    "        return 0\n",
    "    if '|' in text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['has_|'] = df['title2_zh'].apply(has_split_symbol)\n",
    "    df['has_rumor_words'] = df['title2_zh'].apply(is_rumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_has_rumor = train_df.has_rumor_words.values\n",
    "test_has_rumor = test_df.has_rumor_words.values\n",
    "\n",
    "trick_trains_features = np.concatenate((trains[2], train_has_rumor.reshape((-1, 1))), axis=1)\n",
    "trick_tests_features = np.concatenate((tests[2], test_has_rumor.reshape((-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _build_exact_match_sequences(sent_1, sent_2):\n",
    "    sent_1_char_set = set(sent_1)\n",
    "    sent_2_char_set = set(sent_2)\n",
    "    intersection = sent_1_char_set & sent_2_char_set\n",
    "    \n",
    "    sent_1_em = np.zeros_like(sent_1)\n",
    "    sent_2_em = np.zeros_like(sent_2)\n",
    "\n",
    "    for i in range(len(sent_1)):\n",
    "        if sent_1[i] == 0:\n",
    "            continue\n",
    "        if sent_1[i] in intersection:\n",
    "            sent_1_em[i] = 1\n",
    "    \n",
    "    for i in range(len(sent_2)):\n",
    "        if sent_2[i] == 0:\n",
    "            continue        \n",
    "        if sent_2[i] in intersection:\n",
    "            sent_2_em[i] = 1\n",
    "    \n",
    "    return sent_1_em, sent_2_em\n",
    "\n",
    "def build_exact_match_sequences(sents_1, sents_2):\n",
    "    sents_1_em, sents_2_em = [], []\n",
    "    for sent_1, sent_2 in zip(sents_1, sents_2):\n",
    "        sent_1_em, sent_2_em = _build_exact_match_sequences(sent_1, sent_2)\n",
    "        sents_1_em.append(sent_1_em)\n",
    "        sents_2_em.append(sent_2_em)\n",
    "    return np.array(sents_1_em), np.array(sents_2_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_1_ems, trains_2_ems = build_exact_match_sequences(trains[0], trains[1])\n",
    "tests_1_ems, tests_2_ems = build_exact_match_sequences(tests[0], tests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train em (320552, 50) (320552, 50)\n",
      "Shape of test em (80126, 50) (80126, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train em\", trains_1_ems.shape, trains_2_ems.shape)\n",
    "print(\"Shape of test em\", tests_1_ems.shape, tests_2_ems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_train_features = (trains_1_ems, trains_2_ems)\n",
    "em_test_features = (tests_1_ems, tests_2_ems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class_weight.compute_class_weight('balanced', [0, 1, 2], labels.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Ensemble Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_inputs = pd.read_csv(\"../data/ensemble/second_level/FirstLevelPseudoLabels.csv\")\n",
    "pseudo_labels = ensemble_inputs[['unrelated', 'agreed', 'disagreed']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trick or Treat!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tricky = True\n",
    "\n",
    "if use_tricky:\n",
    "    trains = (trains[0], trains[1], trick_trains_features)\n",
    "    tests = (tests[0], tests[1], trick_tests_features)\n",
    "else:\n",
    "    trains = (trains[0], trains[1], trains[2])\n",
    "    tests = (tests[0], tests[1], tests[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "        self.class_weight = [0.93, 1.21]\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, batch_size, get_model_func, tests, em_test_features, pseudo_labels, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        #features = features[:, -1]\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:], tests[0]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:], tests[1]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:], tests[2]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:], em_test_features[0]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:], em_test_features[1]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:], pseudo_labels])\n",
    "\n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=None)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_weighted_accuracy', patience=patience)\n",
    "        bst_model_path = self.model_stamp + str(fold_id) + '.h5'\n",
    "        model.load_weights(bst_model_path)\n",
    "        print(\"Load the model from \", bst_model_path)\n",
    "        fine_tune_model_path = self.model_stamp + \"-fine-tune-class_scaled-\" + str(fold_id) + '.h5'\n",
    "        \n",
    "        val_data = (val_x, val_y, weight_val) if weight_val is not None else (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(fine_tune_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         callbacks=[early_stopping, model_checkpoint],\n",
    "                         class_weight={0: 1/16, 1: 1/15, 2: 1/5})\n",
    "        bst_val_score = max(hist.history['val_weighted_accuracy'])\n",
    "        model.load_weights(fine_tune_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = tf.nn.leaky_relu(K.conv1d(u_vecs, self.W))\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = K.tanh(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "    \n",
    "def get_padding_mask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def unchanged_shape(input_shape):\n",
    "    \"Function for Lambda layer\"\n",
    "    return input_shape\n",
    "\n",
    "def substract(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: x[0] - x[1])([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def eldistance(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: K.sqrt(K.square(x[0] - x[1])))([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def submult(input_1, input_2):\n",
    "    \"Get multiplication and subtraction then concatenate results\"\n",
    "    mult = Multiply()([input_1, input_2])\n",
    "    add = Add()([input_1, input_2])\n",
    "    sub = substract(input_1, input_2)\n",
    "    distance = eldistance(input_1, input_2)\n",
    "    \n",
    "    dual = Concatenate()([input_1, input_2])\n",
    "    dual = Dense(32, activation='relu')(dual)\n",
    "    dual = Dropout(0.5)(dual)\n",
    "    dual = Dense(8, activation='relu')(dual)\n",
    "    \n",
    "    out_= Concatenate()([sub, mult, ])\n",
    "    return out_\n",
    "\n",
    "def apply_multiple(input_, layers):\n",
    "    \"Apply layers to input then concatenate result\"\n",
    "    if not len(layers) > 1:\n",
    "        raise ValueError('Layers list should contain more than 1 layer')\n",
    "    else:\n",
    "        agg_ = []\n",
    "        for layer in layers:\n",
    "            agg_.append(layer(input_))\n",
    "        out_ = Concatenate()(agg_)\n",
    "    return out_\n",
    "\n",
    "def time_distributed(input_, layers):\n",
    "    \"Apply a list of layers in TimeDistributed mode\"\n",
    "    out_ = []\n",
    "    node_ = input_\n",
    "    for layer_ in layers:\n",
    "        node_ = TimeDistributed(layer_)(node_)\n",
    "    out_ = node_\n",
    "    return out_\n",
    "\n",
    "def soft_attention_alignment(input_1, input_2):\n",
    "    \"Align text representation with neural soft attention\"\n",
    "    attention = Dot(axes=-1)([input_1, input_2])\n",
    "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
    "                     output_shape=unchanged_shape)(attention)\n",
    "    w_att_2 = Permute((2, 1))(Lambda(lambda x: softmax(x, axis=2),\n",
    "                             output_shape=unchanged_shape)(attention))\n",
    "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
    "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
    "    return in1_aligned, in2_aligned    \n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q1_c = Input(shape=(max_sequence_length, 11), name='first_sentences_char')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q2_c = Input(shape=(max_sequence_length, 11), name='second_sentences_char')\n",
    "    input_layer_3 = Input(shape=(len(model_config.META_FEATURES),), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words,\n",
    "                            embedding_dim,\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=True)\n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.5)(q1_embed)\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.5)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    \n",
    "    q1_encoded = th(q1_embed,)    \n",
    "    q2_encoded = th(q2_embed,)\n",
    "    \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
    "    q1_encoded = Concatenate()([q2_aligned, q1_encoded])\n",
    "    q2_encoded = Concatenate()([q1_aligned, q2_encoded])  \n",
    "    \n",
    "    cnn_init = Conv1D(32, 1, strides=1, padding='same', activation='relu')\n",
    "    q1_seq = cnn_init(q1_encoded)\n",
    "    q2_seq = cnn_init(q2_encoded)\n",
    "    \n",
    "    cnns = [Conv1D(1, 3, strides=1, padding='same', activation='relu') for i in range(10)]\n",
    "    \n",
    "    for idx, cnn in enumerate(cnns):\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        q1_encoded = Concatenate()([q1_seq, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_seq, q1_aligned, q2_encoded])            \n",
    "        q1_seq = cnn(q1_encoded)\n",
    "        q2_seq = cnn(q2_encoded)    \n",
    "    \n",
    "    \n",
    "    capsule_pooling = Capsule(num_capsule=8, dim_capsule=100, routings=3, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    \n",
    "    #q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])\n",
    "    #q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi, ])\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_darnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(1,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    #q1_embed = Dropout(0.2)(th(q1_embed,))\n",
    "    #q2_embed = Dropout(0.2)(th(q2_embed,))    \n",
    "    \n",
    "    rnns = [CuDNNGRU(42, return_sequences=True) for i in range(3)]\n",
    "    \n",
    "    q1_res = []\n",
    "    q2_res = []\n",
    "    \n",
    "    \n",
    "    for idx, rnn in enumerate(rnns):\n",
    "        q1_seq = rnn(q1_embed)\n",
    "        q1_seq = Dropout(0.1)(q1_seq)\n",
    "        q2_seq = rnn(q2_embed)\n",
    "        q2_seq = Dropout(0.1)(q2_seq)\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        \n",
    "        q1_res.append(q2_aligned)\n",
    "        q1_res.append(q1_seq)\n",
    "        \n",
    "        q2_res.append(q1_aligned)\n",
    "        q2_res.append(q2_seq)\n",
    "        \n",
    "        q1_embed = Concatenate()([q1_seq, q2_aligned, q1_embed])\n",
    "        q2_embed = Concatenate()([q2_seq, q1_aligned, q2_embed])            \n",
    "        \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    q1_res = Concatenate()(q1_res)\n",
    "    q2_res = Concatenate()(q2_res)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.1)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    label_weights = K.max(K.cast(weight_mask, 'float32'), axis=-1)\n",
    "    \n",
    "    true_label = K.argmax(y_true, axis=-1)\n",
    "    pred_label = K.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    res = K.cast(K.equal(true_label, pred_label), tf.float32) * label_weights / K.sum(label_weights)\n",
    "    res = K.sum(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_manager = ModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:200: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 50, 151)      0           embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 50, 151)      0           embedding_5[1][0]                \n",
      "                                                                 embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 50, 151)      0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 50, 151)      0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)          (None, 50, 42)       24570       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 50, 42)       0           cu_dnngru_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 50, 42)       0           cu_dnngru_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 50, 50)       0           dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 50, 50)       0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 50, 42)       0           permute_7[0][0]                  \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 50, 42)       0           lambda_15[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 50, 235)      0           dropout_15[0][0]                 \n",
      "                                                                 dot_21[0][0]                     \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 50, 235)      0           dropout_16[0][0]                 \n",
      "                                                                 dot_20[0][0]                     \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)          (None, 50, 42)       35154       concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 50, 42)       0           cu_dnngru_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 50, 42)       0           cu_dnngru_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 50, 50)       0           dropout_17[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (None, 50, 50)       0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 50, 42)       0           permute_8[0][0]                  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 50, 42)       0           lambda_17[0][0]                  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 50, 319)      0           dropout_17[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 50, 319)      0           dropout_18[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_9 (CuDNNGRU)          (None, 50, 42)       45738       concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 50, 42)       0           cu_dnngru_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 50, 42)       0           cu_dnngru_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 50, 50)       0           dropout_19[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 50, 50)       0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 50, 42)       0           permute_9[0][0]                  \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 50, 42)       0           lambda_19[0][0]                  \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 50, 252)      0           dot_21[0][0]                     \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 dropout_17[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 50, 252)      0           dot_20[0][0]                     \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 dropout_18[0][0]                 \n",
      "                                                                 dot_26[0][0]                     \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 252)          0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 252)          0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 252)          0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 252)          0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 504)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 504)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 504)          0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 504)          0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 2016)         0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 2016)         0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          516352      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            771         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0204 - acc: 0.8848 - weighted_accuracy: 0.8794 - val_loss: 0.3234 - val_acc: 0.8497 - val_weighted_accuracy: 0.8439\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0202 - acc: 0.8850 - weighted_accuracy: 0.8804 - val_loss: 0.3291 - val_acc: 0.8476 - val_weighted_accuracy: 0.8422\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0200 - acc: 0.8864 - weighted_accuracy: 0.8820 - val_loss: 0.3216 - val_acc: 0.8506 - val_weighted_accuracy: 0.8475\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0199 - acc: 0.8872 - weighted_accuracy: 0.8832 - val_loss: 0.3234 - val_acc: 0.8520 - val_weighted_accuracy: 0.8444\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.0198 - acc: 0.8878 - weighted_accuracy: 0.8839 - val_loss: 0.3334 - val_acc: 0.8389 - val_weighted_accuracy: 0.8386\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.0198 - acc: 0.8886 - weighted_accuracy: 0.8844 - val_loss: 0.3158 - val_acc: 0.8585 - val_weighted_accuracy: 0.8511\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0196 - acc: 0.8893 - weighted_accuracy: 0.8852 - val_loss: 0.3313 - val_acc: 0.8444 - val_weighted_accuracy: 0.8444\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0196 - acc: 0.8894 - weighted_accuracy: 0.8856 - val_loss: 0.3213 - val_acc: 0.8503 - val_weighted_accuracy: 0.8459\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0195 - acc: 0.8906 - weighted_accuracy: 0.8867 - val_loss: 0.3258 - val_acc: 0.8531 - val_weighted_accuracy: 0.8509\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0194 - acc: 0.8903 - weighted_accuracy: 0.8864 - val_loss: 0.3127 - val_acc: 0.8582 - val_weighted_accuracy: 0.8547\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0194 - acc: 0.8907 - weighted_accuracy: 0.8871 - val_loss: 0.3310 - val_acc: 0.8472 - val_weighted_accuracy: 0.8463\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0193 - acc: 0.8909 - weighted_accuracy: 0.8875 - val_loss: 0.3295 - val_acc: 0.8465 - val_weighted_accuracy: 0.8453\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0193 - acc: 0.8914 - weighted_accuracy: 0.8878 - val_loss: 0.3172 - val_acc: 0.8540 - val_weighted_accuracy: 0.8498\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0192 - acc: 0.8920 - weighted_accuracy: 0.8882 - val_loss: 0.3393 - val_acc: 0.8459 - val_weighted_accuracy: 0.8445\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0192 - acc: 0.8918 - weighted_accuracy: 0.8884 - val_loss: 0.3426 - val_acc: 0.8412 - val_weighted_accuracy: 0.8415\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0192 - acc: 0.8922 - weighted_accuracy: 0.8887 - val_loss: 0.3164 - val_acc: 0.8571 - val_weighted_accuracy: 0.8511\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0191 - acc: 0.8927 - weighted_accuracy: 0.8893 - val_loss: 0.3262 - val_acc: 0.8524 - val_weighted_accuracy: 0.8471\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0191 - acc: 0.8924 - weighted_accuracy: 0.8890 - val_loss: 0.3248 - val_acc: 0.8538 - val_weighted_accuracy: 0.8488\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0190 - acc: 0.8927 - weighted_accuracy: 0.8896 - val_loss: 0.3091 - val_acc: 0.8582 - val_weighted_accuracy: 0.8526\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0190 - acc: 0.8932 - weighted_accuracy: 0.8898 - val_loss: 0.3125 - val_acc: 0.8580 - val_weighted_accuracy: 0.8515\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 50, 151)      0           embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 50, 151)      0           embedding_7[1][0]                \n",
      "                                                                 embedding_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 50, 151)      0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 50, 151)      0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 50, 50)       0           dropout_22[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 50, 50)       0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 50, 42)       0           permute_10[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 50, 42)       0           lambda_22[0][0]                  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 50, 235)      0           dropout_22[0][0]                 \n",
      "                                                                 dot_30[0][0]                     \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 50, 235)      0           dropout_23[0][0]                 \n",
      "                                                                 dot_29[0][0]                     \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_11 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 50, 50)       0           dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 50, 50)       0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 50, 42)       0           permute_11[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 50, 42)       0           lambda_24[0][0]                  \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 50, 319)      0           dropout_24[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 50, 319)      0           dropout_25[0][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_12 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_44[0][0]             \n",
      "                                                                 concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 50, 50)       0           dropout_26[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 50, 50)       0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 50, 42)       0           permute_12[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 50, 42)       0           lambda_26[0][0]                  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 50, 252)      0           dot_30[0][0]                     \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dot_36[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 50, 252)      0           dot_29[0][0]                     \n",
      "                                                                 dropout_23[0][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 dropout_25[0][0]                 \n",
      "                                                                 dot_35[0][0]                     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 252)          0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 252)          0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 252)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 252)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 504)          0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 504)          0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 504)          0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 504)          0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 2016)         0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 2016)         0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          516352      dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            771         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0192 - acc: 0.8928 - weighted_accuracy: 0.8884 - val_loss: 0.2893 - val_acc: 0.8701 - val_weighted_accuracy: 0.8627\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8926 - weighted_accuracy: 0.8886 - val_loss: 0.2918 - val_acc: 0.8679 - val_weighted_accuracy: 0.8611\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8929 - weighted_accuracy: 0.8890 - val_loss: 0.3004 - val_acc: 0.8654 - val_weighted_accuracy: 0.8603\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 127s 351us/step - loss: 0.0192 - acc: 0.8927 - weighted_accuracy: 0.8888 - val_loss: 0.2967 - val_acc: 0.8647 - val_weighted_accuracy: 0.8591\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0191 - acc: 0.8929 - weighted_accuracy: 0.8892 - val_loss: 0.2947 - val_acc: 0.8692 - val_weighted_accuracy: 0.8625\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0192 - acc: 0.8923 - weighted_accuracy: 0.8884 - val_loss: 0.2985 - val_acc: 0.8638 - val_weighted_accuracy: 0.8598\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8924 - weighted_accuracy: 0.8888 - val_loss: 0.2925 - val_acc: 0.8660 - val_weighted_accuracy: 0.8601\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0191 - acc: 0.8921 - weighted_accuracy: 0.8887 - val_loss: 0.2939 - val_acc: 0.8682 - val_weighted_accuracy: 0.8623\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8919 - weighted_accuracy: 0.8885 - val_loss: 0.2931 - val_acc: 0.8676 - val_weighted_accuracy: 0.8609\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0191 - acc: 0.8925 - weighted_accuracy: 0.8893 - val_loss: 0.2847 - val_acc: 0.8732 - val_weighted_accuracy: 0.8620\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0191 - acc: 0.8926 - weighted_accuracy: 0.8892 - val_loss: 0.2943 - val_acc: 0.8666 - val_weighted_accuracy: 0.8603\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 50, 151)      0           embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 50, 151)      0           embedding_9[1][0]                \n",
      "                                                                 embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 50, 151)      0           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 50, 151)      0           concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_13 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 50, 50)       0           dropout_29[0][0]                 \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 50, 50)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 50, 42)       0           permute_13[0][0]                 \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 50, 42)       0           lambda_29[0][0]                  \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 50, 235)      0           dropout_29[0][0]                 \n",
      "                                                                 dot_39[0][0]                     \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 50, 235)      0           dropout_30[0][0]                 \n",
      "                                                                 dot_38[0][0]                     \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_14 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_55[0][0]             \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 50, 50)       0           dropout_31[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 50, 50)       0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 50, 42)       0           permute_14[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 50, 42)       0           lambda_31[0][0]                  \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 50, 319)      0           dropout_31[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 50, 319)      0           dropout_32[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_15 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_57[0][0]             \n",
      "                                                                 concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 50, 50)       0           dropout_33[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 50, 50)       0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot_45 (Dot)                    (None, 50, 42)       0           permute_15[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 50, 42)       0           lambda_33[0][0]                  \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 50, 252)      0           dot_39[0][0]                     \n",
      "                                                                 dropout_29[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 dropout_31[0][0]                 \n",
      "                                                                 dot_45[0][0]                     \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 50, 252)      0           dot_38[0][0]                     \n",
      "                                                                 dropout_30[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "                                                                 dot_44[0][0]                     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 252)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 252)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 252)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 252)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 504)          0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 504)          0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 504)          0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 504)          0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 2016)         0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 2016)         0           concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          516352      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            771         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.0198 - acc: 0.8889 - weighted_accuracy: 0.8839 - val_loss: 0.3301 - val_acc: 0.8464 - val_weighted_accuracy: 0.8449\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0197 - acc: 0.8897 - weighted_accuracy: 0.8851 - val_loss: 0.3250 - val_acc: 0.8520 - val_weighted_accuracy: 0.8484\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0197 - acc: 0.8902 - weighted_accuracy: 0.8861 - val_loss: 0.3351 - val_acc: 0.8443 - val_weighted_accuracy: 0.8415\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0196 - acc: 0.8901 - weighted_accuracy: 0.8862 - val_loss: 0.3204 - val_acc: 0.8544 - val_weighted_accuracy: 0.8479\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0196 - acc: 0.8905 - weighted_accuracy: 0.8863 - val_loss: 0.3320 - val_acc: 0.8470 - val_weighted_accuracy: 0.8457\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0195 - acc: 0.8908 - weighted_accuracy: 0.8871 - val_loss: 0.3128 - val_acc: 0.8584 - val_weighted_accuracy: 0.8517\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0195 - acc: 0.8902 - weighted_accuracy: 0.8864 - val_loss: 0.3129 - val_acc: 0.8586 - val_weighted_accuracy: 0.8518\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0195 - acc: 0.8910 - weighted_accuracy: 0.8872 - val_loss: 0.3237 - val_acc: 0.8512 - val_weighted_accuracy: 0.8471\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0195 - acc: 0.8909 - weighted_accuracy: 0.8873 - val_loss: 0.3103 - val_acc: 0.8577 - val_weighted_accuracy: 0.8517\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0194 - acc: 0.8914 - weighted_accuracy: 0.8880 - val_loss: 0.3271 - val_acc: 0.8475 - val_weighted_accuracy: 0.8452\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0194 - acc: 0.8915 - weighted_accuracy: 0.8881 - val_loss: 0.3100 - val_acc: 0.8566 - val_weighted_accuracy: 0.8503\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0193 - acc: 0.8916 - weighted_accuracy: 0.8882 - val_loss: 0.3288 - val_acc: 0.8463 - val_weighted_accuracy: 0.8447\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0193 - acc: 0.8914 - weighted_accuracy: 0.8881 - val_loss: 0.3325 - val_acc: 0.8446 - val_weighted_accuracy: 0.8449\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0193 - acc: 0.8915 - weighted_accuracy: 0.8883 - val_loss: 0.3111 - val_acc: 0.8579 - val_weighted_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8927 - weighted_accuracy: 0.8895 - val_loss: 0.3204 - val_acc: 0.8510 - val_weighted_accuracy: 0.8486\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8921 - weighted_accuracy: 0.8890 - val_loss: 0.3131 - val_acc: 0.8567 - val_weighted_accuracy: 0.8513\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8922 - weighted_accuracy: 0.8890 - val_loss: 0.3169 - val_acc: 0.8541 - val_weighted_accuracy: 0.8506\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8920 - weighted_accuracy: 0.8889 - val_loss: 0.3171 - val_acc: 0.8547 - val_weighted_accuracy: 0.8479\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8924 - weighted_accuracy: 0.8892 - val_loss: 0.3190 - val_acc: 0.8532 - val_weighted_accuracy: 0.8498\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0191 - acc: 0.8920 - weighted_accuracy: 0.8888 - val_loss: 0.3273 - val_acc: 0.8486 - val_weighted_accuracy: 0.8444\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0191 - acc: 0.8927 - weighted_accuracy: 0.8895 - val_loss: 0.3142 - val_acc: 0.8580 - val_weighted_accuracy: 0.8523\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8926 - weighted_accuracy: 0.8891 - val_loss: 0.3157 - val_acc: 0.8586 - val_weighted_accuracy: 0.8503\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8930 - weighted_accuracy: 0.8900 - val_loss: 0.3147 - val_acc: 0.8540 - val_weighted_accuracy: 0.8498\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8941 - weighted_accuracy: 0.8911 - val_loss: 0.3054 - val_acc: 0.8621 - val_weighted_accuracy: 0.8527\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8933 - weighted_accuracy: 0.8904 - val_loss: 0.3183 - val_acc: 0.8577 - val_weighted_accuracy: 0.8528\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8934 - weighted_accuracy: 0.8904 - val_loss: 0.3248 - val_acc: 0.8523 - val_weighted_accuracy: 0.8495\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8928 - weighted_accuracy: 0.8896 - val_loss: 0.3252 - val_acc: 0.8510 - val_weighted_accuracy: 0.8474\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8931 - weighted_accuracy: 0.8903 - val_loss: 0.3199 - val_acc: 0.8548 - val_weighted_accuracy: 0.8520\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0189 - acc: 0.8932 - weighted_accuracy: 0.8906 - val_loss: 0.3185 - val_acc: 0.8557 - val_weighted_accuracy: 0.8500\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0190 - acc: 0.8937 - weighted_accuracy: 0.8910 - val_loss: 0.3080 - val_acc: 0.8601 - val_weighted_accuracy: 0.8515\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8929 - weighted_accuracy: 0.8900 - val_loss: 0.3210 - val_acc: 0.8539 - val_weighted_accuracy: 0.8493\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0189 - acc: 0.8937 - weighted_accuracy: 0.8910 - val_loss: 0.3133 - val_acc: 0.8572 - val_weighted_accuracy: 0.8518\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8939 - weighted_accuracy: 0.8908 - val_loss: 0.3092 - val_acc: 0.8587 - val_weighted_accuracy: 0.8531\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0189 - acc: 0.8939 - weighted_accuracy: 0.8911 - val_loss: 0.3214 - val_acc: 0.8535 - val_weighted_accuracy: 0.8497\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0189 - acc: 0.8943 - weighted_accuracy: 0.8916 - val_loss: 0.3144 - val_acc: 0.8562 - val_weighted_accuracy: 0.8508\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0189 - acc: 0.8940 - weighted_accuracy: 0.8913 - val_loss: 0.3098 - val_acc: 0.8592 - val_weighted_accuracy: 0.8532\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0189 - acc: 0.8944 - weighted_accuracy: 0.8917 - val_loss: 0.3342 - val_acc: 0.8478 - val_weighted_accuracy: 0.8451\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0189 - acc: 0.8931 - weighted_accuracy: 0.8901 - val_loss: 0.3167 - val_acc: 0.8558 - val_weighted_accuracy: 0.8487\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0188 - acc: 0.8940 - weighted_accuracy: 0.8910 - val_loss: 0.3253 - val_acc: 0.8507 - val_weighted_accuracy: 0.8477\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0189 - acc: 0.8943 - weighted_accuracy: 0.8916 - val_loss: 0.3312 - val_acc: 0.8494 - val_weighted_accuracy: 0.8471\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0188 - acc: 0.8943 - weighted_accuracy: 0.8917 - val_loss: 0.3142 - val_acc: 0.8572 - val_weighted_accuracy: 0.8511\n",
      "Epoch 42/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0188 - acc: 0.8944 - weighted_accuracy: 0.8918 - val_loss: 0.3159 - val_acc: 0.8576 - val_weighted_accuracy: 0.8528\n",
      "Epoch 43/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0188 - acc: 0.8943 - weighted_accuracy: 0.8916 - val_loss: 0.3083 - val_acc: 0.8597 - val_weighted_accuracy: 0.8546\n",
      "Epoch 44/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0188 - acc: 0.8938 - weighted_accuracy: 0.8914 - val_loss: 0.3135 - val_acc: 0.8570 - val_weighted_accuracy: 0.8513\n",
      "Epoch 45/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0188 - acc: 0.8946 - weighted_accuracy: 0.8918 - val_loss: 0.3176 - val_acc: 0.8568 - val_weighted_accuracy: 0.8506\n",
      "Epoch 46/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0188 - acc: 0.8945 - weighted_accuracy: 0.8918 - val_loss: 0.3184 - val_acc: 0.8566 - val_weighted_accuracy: 0.8519\n",
      "Epoch 47/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0188 - acc: 0.8949 - weighted_accuracy: 0.8922 - val_loss: 0.3171 - val_acc: 0.8565 - val_weighted_accuracy: 0.8513\n",
      "Epoch 48/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0188 - acc: 0.8946 - weighted_accuracy: 0.8920 - val_loss: 0.3153 - val_acc: 0.8571 - val_weighted_accuracy: 0.8514\n",
      "Epoch 49/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0187 - acc: 0.8945 - weighted_accuracy: 0.8921 - val_loss: 0.3109 - val_acc: 0.8575 - val_weighted_accuracy: 0.8509\n",
      "Epoch 50/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0187 - acc: 0.8949 - weighted_accuracy: 0.8925 - val_loss: 0.3218 - val_acc: 0.8525 - val_weighted_accuracy: 0.8498\n",
      "Epoch 51/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0188 - acc: 0.8940 - weighted_accuracy: 0.8914 - val_loss: 0.3191 - val_acc: 0.8551 - val_weighted_accuracy: 0.8502\n",
      "Epoch 52/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.0187 - acc: 0.8945 - weighted_accuracy: 0.8921 - val_loss: 0.3109 - val_acc: 0.8590 - val_weighted_accuracy: 0.8526\n",
      "Epoch 53/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0187 - acc: 0.8954 - weighted_accuracy: 0.8928 - val_loss: 0.3134 - val_acc: 0.8590 - val_weighted_accuracy: 0.8527\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 50, 151)      0           embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 50, 151)      0           embedding_11[1][0]               \n",
      "                                                                 embedding_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 50, 151)      0           concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 50, 151)      0           concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_16 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 50, 50)       0           dropout_36[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 50, 50)       0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 50, 42)       0           permute_16[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 50, 42)       0           lambda_36[0][0]                  \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 50, 235)      0           dropout_36[0][0]                 \n",
      "                                                                 dot_48[0][0]                     \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 50, 235)      0           dropout_37[0][0]                 \n",
      "                                                                 dot_47[0][0]                     \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_17 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_68[0][0]             \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 50, 50)       0           dropout_38[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 50, 50)       0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 50, 42)       0           permute_17[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 50, 42)       0           lambda_38[0][0]                  \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 50, 319)      0           dropout_38[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 50, 319)      0           dropout_39[0][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_18 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_70[0][0]             \n",
      "                                                                 concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 50, 50)       0           dropout_40[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 50, 50)       0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 50, 42)       0           permute_18[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 50, 42)       0           lambda_40[0][0]                  \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 50, 252)      0           dot_48[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "                                                                 dot_54[0][0]                     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 50, 252)      0           dot_47[0][0]                     \n",
      "                                                                 dropout_37[0][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 dropout_39[0][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 252)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 252)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 252)          0           concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 252)          0           concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 504)          0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 504)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 504)          0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 504)          0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 2016)         0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 2016)         0           concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          516352      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            771         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.0195 - acc: 0.8910 - weighted_accuracy: 0.8860 - val_loss: 0.3165 - val_acc: 0.8571 - val_weighted_accuracy: 0.8538\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0195 - acc: 0.8908 - weighted_accuracy: 0.8862 - val_loss: 0.3201 - val_acc: 0.8566 - val_weighted_accuracy: 0.8523\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0195 - acc: 0.8913 - weighted_accuracy: 0.8866 - val_loss: 0.3135 - val_acc: 0.8594 - val_weighted_accuracy: 0.8558\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0195 - acc: 0.8907 - weighted_accuracy: 0.8869 - val_loss: 0.3000 - val_acc: 0.8664 - val_weighted_accuracy: 0.8543\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0195 - acc: 0.8907 - weighted_accuracy: 0.8865 - val_loss: 0.3185 - val_acc: 0.8530 - val_weighted_accuracy: 0.8495\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0194 - acc: 0.8910 - weighted_accuracy: 0.8870 - val_loss: 0.3247 - val_acc: 0.8525 - val_weighted_accuracy: 0.8494\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0194 - acc: 0.8911 - weighted_accuracy: 0.8873 - val_loss: 0.3229 - val_acc: 0.8525 - val_weighted_accuracy: 0.8490\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0194 - acc: 0.8912 - weighted_accuracy: 0.8875 - val_loss: 0.3121 - val_acc: 0.8583 - val_weighted_accuracy: 0.8522\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0194 - acc: 0.8915 - weighted_accuracy: 0.8877 - val_loss: 0.3305 - val_acc: 0.8470 - val_weighted_accuracy: 0.8470\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8912 - weighted_accuracy: 0.8873 - val_loss: 0.3104 - val_acc: 0.8585 - val_weighted_accuracy: 0.8530\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8915 - weighted_accuracy: 0.8878 - val_loss: 0.3071 - val_acc: 0.8614 - val_weighted_accuracy: 0.8544\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8925 - weighted_accuracy: 0.8887 - val_loss: 0.3144 - val_acc: 0.8556 - val_weighted_accuracy: 0.8511\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0193 - acc: 0.8921 - weighted_accuracy: 0.8883 - val_loss: 0.3132 - val_acc: 0.8583 - val_weighted_accuracy: 0.8532\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 50, 151)      0           embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 50, 151)      0           embedding_13[1][0]               \n",
      "                                                                 embedding_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 50, 151)      0           concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 50, 151)      0           concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_19 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 50, 50)       0           dropout_43[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 50, 50)       0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 50, 42)       0           permute_19[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 50, 42)       0           lambda_43[0][0]                  \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 50, 235)      0           dropout_43[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 50, 235)      0           dropout_44[0][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_20 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_81[0][0]             \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 50, 50)       0           dropout_45[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 50, 50)       0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 50, 42)       0           permute_20[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 50, 42)       0           lambda_45[0][0]                  \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 50, 319)      0           dropout_45[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 50, 319)      0           dropout_46[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_21 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_83[0][0]             \n",
      "                                                                 concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 50, 50)       0           dropout_47[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 50, 50)       0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 50, 42)       0           permute_21[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 50, 42)       0           lambda_47[0][0]                  \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 50, 252)      0           dot_57[0][0]                     \n",
      "                                                                 dropout_43[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 dropout_45[0][0]                 \n",
      "                                                                 dot_63[0][0]                     \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 50, 252)      0           dot_56[0][0]                     \n",
      "                                                                 dropout_44[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 dropout_46[0][0]                 \n",
      "                                                                 dot_62[0][0]                     \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 252)          0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 252)          0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 252)          0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 252)          0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 504)          0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 504)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 504)          0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 504)          0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 2016)         0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 2016)         0           concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          516352      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            771         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.0191 - acc: 0.8943 - weighted_accuracy: 0.8895 - val_loss: 0.3289 - val_acc: 0.8509 - val_weighted_accuracy: 0.8426\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8936 - weighted_accuracy: 0.8891 - val_loss: 0.3294 - val_acc: 0.8482 - val_weighted_accuracy: 0.8425\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8942 - weighted_accuracy: 0.8898 - val_loss: 0.3250 - val_acc: 0.8497 - val_weighted_accuracy: 0.8426\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0192 - acc: 0.8931 - weighted_accuracy: 0.8888 - val_loss: 0.3281 - val_acc: 0.8488 - val_weighted_accuracy: 0.8422\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8937 - weighted_accuracy: 0.8896 - val_loss: 0.3220 - val_acc: 0.8506 - val_weighted_accuracy: 0.8447\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8941 - weighted_accuracy: 0.8901 - val_loss: 0.3267 - val_acc: 0.8480 - val_weighted_accuracy: 0.8420\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8941 - weighted_accuracy: 0.8901 - val_loss: 0.3245 - val_acc: 0.8505 - val_weighted_accuracy: 0.8449\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8933 - weighted_accuracy: 0.8892 - val_loss: 0.3383 - val_acc: 0.8411 - val_weighted_accuracy: 0.8386\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8939 - weighted_accuracy: 0.8899 - val_loss: 0.3313 - val_acc: 0.8471 - val_weighted_accuracy: 0.8411\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8941 - weighted_accuracy: 0.8902 - val_loss: 0.3253 - val_acc: 0.8472 - val_weighted_accuracy: 0.8407\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8937 - weighted_accuracy: 0.8897 - val_loss: 0.3365 - val_acc: 0.8460 - val_weighted_accuracy: 0.8436\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8943 - weighted_accuracy: 0.8904 - val_loss: 0.3240 - val_acc: 0.8517 - val_weighted_accuracy: 0.8440\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8936 - weighted_accuracy: 0.8898 - val_loss: 0.3224 - val_acc: 0.8522 - val_weighted_accuracy: 0.8471\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8939 - weighted_accuracy: 0.8900 - val_loss: 0.3344 - val_acc: 0.8481 - val_weighted_accuracy: 0.8427\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8934 - weighted_accuracy: 0.8895 - val_loss: 0.3260 - val_acc: 0.8503 - val_weighted_accuracy: 0.8422\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8945 - weighted_accuracy: 0.8908 - val_loss: 0.3355 - val_acc: 0.8468 - val_weighted_accuracy: 0.8418\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8940 - weighted_accuracy: 0.8903 - val_loss: 0.3353 - val_acc: 0.8450 - val_weighted_accuracy: 0.8425\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0189 - acc: 0.8949 - weighted_accuracy: 0.8914 - val_loss: 0.3216 - val_acc: 0.8517 - val_weighted_accuracy: 0.8428\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8948 - weighted_accuracy: 0.8910 - val_loss: 0.3215 - val_acc: 0.8517 - val_weighted_accuracy: 0.8438\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0190 - acc: 0.8947 - weighted_accuracy: 0.8907 - val_loss: 0.3283 - val_acc: 0.8464 - val_weighted_accuracy: 0.8419\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0189 - acc: 0.8944 - weighted_accuracy: 0.8909 - val_loss: 0.3304 - val_acc: 0.8479 - val_weighted_accuracy: 0.8434\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0189 - acc: 0.8946 - weighted_accuracy: 0.8912 - val_loss: 0.3332 - val_acc: 0.8473 - val_weighted_accuracy: 0.8430\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0188 - acc: 0.8946 - weighted_accuracy: 0.8912 - val_loss: 0.3298 - val_acc: 0.8468 - val_weighted_accuracy: 0.8413\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 50, 151)      0           embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 50, 151)      0           embedding_15[1][0]               \n",
      "                                                                 embedding_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 50, 151)      0           concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 50, 151)      0           concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_22 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 50, 50)       0           dropout_50[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 50, 50)       0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 50, 42)       0           permute_22[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 50, 42)       0           lambda_50[0][0]                  \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 50, 235)      0           dropout_50[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 50, 235)      0           dropout_51[0][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_23 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_94[0][0]             \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 50, 50)       0           dropout_52[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 50, 50)       0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 50, 42)       0           permute_23[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 50, 42)       0           lambda_52[0][0]                  \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 50, 319)      0           dropout_52[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 50, 319)      0           dropout_53[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_24 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_96[0][0]             \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 50, 50)       0           dropout_54[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 50, 50)       0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 50, 42)       0           permute_24[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 50, 42)       0           lambda_54[0][0]                  \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 50, 252)      0           dot_66[0][0]                     \n",
      "                                                                 dropout_50[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 dropout_52[0][0]                 \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 50, 252)      0           dot_65[0][0]                     \n",
      "                                                                 dropout_51[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 252)          0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 252)          0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 252)          0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 252)          0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 504)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 504)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 504)          0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 504)          0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 2016)         0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 2016)         0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          516352      dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            771         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.0201 - acc: 0.8872 - weighted_accuracy: 0.8821 - val_loss: 0.3539 - val_acc: 0.8292 - val_weighted_accuracy: 0.8264\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0199 - acc: 0.8885 - weighted_accuracy: 0.8836 - val_loss: 0.3377 - val_acc: 0.8379 - val_weighted_accuracy: 0.8265\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0198 - acc: 0.8885 - weighted_accuracy: 0.8841 - val_loss: 0.3613 - val_acc: 0.8249 - val_weighted_accuracy: 0.8198\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0197 - acc: 0.8893 - weighted_accuracy: 0.8850 - val_loss: 0.3621 - val_acc: 0.8284 - val_weighted_accuracy: 0.8237\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0196 - acc: 0.8892 - weighted_accuracy: 0.8851 - val_loss: 0.3468 - val_acc: 0.8335 - val_weighted_accuracy: 0.8267\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0195 - acc: 0.8903 - weighted_accuracy: 0.8863 - val_loss: 0.3510 - val_acc: 0.8355 - val_weighted_accuracy: 0.8266\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0195 - acc: 0.8909 - weighted_accuracy: 0.8871 - val_loss: 0.3500 - val_acc: 0.8322 - val_weighted_accuracy: 0.8241\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0194 - acc: 0.8905 - weighted_accuracy: 0.8871 - val_loss: 0.3371 - val_acc: 0.8468 - val_weighted_accuracy: 0.8267\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0194 - acc: 0.8913 - weighted_accuracy: 0.8877 - val_loss: 0.3431 - val_acc: 0.8369 - val_weighted_accuracy: 0.8259\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8916 - weighted_accuracy: 0.8878 - val_loss: 0.3446 - val_acc: 0.8358 - val_weighted_accuracy: 0.8272\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8911 - weighted_accuracy: 0.8876 - val_loss: 0.3402 - val_acc: 0.8393 - val_weighted_accuracy: 0.8287\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8922 - weighted_accuracy: 0.8888 - val_loss: 0.3539 - val_acc: 0.8413 - val_weighted_accuracy: 0.8287\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8925 - weighted_accuracy: 0.8896 - val_loss: 0.3367 - val_acc: 0.8401 - val_weighted_accuracy: 0.8291\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8933 - weighted_accuracy: 0.8896 - val_loss: 0.3457 - val_acc: 0.8384 - val_weighted_accuracy: 0.8323\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8932 - weighted_accuracy: 0.8899 - val_loss: 0.3332 - val_acc: 0.8424 - val_weighted_accuracy: 0.8318\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8934 - weighted_accuracy: 0.8899 - val_loss: 0.3361 - val_acc: 0.8412 - val_weighted_accuracy: 0.8319\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0191 - acc: 0.8930 - weighted_accuracy: 0.8898 - val_loss: 0.3419 - val_acc: 0.8419 - val_weighted_accuracy: 0.8301\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8938 - weighted_accuracy: 0.8904 - val_loss: 0.3505 - val_acc: 0.8362 - val_weighted_accuracy: 0.8279\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0190 - acc: 0.8933 - weighted_accuracy: 0.8901 - val_loss: 0.3363 - val_acc: 0.8427 - val_weighted_accuracy: 0.8318\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0189 - acc: 0.8935 - weighted_accuracy: 0.8903 - val_loss: 0.3412 - val_acc: 0.8446 - val_weighted_accuracy: 0.8322\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0189 - acc: 0.8937 - weighted_accuracy: 0.8907 - val_loss: 0.3384 - val_acc: 0.8414 - val_weighted_accuracy: 0.8312\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0189 - acc: 0.8942 - weighted_accuracy: 0.8911 - val_loss: 0.3391 - val_acc: 0.8415 - val_weighted_accuracy: 0.8310\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.0189 - acc: 0.8939 - weighted_accuracy: 0.8906 - val_loss: 0.3384 - val_acc: 0.8408 - val_weighted_accuracy: 0.8318\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0189 - acc: 0.8938 - weighted_accuracy: 0.8908 - val_loss: 0.3344 - val_acc: 0.8447 - val_weighted_accuracy: 0.8315\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 50, 151)      0           embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 50, 151)      0           embedding_17[1][0]               \n",
      "                                                                 embedding_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 50, 151)      0           concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 50, 151)      0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_25 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 50, 50)       0           dropout_57[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 50, 50)       0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 50, 42)       0           permute_25[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 50, 42)       0           lambda_57[0][0]                  \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 50, 235)      0           dropout_57[0][0]                 \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 spatial_dropout1d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 50, 235)      0           dropout_58[0][0]                 \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_26 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_107[0][0]            \n",
      "                                                                 concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 50, 50)       0           dropout_59[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 50, 50)       0           lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 50, 42)       0           permute_26[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 50, 42)       0           lambda_59[0][0]                  \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 50, 319)      0           dropout_59[0][0]                 \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 50, 319)      0           dropout_60[0][0]                 \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_27 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_109[0][0]            \n",
      "                                                                 concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 50, 50)       0           dropout_61[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 50, 50)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 50, 42)       0           permute_27[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 50, 42)       0           lambda_61[0][0]                  \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 50, 252)      0           dot_75[0][0]                     \n",
      "                                                                 dropout_57[0][0]                 \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 dropout_59[0][0]                 \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 50, 252)      0           dot_74[0][0]                     \n",
      "                                                                 dropout_58[0][0]                 \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 dropout_60[0][0]                 \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 252)          0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 252)          0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 252)          0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 252)          0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 504)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 504)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 504)          0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 504)          0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 2016)         0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 2016)         0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          516352      dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 3)            771         dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 126s 348us/step - loss: 0.0203 - acc: 0.8851 - weighted_accuracy: 0.8800 - val_loss: 0.3043 - val_acc: 0.8627 - val_weighted_accuracy: 0.8573\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0202 - acc: 0.8851 - weighted_accuracy: 0.8807 - val_loss: 0.3148 - val_acc: 0.8562 - val_weighted_accuracy: 0.8536\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0201 - acc: 0.8866 - weighted_accuracy: 0.8821 - val_loss: 0.3187 - val_acc: 0.8503 - val_weighted_accuracy: 0.8533\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0200 - acc: 0.8874 - weighted_accuracy: 0.8830 - val_loss: 0.3098 - val_acc: 0.8595 - val_weighted_accuracy: 0.8561\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0199 - acc: 0.8880 - weighted_accuracy: 0.8837 - val_loss: 0.3112 - val_acc: 0.8594 - val_weighted_accuracy: 0.8561\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0198 - acc: 0.8885 - weighted_accuracy: 0.8844 - val_loss: 0.3297 - val_acc: 0.8514 - val_weighted_accuracy: 0.8499\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0198 - acc: 0.8888 - weighted_accuracy: 0.8849 - val_loss: 0.3071 - val_acc: 0.8625 - val_weighted_accuracy: 0.8586\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0197 - acc: 0.8889 - weighted_accuracy: 0.8849 - val_loss: 0.2990 - val_acc: 0.8647 - val_weighted_accuracy: 0.8604\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0196 - acc: 0.8890 - weighted_accuracy: 0.8848 - val_loss: 0.3138 - val_acc: 0.8592 - val_weighted_accuracy: 0.8566\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0195 - acc: 0.8901 - weighted_accuracy: 0.8860 - val_loss: 0.3057 - val_acc: 0.8630 - val_weighted_accuracy: 0.8585\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0195 - acc: 0.8905 - weighted_accuracy: 0.8868 - val_loss: 0.3283 - val_acc: 0.8506 - val_weighted_accuracy: 0.8522\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0195 - acc: 0.8909 - weighted_accuracy: 0.8870 - val_loss: 0.3249 - val_acc: 0.8517 - val_weighted_accuracy: 0.8501\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0195 - acc: 0.8904 - weighted_accuracy: 0.8866 - val_loss: 0.3188 - val_acc: 0.8555 - val_weighted_accuracy: 0.8536\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0194 - acc: 0.8903 - weighted_accuracy: 0.8866 - val_loss: 0.3020 - val_acc: 0.8639 - val_weighted_accuracy: 0.8610\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8911 - weighted_accuracy: 0.8876 - val_loss: 0.3068 - val_acc: 0.8634 - val_weighted_accuracy: 0.8604\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0194 - acc: 0.8908 - weighted_accuracy: 0.8872 - val_loss: 0.3029 - val_acc: 0.8644 - val_weighted_accuracy: 0.8590\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8914 - weighted_accuracy: 0.8875 - val_loss: 0.2993 - val_acc: 0.8644 - val_weighted_accuracy: 0.8595\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8917 - weighted_accuracy: 0.8884 - val_loss: 0.3085 - val_acc: 0.8614 - val_weighted_accuracy: 0.8561\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0192 - acc: 0.8927 - weighted_accuracy: 0.8891 - val_loss: 0.3047 - val_acc: 0.8593 - val_weighted_accuracy: 0.8576\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0191 - acc: 0.8919 - weighted_accuracy: 0.8885 - val_loss: 0.3031 - val_acc: 0.8640 - val_weighted_accuracy: 0.8590\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8921 - weighted_accuracy: 0.8889 - val_loss: 0.3084 - val_acc: 0.8599 - val_weighted_accuracy: 0.8560\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8924 - weighted_accuracy: 0.8892 - val_loss: 0.3160 - val_acc: 0.8571 - val_weighted_accuracy: 0.8536\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8930 - weighted_accuracy: 0.8896 - val_loss: 0.3135 - val_acc: 0.8604 - val_weighted_accuracy: 0.8564\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8928 - weighted_accuracy: 0.8896 - val_loss: 0.2955 - val_acc: 0.8665 - val_weighted_accuracy: 0.8594\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 50, 151)      0           embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 50, 151)      0           embedding_19[1][0]               \n",
      "                                                                 embedding_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 50, 151)      0           concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 50, 151)      0           concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_28 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 50, 42)       0           cu_dnngru_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 50, 42)       0           cu_dnngru_28[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 50, 50)       0           dropout_64[0][0]                 \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 50, 50)       0           lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 50, 42)       0           permute_28[0][0]                 \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 50, 42)       0           lambda_64[0][0]                  \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 50, 235)      0           dropout_64[0][0]                 \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 spatial_dropout1d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 50, 235)      0           dropout_65[0][0]                 \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_29 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_120[0][0]            \n",
      "                                                                 concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 50, 42)       0           cu_dnngru_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 50, 42)       0           cu_dnngru_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_85 (Dot)                    (None, 50, 50)       0           dropout_66[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 50, 50)       0           lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_87 (Dot)                    (None, 50, 42)       0           permute_29[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_86 (Dot)                    (None, 50, 42)       0           lambda_66[0][0]                  \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 50, 319)      0           dropout_66[0][0]                 \n",
      "                                                                 dot_87[0][0]                     \n",
      "                                                                 concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 50, 319)      0           dropout_67[0][0]                 \n",
      "                                                                 dot_86[0][0]                     \n",
      "                                                                 concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_30 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_122[0][0]            \n",
      "                                                                 concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 50, 42)       0           cu_dnngru_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 50, 42)       0           cu_dnngru_30[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_88 (Dot)                    (None, 50, 50)       0           dropout_68[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 50, 50)       0           lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_90 (Dot)                    (None, 50, 42)       0           permute_30[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_89 (Dot)                    (None, 50, 42)       0           lambda_68[0][0]                  \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 50, 252)      0           dot_84[0][0]                     \n",
      "                                                                 dropout_64[0][0]                 \n",
      "                                                                 dot_87[0][0]                     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "                                                                 dot_90[0][0]                     \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 50, 252)      0           dot_83[0][0]                     \n",
      "                                                                 dropout_65[0][0]                 \n",
      "                                                                 dot_86[0][0]                     \n",
      "                                                                 dropout_67[0][0]                 \n",
      "                                                                 dot_89[0][0]                     \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 252)          0           concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 252)          0           concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 252)          0           concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 252)          0           concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 504)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 504)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 504)          0           concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 504)          0           concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 2016)         0           concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "                                                                 lambda_70[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 2016)         0           concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          516352      dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            771         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 126s 351us/step - loss: 0.0195 - acc: 0.8909 - weighted_accuracy: 0.8861 - val_loss: 0.3303 - val_acc: 0.8522 - val_weighted_accuracy: 0.8505\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0194 - acc: 0.8910 - weighted_accuracy: 0.8864 - val_loss: 0.2965 - val_acc: 0.8656 - val_weighted_accuracy: 0.8572\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0194 - acc: 0.8918 - weighted_accuracy: 0.8874 - val_loss: 0.2967 - val_acc: 0.8634 - val_weighted_accuracy: 0.8568\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0194 - acc: 0.8914 - weighted_accuracy: 0.8876 - val_loss: 0.3014 - val_acc: 0.8650 - val_weighted_accuracy: 0.8583\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0194 - acc: 0.8915 - weighted_accuracy: 0.8872 - val_loss: 0.2992 - val_acc: 0.8635 - val_weighted_accuracy: 0.8578\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0193 - acc: 0.8916 - weighted_accuracy: 0.8875 - val_loss: 0.2981 - val_acc: 0.8639 - val_weighted_accuracy: 0.8590\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0193 - acc: 0.8916 - weighted_accuracy: 0.8874 - val_loss: 0.3097 - val_acc: 0.8603 - val_weighted_accuracy: 0.8572\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0192 - acc: 0.8920 - weighted_accuracy: 0.8884 - val_loss: 0.2888 - val_acc: 0.8691 - val_weighted_accuracy: 0.8581\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0193 - acc: 0.8920 - weighted_accuracy: 0.8880 - val_loss: 0.2943 - val_acc: 0.8662 - val_weighted_accuracy: 0.8592\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.0192 - acc: 0.8924 - weighted_accuracy: 0.8885 - val_loss: 0.3315 - val_acc: 0.8542 - val_weighted_accuracy: 0.8517\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.0192 - acc: 0.8921 - weighted_accuracy: 0.8883 - val_loss: 0.2910 - val_acc: 0.8699 - val_weighted_accuracy: 0.8619\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0192 - acc: 0.8926 - weighted_accuracy: 0.8888 - val_loss: 0.2855 - val_acc: 0.8728 - val_weighted_accuracy: 0.8614\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.0192 - acc: 0.8927 - weighted_accuracy: 0.8891 - val_loss: 0.3050 - val_acc: 0.8621 - val_weighted_accuracy: 0.8573\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0191 - acc: 0.8924 - weighted_accuracy: 0.8888 - val_loss: 0.3010 - val_acc: 0.8641 - val_weighted_accuracy: 0.8579\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8916 - weighted_accuracy: 0.8885 - val_loss: 0.2954 - val_acc: 0.8656 - val_weighted_accuracy: 0.8589\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0191 - acc: 0.8927 - weighted_accuracy: 0.8891 - val_loss: 0.3021 - val_acc: 0.8649 - val_weighted_accuracy: 0.8584\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0191 - acc: 0.8929 - weighted_accuracy: 0.8895 - val_loss: 0.3043 - val_acc: 0.8610 - val_weighted_accuracy: 0.8562\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0191 - acc: 0.8927 - weighted_accuracy: 0.8892 - val_loss: 0.2958 - val_acc: 0.8659 - val_weighted_accuracy: 0.8591\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8932 - weighted_accuracy: 0.8899 - val_loss: 0.3016 - val_acc: 0.8642 - val_weighted_accuracy: 0.8570\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0191 - acc: 0.8930 - weighted_accuracy: 0.8896 - val_loss: 0.2972 - val_acc: 0.8656 - val_weighted_accuracy: 0.8584\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0190 - acc: 0.8930 - weighted_accuracy: 0.8895 - val_loss: 0.2982 - val_acc: 0.8673 - val_weighted_accuracy: 0.8595\n",
      "score 0.8537635833334389\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "80126/80126 [==============================] - 9s 111us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_darnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2][:, -1]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2][:, -1]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PS3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    meta_features_input = Input(shape=(1,), name='mata-features')\n",
    "    \n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    flex_embedding = Embedding(nb_words, 20,\n",
    "                      input_length=max_sequence_length,\n",
    "                      trainable=True)\n",
    "    \n",
    "    em_embeddings = Reshape((max_sequence_length, 1))\n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match),])\n",
    "    q1_encoded = SpatialDropout1D(0.2)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match),])\n",
    "    q2_encoded = SpatialDropout1D(0.2)(q2_embed)\n",
    "\n",
    "\n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    nb_filters = 64\n",
    "    \n",
    "    cnns = [Conv1D(64, 1, strides=1, padding='same', activation='relu') for i in range(3)]\n",
    "    gates_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='tanh') for i in range(3)]\n",
    "    sigm_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='sigmoid') for i in range(3)]\n",
    "    \n",
    "    for i in range(len(cnns)):\n",
    "        drop = Dropout(0.1)\n",
    "        q1_t = gates_cnns[i](q1_encoded)\n",
    "        q2_t = gates_cnns[i](q2_encoded)    \n",
    "        \n",
    "        q1_s = sigm_cnns[i](q1_encoded)\n",
    "        q2_s = sigm_cnns[i](q2_encoded)        \n",
    "        \n",
    "        q1_x = Multiply()([q1_t, q1_s])\n",
    "        q1_x = cnns[i](q1_x)\n",
    "        q1_x = drop(q1_x)\n",
    "        \n",
    "        q2_x = Multiply()([q2_t, q2_s])\n",
    "        q2_x = cnns[i](q2_x)\n",
    "        q2_x = drop(q2_x)\n",
    "\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_x, q2_x)\n",
    "        q1_encoded = Concatenate()([q1_x, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_x, q1_aligned, q2_encoded]) \n",
    "    \n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    attn = AttentionWeightedAverage()\n",
    "    \n",
    "    \n",
    "    q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])\n",
    "    q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])    \n",
    "    \n",
    "    \n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    #drops = Dropout(0.3)\n",
    "    #q1_rep = shrink(drops(q1_rep))\n",
    "    #q2_rep = shrink(drops(q2_rep))\n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    #h_all = Dropout(0.35)(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)    \n",
    "    h_all = Dense(64, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-6))(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, meta_features_input, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 50, 151)      0           embedding_21[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 50, 151)      0           embedding_21[1][0]               \n",
      "                                                                 reshape_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 50, 151)      0           concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 50, 151)      0           concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 50, 64)       29056       spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 50, 64)       29056       spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 50, 64)       0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 50, 64)       0           conv1d_4[1][0]                   \n",
      "                                                                 conv1d_7[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 64)       4160        multiply_11[0][0]                \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 50, 64)       0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_91 (Dot)                    (None, 50, 50)       0           dropout_71[0][0]                 \n",
      "                                                                 dropout_71[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_31 (Permute)            (None, 50, 50)       0           lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_93 (Dot)                    (None, 50, 64)       0           permute_31[0][0]                 \n",
      "                                                                 dropout_71[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_92 (Dot)                    (None, 50, 64)       0           lambda_71[0][0]                  \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 50, 279)      0           dropout_71[0][0]                 \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 spatial_dropout1d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 50, 279)      0           dropout_71[1][0]                 \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 50, 64)       53632       concatenate_133[0][0]            \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 50, 64)       53632       concatenate_133[0][0]            \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 50, 64)       0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 50, 64)       0           conv1d_5[1][0]                   \n",
      "                                                                 conv1d_8[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 64)       4160        multiply_13[0][0]                \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 50, 64)       0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_94 (Dot)                    (None, 50, 50)       0           dropout_72[0][0]                 \n",
      "                                                                 dropout_72[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_32 (Permute)            (None, 50, 50)       0           lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_96 (Dot)                    (None, 50, 64)       0           permute_32[0][0]                 \n",
      "                                                                 dropout_72[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_95 (Dot)                    (None, 50, 64)       0           lambda_73[0][0]                  \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 50, 407)      0           dropout_72[0][0]                 \n",
      "                                                                 dot_96[0][0]                     \n",
      "                                                                 concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 50, 407)      0           dropout_72[1][0]                 \n",
      "                                                                 dot_95[0][0]                     \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 50, 64)       78208       concatenate_135[0][0]            \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 50, 64)       78208       concatenate_135[0][0]            \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 50, 64)       0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 50, 64)       0           conv1d_6[1][0]                   \n",
      "                                                                 conv1d_9[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 64)       4160        multiply_15[0][0]                \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 50, 64)       0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_97 (Dot)                    (None, 50, 50)       0           dropout_73[0][0]                 \n",
      "                                                                 dropout_73[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_33 (Permute)            (None, 50, 50)       0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_99 (Dot)                    (None, 50, 64)       0           permute_33[0][0]                 \n",
      "                                                                 dropout_73[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_98 (Dot)                    (None, 50, 64)       0           lambda_75[0][0]                  \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 50, 535)      0           dropout_73[0][0]                 \n",
      "                                                                 dot_99[0][0]                     \n",
      "                                                                 concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 50, 535)      0           dropout_73[1][0]                 \n",
      "                                                                 dot_98[0][0]                     \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 535)          0           concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 535)          0           concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_1 (A (None, 535)          535         concatenate_137[0][0]            \n",
      "                                                                 concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 535)          0           concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 535)          0           concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 1605)         0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "                                                                 attention_weighted_average_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 1605)         0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 attention_weighted_average_1[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 1605)         0           concatenate_139[0][0]            \n",
      "                                                                 concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 1605)         0           concatenate_139[0][0]            \n",
      "                                                                 concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 6420)         0           concatenate_139[0][0]            \n",
      "                                                                 concatenate_140[0][0]            \n",
      "                                                                 lambda_77[0][0]                  \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 6420)         0           concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 6420)         25680       dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           410944      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            195         dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0235 - acc: 0.8662 - weighted_accuracy: 0.8600 - val_loss: 0.3166 - val_acc: 0.8556 - val_weighted_accuracy: 0.8442\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0235 - acc: 0.8683 - weighted_accuracy: 0.8625 - val_loss: 0.3138 - val_acc: 0.8566 - val_weighted_accuracy: 0.8431\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0233 - acc: 0.8708 - weighted_accuracy: 0.8652 - val_loss: 0.3116 - val_acc: 0.8566 - val_weighted_accuracy: 0.8427\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0232 - acc: 0.8726 - weighted_accuracy: 0.8672 - val_loss: 0.3133 - val_acc: 0.8586 - val_weighted_accuracy: 0.8460\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0228 - acc: 0.8745 - weighted_accuracy: 0.8695 - val_loss: 0.3037 - val_acc: 0.8618 - val_weighted_accuracy: 0.8478\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0227 - acc: 0.8754 - weighted_accuracy: 0.8705 - val_loss: 0.3121 - val_acc: 0.8531 - val_weighted_accuracy: 0.8377\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0224 - acc: 0.8774 - weighted_accuracy: 0.8725 - val_loss: 0.3081 - val_acc: 0.8588 - val_weighted_accuracy: 0.8465\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0224 - acc: 0.8776 - weighted_accuracy: 0.8727 - val_loss: 0.3037 - val_acc: 0.8634 - val_weighted_accuracy: 0.8487\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0223 - acc: 0.8788 - weighted_accuracy: 0.8743 - val_loss: 0.3113 - val_acc: 0.8595 - val_weighted_accuracy: 0.8492\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0221 - acc: 0.8795 - weighted_accuracy: 0.8746 - val_loss: 0.3004 - val_acc: 0.8645 - val_weighted_accuracy: 0.8532\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0220 - acc: 0.8804 - weighted_accuracy: 0.8760 - val_loss: 0.3029 - val_acc: 0.8624 - val_weighted_accuracy: 0.8509\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0219 - acc: 0.8809 - weighted_accuracy: 0.8763 - val_loss: 0.3014 - val_acc: 0.8645 - val_weighted_accuracy: 0.8516\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0218 - acc: 0.8821 - weighted_accuracy: 0.8778 - val_loss: 0.3017 - val_acc: 0.8624 - val_weighted_accuracy: 0.8527\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0216 - acc: 0.8828 - weighted_accuracy: 0.8784 - val_loss: 0.2974 - val_acc: 0.8675 - val_weighted_accuracy: 0.8538\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0216 - acc: 0.8826 - weighted_accuracy: 0.8786 - val_loss: 0.2965 - val_acc: 0.8682 - val_weighted_accuracy: 0.8489\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0216 - acc: 0.8825 - weighted_accuracy: 0.8782 - val_loss: 0.2919 - val_acc: 0.8686 - val_weighted_accuracy: 0.8502\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0215 - acc: 0.8832 - weighted_accuracy: 0.8792 - val_loss: 0.3038 - val_acc: 0.8628 - val_weighted_accuracy: 0.8506\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0215 - acc: 0.8838 - weighted_accuracy: 0.8796 - val_loss: 0.3044 - val_acc: 0.8643 - val_weighted_accuracy: 0.8556\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0213 - acc: 0.8842 - weighted_accuracy: 0.8801 - val_loss: 0.2964 - val_acc: 0.8667 - val_weighted_accuracy: 0.8509\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0213 - acc: 0.8845 - weighted_accuracy: 0.8804 - val_loss: 0.3072 - val_acc: 0.8633 - val_weighted_accuracy: 0.8553\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0212 - acc: 0.8845 - weighted_accuracy: 0.8804 - val_loss: 0.2970 - val_acc: 0.8645 - val_weighted_accuracy: 0.8521\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0211 - acc: 0.8851 - weighted_accuracy: 0.8813 - val_loss: 0.2929 - val_acc: 0.8685 - val_weighted_accuracy: 0.8530\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0211 - acc: 0.8853 - weighted_accuracy: 0.8817 - val_loss: 0.2941 - val_acc: 0.8664 - val_weighted_accuracy: 0.8498\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0211 - acc: 0.8855 - weighted_accuracy: 0.8818 - val_loss: 0.2937 - val_acc: 0.8681 - val_weighted_accuracy: 0.8552\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0211 - acc: 0.8860 - weighted_accuracy: 0.8823 - val_loss: 0.3057 - val_acc: 0.8657 - val_weighted_accuracy: 0.8550\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0210 - acc: 0.8866 - weighted_accuracy: 0.8829 - val_loss: 0.2956 - val_acc: 0.8689 - val_weighted_accuracy: 0.8553\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0209 - acc: 0.8868 - weighted_accuracy: 0.8830 - val_loss: 0.3042 - val_acc: 0.8634 - val_weighted_accuracy: 0.8552\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 119s 331us/step - loss: 0.0210 - acc: 0.8871 - weighted_accuracy: 0.8832 - val_loss: 0.2939 - val_acc: 0.8680 - val_weighted_accuracy: 0.8521\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 50, 151)      0           embedding_23[0][0]               \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 50, 151)      0           embedding_23[1][0]               \n",
      "                                                                 reshape_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 50, 151)      0           concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 50, 151)      0           concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 50, 64)       0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 50, 64)       0           conv1d_13[1][0]                  \n",
      "                                                                 conv1d_16[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 50, 64)       4160        multiply_18[0][0]                \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 50, 64)       0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_10[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_100 (Dot)                   (None, 50, 50)       0           dropout_75[0][0]                 \n",
      "                                                                 dropout_75[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_34 (Permute)            (None, 50, 50)       0           lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_102 (Dot)                   (None, 50, 64)       0           permute_34[0][0]                 \n",
      "                                                                 dropout_75[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 50, 64)       0           lambda_78[0][0]                  \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 50, 279)      0           dropout_75[0][0]                 \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 spatial_dropout1d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 50, 279)      0           dropout_75[1][0]                 \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 50, 64)       53632       concatenate_144[0][0]            \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 50, 64)       53632       concatenate_144[0][0]            \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 50, 64)       0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 50, 64)       0           conv1d_14[1][0]                  \n",
      "                                                                 conv1d_17[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 50, 64)       4160        multiply_20[0][0]                \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 50, 64)       0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_11[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_103 (Dot)                   (None, 50, 50)       0           dropout_76[0][0]                 \n",
      "                                                                 dropout_76[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_35 (Permute)            (None, 50, 50)       0           lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_105 (Dot)                   (None, 50, 64)       0           permute_35[0][0]                 \n",
      "                                                                 dropout_76[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_104 (Dot)                   (None, 50, 64)       0           lambda_80[0][0]                  \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 50, 407)      0           dropout_76[0][0]                 \n",
      "                                                                 dot_105[0][0]                    \n",
      "                                                                 concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 50, 407)      0           dropout_76[1][0]                 \n",
      "                                                                 dot_104[0][0]                    \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 50, 64)       78208       concatenate_146[0][0]            \n",
      "                                                                 concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 50, 64)       78208       concatenate_146[0][0]            \n",
      "                                                                 concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 50, 64)       0           conv1d_15[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 50, 64)       0           conv1d_15[1][0]                  \n",
      "                                                                 conv1d_18[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 64)       4160        multiply_22[0][0]                \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 50, 64)       0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_12[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_106 (Dot)                   (None, 50, 50)       0           dropout_77[0][0]                 \n",
      "                                                                 dropout_77[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 50, 50)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_36 (Permute)            (None, 50, 50)       0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 50, 50)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_108 (Dot)                   (None, 50, 64)       0           permute_36[0][0]                 \n",
      "                                                                 dropout_77[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_107 (Dot)                   (None, 50, 64)       0           lambda_82[0][0]                  \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 50, 535)      0           dropout_77[0][0]                 \n",
      "                                                                 dot_108[0][0]                    \n",
      "                                                                 concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 50, 535)      0           dropout_77[1][0]                 \n",
      "                                                                 dot_107[0][0]                    \n",
      "                                                                 concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 535)          0           concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 535)          0           concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 535)          535         concatenate_148[0][0]            \n",
      "                                                                 concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 535)          0           concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 535)          0           concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 1605)         0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 attention_weighted_average_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 1605)         0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "                                                                 attention_weighted_average_2[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 1605)         0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 1605)         0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 6420)         0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "                                                                 lambda_84[0][0]                  \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 6420)         0           concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6420)         25680       dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64)           410944      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 3)            195         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0227 - acc: 0.8778 - weighted_accuracy: 0.8722 - val_loss: 0.2989 - val_acc: 0.8673 - val_weighted_accuracy: 0.8570\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0230 - acc: 0.8757 - weighted_accuracy: 0.8702 - val_loss: 0.3049 - val_acc: 0.8631 - val_weighted_accuracy: 0.8553\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0229 - acc: 0.8763 - weighted_accuracy: 0.8713 - val_loss: 0.3066 - val_acc: 0.8612 - val_weighted_accuracy: 0.8535\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0230 - acc: 0.8760 - weighted_accuracy: 0.8706 - val_loss: 0.2850 - val_acc: 0.8735 - val_weighted_accuracy: 0.8572\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0227 - acc: 0.8777 - weighted_accuracy: 0.8729 - val_loss: 0.2906 - val_acc: 0.8708 - val_weighted_accuracy: 0.8599\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0227 - acc: 0.8780 - weighted_accuracy: 0.8732 - val_loss: 0.2950 - val_acc: 0.8654 - val_weighted_accuracy: 0.8519\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0225 - acc: 0.8785 - weighted_accuracy: 0.8738 - val_loss: 0.2962 - val_acc: 0.8662 - val_weighted_accuracy: 0.8573\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0223 - acc: 0.8800 - weighted_accuracy: 0.8752 - val_loss: 0.2897 - val_acc: 0.8701 - val_weighted_accuracy: 0.8580\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0222 - acc: 0.8808 - weighted_accuracy: 0.8762 - val_loss: 0.2878 - val_acc: 0.8722 - val_weighted_accuracy: 0.8601\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0222 - acc: 0.8804 - weighted_accuracy: 0.8758 - val_loss: 0.2794 - val_acc: 0.8763 - val_weighted_accuracy: 0.8623\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0221 - acc: 0.8812 - weighted_accuracy: 0.8767 - val_loss: 0.2866 - val_acc: 0.8730 - val_weighted_accuracy: 0.8613\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0220 - acc: 0.8820 - weighted_accuracy: 0.8774 - val_loss: 0.2912 - val_acc: 0.8679 - val_weighted_accuracy: 0.8505\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0219 - acc: 0.8827 - weighted_accuracy: 0.8783 - val_loss: 0.2824 - val_acc: 0.8750 - val_weighted_accuracy: 0.8602\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0218 - acc: 0.8831 - weighted_accuracy: 0.8788 - val_loss: 0.2887 - val_acc: 0.8709 - val_weighted_accuracy: 0.8618\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0217 - acc: 0.8841 - weighted_accuracy: 0.8799 - val_loss: 0.2894 - val_acc: 0.8713 - val_weighted_accuracy: 0.8571\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0217 - acc: 0.8838 - weighted_accuracy: 0.8796 - val_loss: 0.2872 - val_acc: 0.8703 - val_weighted_accuracy: 0.8589\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0216 - acc: 0.8838 - weighted_accuracy: 0.8799 - val_loss: 0.2787 - val_acc: 0.8752 - val_weighted_accuracy: 0.8582\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0216 - acc: 0.8836 - weighted_accuracy: 0.8793 - val_loss: 0.2823 - val_acc: 0.8727 - val_weighted_accuracy: 0.8559\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0215 - acc: 0.8843 - weighted_accuracy: 0.8801 - val_loss: 0.2864 - val_acc: 0.8682 - val_weighted_accuracy: 0.8523\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 120s 331us/step - loss: 0.0215 - acc: 0.8852 - weighted_accuracy: 0.8810 - val_loss: 0.2798 - val_acc: 0.8767 - val_weighted_accuracy: 0.8620\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 50, 151)      0           embedding_25[0][0]               \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 50, 151)      0           embedding_25[1][0]               \n",
      "                                                                 reshape_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 50, 151)      0           concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 50, 151)      0           concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 50, 64)       0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 50, 64)       0           conv1d_22[1][0]                  \n",
      "                                                                 conv1d_25[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 50, 64)       4160        multiply_25[0][0]                \n",
      "                                                                 multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 50, 64)       0           conv1d_19[0][0]                  \n",
      "                                                                 conv1d_19[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_109 (Dot)                   (None, 50, 50)       0           dropout_79[0][0]                 \n",
      "                                                                 dropout_79[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 50, 50)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_37 (Permute)            (None, 50, 50)       0           lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 50, 50)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_111 (Dot)                   (None, 50, 64)       0           permute_37[0][0]                 \n",
      "                                                                 dropout_79[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_110 (Dot)                   (None, 50, 64)       0           lambda_85[0][0]                  \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 50, 279)      0           dropout_79[0][0]                 \n",
      "                                                                 dot_111[0][0]                    \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 50, 279)      0           dropout_79[1][0]                 \n",
      "                                                                 dot_110[0][0]                    \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 50, 64)       53632       concatenate_155[0][0]            \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 50, 64)       53632       concatenate_155[0][0]            \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 50, 64)       0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 50, 64)       0           conv1d_23[1][0]                  \n",
      "                                                                 conv1d_26[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 50, 64)       4160        multiply_27[0][0]                \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 50, 64)       0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_20[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_112 (Dot)                   (None, 50, 50)       0           dropout_80[0][0]                 \n",
      "                                                                 dropout_80[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 50, 50)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_38 (Permute)            (None, 50, 50)       0           lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 50, 50)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_114 (Dot)                   (None, 50, 64)       0           permute_38[0][0]                 \n",
      "                                                                 dropout_80[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_113 (Dot)                   (None, 50, 64)       0           lambda_87[0][0]                  \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 50, 407)      0           dropout_80[0][0]                 \n",
      "                                                                 dot_114[0][0]                    \n",
      "                                                                 concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 50, 407)      0           dropout_80[1][0]                 \n",
      "                                                                 dot_113[0][0]                    \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 50, 64)       78208       concatenate_157[0][0]            \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 50, 64)       78208       concatenate_157[0][0]            \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 50, 64)       0           conv1d_24[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 50, 64)       0           conv1d_24[1][0]                  \n",
      "                                                                 conv1d_27[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 50, 64)       4160        multiply_29[0][0]                \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 50, 64)       0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_21[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_115 (Dot)                   (None, 50, 50)       0           dropout_81[0][0]                 \n",
      "                                                                 dropout_81[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_39 (Permute)            (None, 50, 50)       0           lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_117 (Dot)                   (None, 50, 64)       0           permute_39[0][0]                 \n",
      "                                                                 dropout_81[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_116 (Dot)                   (None, 50, 64)       0           lambda_89[0][0]                  \n",
      "                                                                 dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 50, 535)      0           dropout_81[0][0]                 \n",
      "                                                                 dot_117[0][0]                    \n",
      "                                                                 concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 50, 535)      0           dropout_81[1][0]                 \n",
      "                                                                 dot_116[0][0]                    \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 535)          0           concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 535)          0           concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 535)          535         concatenate_159[0][0]            \n",
      "                                                                 concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 535)          0           concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 535)          0           concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 1605)         0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 1605)         0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "                                                                 attention_weighted_average_3[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 1605)         0           concatenate_161[0][0]            \n",
      "                                                                 concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 1605)         0           concatenate_161[0][0]            \n",
      "                                                                 concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 6420)         0           concatenate_161[0][0]            \n",
      "                                                                 concatenate_162[0][0]            \n",
      "                                                                 lambda_91[0][0]                  \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 6420)         0           concatenate_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6420)         25680       dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64)           410944      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 3)            195         dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.0231 - acc: 0.8714 - weighted_accuracy: 0.8650 - val_loss: 0.3253 - val_acc: 0.8493 - val_weighted_accuracy: 0.8436\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0233 - acc: 0.8707 - weighted_accuracy: 0.8644 - val_loss: 0.3288 - val_acc: 0.8490 - val_weighted_accuracy: 0.8448\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0232 - acc: 0.8733 - weighted_accuracy: 0.8674 - val_loss: 0.3208 - val_acc: 0.8524 - val_weighted_accuracy: 0.8394\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0230 - acc: 0.8744 - weighted_accuracy: 0.8687 - val_loss: 0.3213 - val_acc: 0.8530 - val_weighted_accuracy: 0.8452\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0227 - acc: 0.8761 - weighted_accuracy: 0.8710 - val_loss: 0.3142 - val_acc: 0.8572 - val_weighted_accuracy: 0.8469\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0226 - acc: 0.8779 - weighted_accuracy: 0.8727 - val_loss: 0.3131 - val_acc: 0.8558 - val_weighted_accuracy: 0.8450\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0225 - acc: 0.8784 - weighted_accuracy: 0.8732 - val_loss: 0.3072 - val_acc: 0.8617 - val_weighted_accuracy: 0.8504\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0223 - acc: 0.8787 - weighted_accuracy: 0.8736 - val_loss: 0.3134 - val_acc: 0.8601 - val_weighted_accuracy: 0.8502\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0221 - acc: 0.8805 - weighted_accuracy: 0.8757 - val_loss: 0.3165 - val_acc: 0.8539 - val_weighted_accuracy: 0.8456\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0221 - acc: 0.8804 - weighted_accuracy: 0.8757 - val_loss: 0.3222 - val_acc: 0.8526 - val_weighted_accuracy: 0.8478\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0220 - acc: 0.8809 - weighted_accuracy: 0.8760 - val_loss: 0.3112 - val_acc: 0.8579 - val_weighted_accuracy: 0.8490\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0219 - acc: 0.8811 - weighted_accuracy: 0.8765 - val_loss: 0.3133 - val_acc: 0.8585 - val_weighted_accuracy: 0.8490\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0217 - acc: 0.8828 - weighted_accuracy: 0.8780 - val_loss: 0.3090 - val_acc: 0.8608 - val_weighted_accuracy: 0.8513\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0217 - acc: 0.8824 - weighted_accuracy: 0.8777 - val_loss: 0.3072 - val_acc: 0.8631 - val_weighted_accuracy: 0.8530\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0215 - acc: 0.8840 - weighted_accuracy: 0.8794 - val_loss: 0.3083 - val_acc: 0.8598 - val_weighted_accuracy: 0.8481\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0215 - acc: 0.8833 - weighted_accuracy: 0.8786 - val_loss: 0.3047 - val_acc: 0.8643 - val_weighted_accuracy: 0.8512\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0215 - acc: 0.8836 - weighted_accuracy: 0.8793 - val_loss: 0.3078 - val_acc: 0.8604 - val_weighted_accuracy: 0.8470\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0214 - acc: 0.8845 - weighted_accuracy: 0.8802 - val_loss: 0.3043 - val_acc: 0.8626 - val_weighted_accuracy: 0.8515\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0213 - acc: 0.8846 - weighted_accuracy: 0.8800 - val_loss: 0.3064 - val_acc: 0.8599 - val_weighted_accuracy: 0.8519\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0212 - acc: 0.8855 - weighted_accuracy: 0.8813 - val_loss: 0.3029 - val_acc: 0.8617 - val_weighted_accuracy: 0.8522\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0212 - acc: 0.8854 - weighted_accuracy: 0.8811 - val_loss: 0.3034 - val_acc: 0.8620 - val_weighted_accuracy: 0.8487\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0211 - acc: 0.8861 - weighted_accuracy: 0.8815 - val_loss: 0.3051 - val_acc: 0.8626 - val_weighted_accuracy: 0.8524\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0212 - acc: 0.8856 - weighted_accuracy: 0.8813 - val_loss: 0.3051 - val_acc: 0.8636 - val_weighted_accuracy: 0.8546\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0211 - acc: 0.8857 - weighted_accuracy: 0.8816 - val_loss: 0.3145 - val_acc: 0.8579 - val_weighted_accuracy: 0.8474\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0210 - acc: 0.8863 - weighted_accuracy: 0.8823 - val_loss: 0.3133 - val_acc: 0.8572 - val_weighted_accuracy: 0.8504\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0210 - acc: 0.8861 - weighted_accuracy: 0.8819 - val_loss: 0.3065 - val_acc: 0.8606 - val_weighted_accuracy: 0.8506\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0209 - acc: 0.8867 - weighted_accuracy: 0.8827 - val_loss: 0.3044 - val_acc: 0.8643 - val_weighted_accuracy: 0.8537\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0210 - acc: 0.8860 - weighted_accuracy: 0.8815 - val_loss: 0.3092 - val_acc: 0.8605 - val_weighted_accuracy: 0.8528\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0209 - acc: 0.8870 - weighted_accuracy: 0.8827 - val_loss: 0.3073 - val_acc: 0.8621 - val_weighted_accuracy: 0.8534\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0209 - acc: 0.8873 - weighted_accuracy: 0.8832 - val_loss: 0.3092 - val_acc: 0.8597 - val_weighted_accuracy: 0.8542\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0209 - acc: 0.8871 - weighted_accuracy: 0.8829 - val_loss: 0.3080 - val_acc: 0.8592 - val_weighted_accuracy: 0.8512\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0208 - acc: 0.8877 - weighted_accuracy: 0.8837 - val_loss: 0.3108 - val_acc: 0.8616 - val_weighted_accuracy: 0.8539\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0208 - acc: 0.8876 - weighted_accuracy: 0.8837 - val_loss: 0.3140 - val_acc: 0.8569 - val_weighted_accuracy: 0.8446\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 50, 151)      0           embedding_27[0][0]               \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 50, 151)      0           embedding_27[1][0]               \n",
      "                                                                 reshape_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 50, 151)      0           concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 50, 151)      0           concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 50, 64)       0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 50, 64)       0           conv1d_31[1][0]                  \n",
      "                                                                 conv1d_34[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 50, 64)       4160        multiply_32[0][0]                \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 50, 64)       0           conv1d_28[0][0]                  \n",
      "                                                                 conv1d_28[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_118 (Dot)                   (None, 50, 50)       0           dropout_83[0][0]                 \n",
      "                                                                 dropout_83[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_40 (Permute)            (None, 50, 50)       0           lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_120 (Dot)                   (None, 50, 64)       0           permute_40[0][0]                 \n",
      "                                                                 dropout_83[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_119 (Dot)                   (None, 50, 64)       0           lambda_92[0][0]                  \n",
      "                                                                 dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 50, 279)      0           dropout_83[0][0]                 \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 spatial_dropout1d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 50, 279)      0           dropout_83[1][0]                 \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 50, 64)       53632       concatenate_166[0][0]            \n",
      "                                                                 concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 50, 64)       53632       concatenate_166[0][0]            \n",
      "                                                                 concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 50, 64)       0           conv1d_32[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 50, 64)       0           conv1d_32[1][0]                  \n",
      "                                                                 conv1d_35[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 50, 64)       4160        multiply_34[0][0]                \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 50, 64)       0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_29[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_121 (Dot)                   (None, 50, 50)       0           dropout_84[0][0]                 \n",
      "                                                                 dropout_84[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_41 (Permute)            (None, 50, 50)       0           lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_123 (Dot)                   (None, 50, 64)       0           permute_41[0][0]                 \n",
      "                                                                 dropout_84[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_122 (Dot)                   (None, 50, 64)       0           lambda_94[0][0]                  \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 50, 407)      0           dropout_84[0][0]                 \n",
      "                                                                 dot_123[0][0]                    \n",
      "                                                                 concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 50, 407)      0           dropout_84[1][0]                 \n",
      "                                                                 dot_122[0][0]                    \n",
      "                                                                 concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 50, 64)       78208       concatenate_168[0][0]            \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 50, 64)       78208       concatenate_168[0][0]            \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 50, 64)       0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 50, 64)       0           conv1d_33[1][0]                  \n",
      "                                                                 conv1d_36[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 50, 64)       4160        multiply_36[0][0]                \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 50, 64)       0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_30[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_124 (Dot)                   (None, 50, 50)       0           dropout_85[0][0]                 \n",
      "                                                                 dropout_85[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 50, 50)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_42 (Permute)            (None, 50, 50)       0           lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 50, 50)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_126 (Dot)                   (None, 50, 64)       0           permute_42[0][0]                 \n",
      "                                                                 dropout_85[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_125 (Dot)                   (None, 50, 64)       0           lambda_96[0][0]                  \n",
      "                                                                 dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 50, 535)      0           dropout_85[0][0]                 \n",
      "                                                                 dot_126[0][0]                    \n",
      "                                                                 concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 50, 535)      0           dropout_85[1][0]                 \n",
      "                                                                 dot_125[0][0]                    \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 535)          0           concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 535)          0           concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_4 (A (None, 535)          535         concatenate_170[0][0]            \n",
      "                                                                 concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 535)          0           concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 535)          0           concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 1605)         0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "                                                                 attention_weighted_average_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 1605)         0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "                                                                 attention_weighted_average_4[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 1605)         0           concatenate_172[0][0]            \n",
      "                                                                 concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 1605)         0           concatenate_172[0][0]            \n",
      "                                                                 concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 6420)         0           concatenate_172[0][0]            \n",
      "                                                                 concatenate_173[0][0]            \n",
      "                                                                 lambda_98[0][0]                  \n",
      "                                                                 multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 6420)         0           concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6420)         25680       dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 64)           410944      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 3)            195         dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0229 - acc: 0.8751 - weighted_accuracy: 0.8690 - val_loss: 0.3194 - val_acc: 0.8581 - val_weighted_accuracy: 0.8498\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0231 - acc: 0.8740 - weighted_accuracy: 0.8679 - val_loss: 0.3107 - val_acc: 0.8614 - val_weighted_accuracy: 0.8479\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0231 - acc: 0.8750 - weighted_accuracy: 0.8690 - val_loss: 0.3208 - val_acc: 0.8567 - val_weighted_accuracy: 0.8501\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0230 - acc: 0.8764 - weighted_accuracy: 0.8705 - val_loss: 0.3017 - val_acc: 0.8650 - val_weighted_accuracy: 0.8481\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0228 - acc: 0.8772 - weighted_accuracy: 0.8717 - val_loss: 0.3103 - val_acc: 0.8612 - val_weighted_accuracy: 0.8499\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0226 - acc: 0.8782 - weighted_accuracy: 0.8728 - val_loss: 0.3203 - val_acc: 0.8555 - val_weighted_accuracy: 0.8473\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0225 - acc: 0.8783 - weighted_accuracy: 0.8732 - val_loss: 0.3169 - val_acc: 0.8599 - val_weighted_accuracy: 0.8515\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.0224 - acc: 0.8792 - weighted_accuracy: 0.8743 - val_loss: 0.3003 - val_acc: 0.8666 - val_weighted_accuracy: 0.8512\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.0222 - acc: 0.8798 - weighted_accuracy: 0.8749 - val_loss: 0.3052 - val_acc: 0.8637 - val_weighted_accuracy: 0.8526\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.0221 - acc: 0.8804 - weighted_accuracy: 0.8757 - val_loss: 0.3024 - val_acc: 0.8652 - val_weighted_accuracy: 0.8518\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.0220 - acc: 0.8822 - weighted_accuracy: 0.8777 - val_loss: 0.3176 - val_acc: 0.8569 - val_weighted_accuracy: 0.8473\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0219 - acc: 0.8820 - weighted_accuracy: 0.8773 - val_loss: 0.3046 - val_acc: 0.8635 - val_weighted_accuracy: 0.8529\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0219 - acc: 0.8820 - weighted_accuracy: 0.8772 - val_loss: 0.3060 - val_acc: 0.8626 - val_weighted_accuracy: 0.8493\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.0218 - acc: 0.8827 - weighted_accuracy: 0.8782 - val_loss: 0.2991 - val_acc: 0.8663 - val_weighted_accuracy: 0.8504\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0217 - acc: 0.8834 - weighted_accuracy: 0.8792 - val_loss: 0.3102 - val_acc: 0.8595 - val_weighted_accuracy: 0.8508\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.0216 - acc: 0.8834 - weighted_accuracy: 0.8789 - val_loss: 0.3017 - val_acc: 0.8676 - val_weighted_accuracy: 0.8514\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0215 - acc: 0.8839 - weighted_accuracy: 0.8795 - val_loss: 0.3153 - val_acc: 0.8600 - val_weighted_accuracy: 0.8548\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0215 - acc: 0.8842 - weighted_accuracy: 0.8799 - val_loss: 0.3016 - val_acc: 0.8640 - val_weighted_accuracy: 0.8534\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0214 - acc: 0.8844 - weighted_accuracy: 0.8804 - val_loss: 0.3016 - val_acc: 0.8657 - val_weighted_accuracy: 0.8554\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0214 - acc: 0.8844 - weighted_accuracy: 0.8801 - val_loss: 0.3027 - val_acc: 0.8624 - val_weighted_accuracy: 0.8487\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0213 - acc: 0.8849 - weighted_accuracy: 0.8804 - val_loss: 0.3021 - val_acc: 0.8651 - val_weighted_accuracy: 0.8545\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 120s 332us/step - loss: 0.0212 - acc: 0.8855 - weighted_accuracy: 0.8816 - val_loss: 0.2970 - val_acc: 0.8660 - val_weighted_accuracy: 0.8535\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.0212 - acc: 0.8857 - weighted_accuracy: 0.8816 - val_loss: 0.3045 - val_acc: 0.8636 - val_weighted_accuracy: 0.8525\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0212 - acc: 0.8859 - weighted_accuracy: 0.8818 - val_loss: 0.3001 - val_acc: 0.8666 - val_weighted_accuracy: 0.8528\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0211 - acc: 0.8862 - weighted_accuracy: 0.8823 - val_loss: 0.2997 - val_acc: 0.8631 - val_weighted_accuracy: 0.8545\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0210 - acc: 0.8868 - weighted_accuracy: 0.8830 - val_loss: 0.2975 - val_acc: 0.8662 - val_weighted_accuracy: 0.8556\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0211 - acc: 0.8862 - weighted_accuracy: 0.8823 - val_loss: 0.3069 - val_acc: 0.8610 - val_weighted_accuracy: 0.8504\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0210 - acc: 0.8867 - weighted_accuracy: 0.8827 - val_loss: 0.3080 - val_acc: 0.8628 - val_weighted_accuracy: 0.8558\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0210 - acc: 0.8863 - weighted_accuracy: 0.8827 - val_loss: 0.3067 - val_acc: 0.8623 - val_weighted_accuracy: 0.8552\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8866 - weighted_accuracy: 0.8828 - val_loss: 0.3018 - val_acc: 0.8638 - val_weighted_accuracy: 0.8554\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8878 - weighted_accuracy: 0.8838 - val_loss: 0.3041 - val_acc: 0.8639 - val_weighted_accuracy: 0.8546\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8869 - weighted_accuracy: 0.8833 - val_loss: 0.3012 - val_acc: 0.8651 - val_weighted_accuracy: 0.8512\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8866 - weighted_accuracy: 0.8829 - val_loss: 0.3047 - val_acc: 0.8614 - val_weighted_accuracy: 0.8517\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0208 - acc: 0.8884 - weighted_accuracy: 0.8848 - val_loss: 0.3054 - val_acc: 0.8602 - val_weighted_accuracy: 0.8496\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0207 - acc: 0.8878 - weighted_accuracy: 0.8844 - val_loss: 0.3039 - val_acc: 0.8629 - val_weighted_accuracy: 0.8487\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0207 - acc: 0.8877 - weighted_accuracy: 0.8841 - val_loss: 0.3068 - val_acc: 0.8630 - val_weighted_accuracy: 0.8558\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0207 - acc: 0.8881 - weighted_accuracy: 0.8847 - val_loss: 0.3052 - val_acc: 0.8629 - val_weighted_accuracy: 0.8479\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0207 - acc: 0.8880 - weighted_accuracy: 0.8842 - val_loss: 0.3035 - val_acc: 0.8637 - val_weighted_accuracy: 0.8569\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0206 - acc: 0.8887 - weighted_accuracy: 0.8850 - val_loss: 0.3003 - val_acc: 0.8643 - val_weighted_accuracy: 0.8558\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0206 - acc: 0.8885 - weighted_accuracy: 0.8848 - val_loss: 0.2955 - val_acc: 0.8701 - val_weighted_accuracy: 0.8581\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0207 - acc: 0.8884 - weighted_accuracy: 0.8847 - val_loss: 0.2948 - val_acc: 0.8701 - val_weighted_accuracy: 0.8526\n",
      "Epoch 42/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0206 - acc: 0.8881 - weighted_accuracy: 0.8845 - val_loss: 0.2968 - val_acc: 0.8681 - val_weighted_accuracy: 0.8579\n",
      "Epoch 43/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0206 - acc: 0.8885 - weighted_accuracy: 0.8848 - val_loss: 0.3052 - val_acc: 0.8617 - val_weighted_accuracy: 0.8469\n",
      "Epoch 44/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0206 - acc: 0.8886 - weighted_accuracy: 0.8849 - val_loss: 0.2970 - val_acc: 0.8669 - val_weighted_accuracy: 0.8549\n",
      "Epoch 45/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0206 - acc: 0.8887 - weighted_accuracy: 0.8853 - val_loss: 0.3029 - val_acc: 0.8627 - val_weighted_accuracy: 0.8533\n",
      "Epoch 46/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0205 - acc: 0.8890 - weighted_accuracy: 0.8858 - val_loss: 0.2946 - val_acc: 0.8680 - val_weighted_accuracy: 0.8569\n",
      "Epoch 47/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0205 - acc: 0.8892 - weighted_accuracy: 0.8860 - val_loss: 0.2985 - val_acc: 0.8669 - val_weighted_accuracy: 0.8568\n",
      "Epoch 48/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0205 - acc: 0.8890 - weighted_accuracy: 0.8855 - val_loss: 0.2968 - val_acc: 0.8665 - val_weighted_accuracy: 0.8540\n",
      "Epoch 49/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0205 - acc: 0.8900 - weighted_accuracy: 0.8864 - val_loss: 0.2949 - val_acc: 0.8686 - val_weighted_accuracy: 0.8574\n",
      "Epoch 50/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0204 - acc: 0.8896 - weighted_accuracy: 0.8862 - val_loss: 0.2999 - val_acc: 0.8647 - val_weighted_accuracy: 0.8505\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 50, 151)      0           embedding_29[0][0]               \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 50, 151)      0           embedding_29[1][0]               \n",
      "                                                                 reshape_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 50, 151)      0           concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 50, 151)      0           concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 50, 64)       0           conv1d_40[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 50, 64)       0           conv1d_40[1][0]                  \n",
      "                                                                 conv1d_43[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 50, 64)       4160        multiply_39[0][0]                \n",
      "                                                                 multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 50, 64)       0           conv1d_37[0][0]                  \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_127 (Dot)                   (None, 50, 50)       0           dropout_87[0][0]                 \n",
      "                                                                 dropout_87[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 50, 50)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_43 (Permute)            (None, 50, 50)       0           lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 50, 50)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_129 (Dot)                   (None, 50, 64)       0           permute_43[0][0]                 \n",
      "                                                                 dropout_87[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_128 (Dot)                   (None, 50, 64)       0           lambda_99[0][0]                  \n",
      "                                                                 dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 50, 279)      0           dropout_87[0][0]                 \n",
      "                                                                 dot_129[0][0]                    \n",
      "                                                                 spatial_dropout1d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 50, 279)      0           dropout_87[1][0]                 \n",
      "                                                                 dot_128[0][0]                    \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 50, 64)       53632       concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 50, 64)       53632       concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 50, 64)       0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 50, 64)       0           conv1d_41[1][0]                  \n",
      "                                                                 conv1d_44[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 50, 64)       4160        multiply_41[0][0]                \n",
      "                                                                 multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 50, 64)       0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_130 (Dot)                   (None, 50, 50)       0           dropout_88[0][0]                 \n",
      "                                                                 dropout_88[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 50, 50)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_44 (Permute)            (None, 50, 50)       0           lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 50, 50)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_132 (Dot)                   (None, 50, 64)       0           permute_44[0][0]                 \n",
      "                                                                 dropout_88[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_131 (Dot)                   (None, 50, 64)       0           lambda_101[0][0]                 \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 50, 407)      0           dropout_88[0][0]                 \n",
      "                                                                 dot_132[0][0]                    \n",
      "                                                                 concatenate_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 50, 407)      0           dropout_88[1][0]                 \n",
      "                                                                 dot_131[0][0]                    \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 50, 64)       78208       concatenate_179[0][0]            \n",
      "                                                                 concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 50, 64)       78208       concatenate_179[0][0]            \n",
      "                                                                 concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 50, 64)       0           conv1d_42[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 50, 64)       0           conv1d_42[1][0]                  \n",
      "                                                                 conv1d_45[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 50, 64)       4160        multiply_43[0][0]                \n",
      "                                                                 multiply_44[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 50, 64)       0           conv1d_39[0][0]                  \n",
      "                                                                 conv1d_39[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_133 (Dot)                   (None, 50, 50)       0           dropout_89[0][0]                 \n",
      "                                                                 dropout_89[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 50, 50)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_45 (Permute)            (None, 50, 50)       0           lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 50, 50)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_135 (Dot)                   (None, 50, 64)       0           permute_45[0][0]                 \n",
      "                                                                 dropout_89[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_134 (Dot)                   (None, 50, 64)       0           lambda_103[0][0]                 \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 50, 535)      0           dropout_89[0][0]                 \n",
      "                                                                 dot_135[0][0]                    \n",
      "                                                                 concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 50, 535)      0           dropout_89[1][0]                 \n",
      "                                                                 dot_134[0][0]                    \n",
      "                                                                 concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 535)          0           concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 535)          0           concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_5 (A (None, 535)          535         concatenate_181[0][0]            \n",
      "                                                                 concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 535)          0           concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 535)          0           concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 1605)         0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "                                                                 attention_weighted_average_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 1605)         0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "                                                                 attention_weighted_average_5[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 1605)         0           concatenate_183[0][0]            \n",
      "                                                                 concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 1605)         0           concatenate_183[0][0]            \n",
      "                                                                 concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 6420)         0           concatenate_183[0][0]            \n",
      "                                                                 concatenate_184[0][0]            \n",
      "                                                                 lambda_105[0][0]                 \n",
      "                                                                 multiply_45[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 6420)         0           concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6420)         25680       dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 64)           410944      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 3)            195         dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 128s 354us/step - loss: 0.0225 - acc: 0.8795 - weighted_accuracy: 0.8740 - val_loss: 0.3434 - val_acc: 0.8414 - val_weighted_accuracy: 0.8342\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0229 - acc: 0.8771 - weighted_accuracy: 0.8712 - val_loss: 0.3317 - val_acc: 0.8468 - val_weighted_accuracy: 0.8338\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0229 - acc: 0.8785 - weighted_accuracy: 0.8727 - val_loss: 0.3181 - val_acc: 0.8542 - val_weighted_accuracy: 0.8382\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0228 - acc: 0.8780 - weighted_accuracy: 0.8719 - val_loss: 0.3190 - val_acc: 0.8530 - val_weighted_accuracy: 0.8404\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0227 - acc: 0.8789 - weighted_accuracy: 0.8735 - val_loss: 0.3218 - val_acc: 0.8512 - val_weighted_accuracy: 0.8368\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0226 - acc: 0.8793 - weighted_accuracy: 0.8737 - val_loss: 0.3249 - val_acc: 0.8480 - val_weighted_accuracy: 0.8391\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0224 - acc: 0.8805 - weighted_accuracy: 0.8752 - val_loss: 0.3227 - val_acc: 0.8504 - val_weighted_accuracy: 0.8433\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0223 - acc: 0.8807 - weighted_accuracy: 0.8755 - val_loss: 0.3282 - val_acc: 0.8479 - val_weighted_accuracy: 0.8400\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.0222 - acc: 0.8815 - weighted_accuracy: 0.8766 - val_loss: 0.3204 - val_acc: 0.8515 - val_weighted_accuracy: 0.8343\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.0221 - acc: 0.8818 - weighted_accuracy: 0.8766 - val_loss: 0.3301 - val_acc: 0.8446 - val_weighted_accuracy: 0.8312\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0220 - acc: 0.8824 - weighted_accuracy: 0.8774 - val_loss: 0.3219 - val_acc: 0.8488 - val_weighted_accuracy: 0.8403\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0218 - acc: 0.8832 - weighted_accuracy: 0.8782 - val_loss: 0.3248 - val_acc: 0.8494 - val_weighted_accuracy: 0.8387\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0218 - acc: 0.8833 - weighted_accuracy: 0.8785 - val_loss: 0.3294 - val_acc: 0.8471 - val_weighted_accuracy: 0.8385\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0217 - acc: 0.8841 - weighted_accuracy: 0.8794 - val_loss: 0.3200 - val_acc: 0.8532 - val_weighted_accuracy: 0.8428\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0217 - acc: 0.8833 - weighted_accuracy: 0.8788 - val_loss: 0.3170 - val_acc: 0.8509 - val_weighted_accuracy: 0.8367\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0216 - acc: 0.8851 - weighted_accuracy: 0.8804 - val_loss: 0.3201 - val_acc: 0.8506 - val_weighted_accuracy: 0.8410\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0215 - acc: 0.8848 - weighted_accuracy: 0.8803 - val_loss: 0.3185 - val_acc: 0.8523 - val_weighted_accuracy: 0.8393\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 50, 151)      0           embedding_31[0][0]               \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 50, 151)      0           embedding_31[1][0]               \n",
      "                                                                 reshape_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 50, 151)      0           concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 50, 151)      0           concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 50, 64)       0           conv1d_49[0][0]                  \n",
      "                                                                 conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 50, 64)       0           conv1d_49[1][0]                  \n",
      "                                                                 conv1d_52[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 50, 64)       4160        multiply_46[0][0]                \n",
      "                                                                 multiply_47[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 50, 64)       0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_46[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_136 (Dot)                   (None, 50, 50)       0           dropout_91[0][0]                 \n",
      "                                                                 dropout_91[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 50, 50)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_46 (Permute)            (None, 50, 50)       0           lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 50, 50)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_138 (Dot)                   (None, 50, 64)       0           permute_46[0][0]                 \n",
      "                                                                 dropout_91[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_137 (Dot)                   (None, 50, 64)       0           lambda_106[0][0]                 \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 50, 279)      0           dropout_91[0][0]                 \n",
      "                                                                 dot_138[0][0]                    \n",
      "                                                                 spatial_dropout1d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 50, 279)      0           dropout_91[1][0]                 \n",
      "                                                                 dot_137[0][0]                    \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 50, 64)       53632       concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 50, 64)       53632       concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 50, 64)       0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 50, 64)       0           conv1d_50[1][0]                  \n",
      "                                                                 conv1d_53[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 50, 64)       4160        multiply_48[0][0]                \n",
      "                                                                 multiply_49[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 50, 64)       0           conv1d_47[0][0]                  \n",
      "                                                                 conv1d_47[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_139 (Dot)                   (None, 50, 50)       0           dropout_92[0][0]                 \n",
      "                                                                 dropout_92[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 50, 50)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_47 (Permute)            (None, 50, 50)       0           lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 50, 50)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_141 (Dot)                   (None, 50, 64)       0           permute_47[0][0]                 \n",
      "                                                                 dropout_92[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_140 (Dot)                   (None, 50, 64)       0           lambda_108[0][0]                 \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 50, 407)      0           dropout_92[0][0]                 \n",
      "                                                                 dot_141[0][0]                    \n",
      "                                                                 concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 50, 407)      0           dropout_92[1][0]                 \n",
      "                                                                 dot_140[0][0]                    \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 50, 64)       78208       concatenate_190[0][0]            \n",
      "                                                                 concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 50, 64)       78208       concatenate_190[0][0]            \n",
      "                                                                 concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 50, 64)       0           conv1d_51[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 50, 64)       0           conv1d_51[1][0]                  \n",
      "                                                                 conv1d_54[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 50, 64)       4160        multiply_50[0][0]                \n",
      "                                                                 multiply_51[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 50, 64)       0           conv1d_48[0][0]                  \n",
      "                                                                 conv1d_48[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_142 (Dot)                   (None, 50, 50)       0           dropout_93[0][0]                 \n",
      "                                                                 dropout_93[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 50, 50)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_48 (Permute)            (None, 50, 50)       0           lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 50, 50)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_144 (Dot)                   (None, 50, 64)       0           permute_48[0][0]                 \n",
      "                                                                 dropout_93[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_143 (Dot)                   (None, 50, 64)       0           lambda_110[0][0]                 \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 50, 535)      0           dropout_93[0][0]                 \n",
      "                                                                 dot_144[0][0]                    \n",
      "                                                                 concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 50, 535)      0           dropout_93[1][0]                 \n",
      "                                                                 dot_143[0][0]                    \n",
      "                                                                 concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 535)          0           concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 535)          0           concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_6 (A (None, 535)          535         concatenate_192[0][0]            \n",
      "                                                                 concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 535)          0           concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 535)          0           concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 1605)         0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "                                                                 attention_weighted_average_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_195 (Concatenate)   (None, 1605)         0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "                                                                 attention_weighted_average_6[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 1605)         0           concatenate_194[0][0]            \n",
      "                                                                 concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 1605)         0           concatenate_194[0][0]            \n",
      "                                                                 concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_196 (Concatenate)   (None, 6420)         0           concatenate_194[0][0]            \n",
      "                                                                 concatenate_195[0][0]            \n",
      "                                                                 lambda_112[0][0]                 \n",
      "                                                                 multiply_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 6420)         0           concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6420)         25680       dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 64)           410944      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 3)            195         dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.0228 - acc: 0.8744 - weighted_accuracy: 0.8680 - val_loss: 0.3337 - val_acc: 0.8464 - val_weighted_accuracy: 0.8308\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0231 - acc: 0.8736 - weighted_accuracy: 0.8673 - val_loss: 0.3431 - val_acc: 0.8391 - val_weighted_accuracy: 0.8237\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0230 - acc: 0.8749 - weighted_accuracy: 0.8691 - val_loss: 0.3404 - val_acc: 0.8409 - val_weighted_accuracy: 0.8295\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0229 - acc: 0.8760 - weighted_accuracy: 0.8705 - val_loss: 0.3414 - val_acc: 0.8406 - val_weighted_accuracy: 0.8294\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0226 - acc: 0.8780 - weighted_accuracy: 0.8725 - val_loss: 0.3350 - val_acc: 0.8437 - val_weighted_accuracy: 0.8269\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0225 - acc: 0.8792 - weighted_accuracy: 0.8739 - val_loss: 0.3339 - val_acc: 0.8455 - val_weighted_accuracy: 0.8307\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0224 - acc: 0.8800 - weighted_accuracy: 0.8745 - val_loss: 0.3300 - val_acc: 0.8475 - val_weighted_accuracy: 0.8293\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0222 - acc: 0.8803 - weighted_accuracy: 0.8749 - val_loss: 0.3346 - val_acc: 0.8468 - val_weighted_accuracy: 0.8284\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0221 - acc: 0.8807 - weighted_accuracy: 0.8755 - val_loss: 0.3307 - val_acc: 0.8482 - val_weighted_accuracy: 0.8336\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0220 - acc: 0.8816 - weighted_accuracy: 0.8764 - val_loss: 0.3261 - val_acc: 0.8528 - val_weighted_accuracy: 0.8349\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0219 - acc: 0.8819 - weighted_accuracy: 0.8770 - val_loss: 0.3358 - val_acc: 0.8462 - val_weighted_accuracy: 0.8319\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0218 - acc: 0.8828 - weighted_accuracy: 0.8779 - val_loss: 0.3350 - val_acc: 0.8424 - val_weighted_accuracy: 0.8260\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0217 - acc: 0.8839 - weighted_accuracy: 0.8795 - val_loss: 0.3314 - val_acc: 0.8472 - val_weighted_accuracy: 0.8332\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0216 - acc: 0.8836 - weighted_accuracy: 0.8789 - val_loss: 0.3288 - val_acc: 0.8497 - val_weighted_accuracy: 0.8301\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0216 - acc: 0.8837 - weighted_accuracy: 0.8790 - val_loss: 0.3275 - val_acc: 0.8486 - val_weighted_accuracy: 0.8315\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0214 - acc: 0.8839 - weighted_accuracy: 0.8794 - val_loss: 0.3324 - val_acc: 0.8466 - val_weighted_accuracy: 0.8286\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0214 - acc: 0.8852 - weighted_accuracy: 0.8808 - val_loss: 0.3394 - val_acc: 0.8404 - val_weighted_accuracy: 0.8238\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0214 - acc: 0.8851 - weighted_accuracy: 0.8807 - val_loss: 0.3336 - val_acc: 0.8459 - val_weighted_accuracy: 0.8250\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0213 - acc: 0.8852 - weighted_accuracy: 0.8809 - val_loss: 0.3328 - val_acc: 0.8415 - val_weighted_accuracy: 0.8286\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 120s 333us/step - loss: 0.0212 - acc: 0.8863 - weighted_accuracy: 0.8822 - val_loss: 0.3440 - val_acc: 0.8373 - val_weighted_accuracy: 0.8131\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_197 (Concatenate)   (None, 50, 151)      0           embedding_33[0][0]               \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 50, 151)      0           embedding_33[1][0]               \n",
      "                                                                 reshape_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, 50, 151)      0           concatenate_197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, 50, 151)      0           concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 50, 64)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 50, 64)       0           conv1d_58[1][0]                  \n",
      "                                                                 conv1d_61[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 50, 64)       4160        multiply_53[0][0]                \n",
      "                                                                 multiply_54[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 50, 64)       0           conv1d_55[0][0]                  \n",
      "                                                                 conv1d_55[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_145 (Dot)                   (None, 50, 50)       0           dropout_95[0][0]                 \n",
      "                                                                 dropout_95[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 50, 50)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_49 (Permute)            (None, 50, 50)       0           lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 50, 50)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_147 (Dot)                   (None, 50, 64)       0           permute_49[0][0]                 \n",
      "                                                                 dropout_95[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_146 (Dot)                   (None, 50, 64)       0           lambda_113[0][0]                 \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 50, 279)      0           dropout_95[0][0]                 \n",
      "                                                                 dot_147[0][0]                    \n",
      "                                                                 spatial_dropout1d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 50, 279)      0           dropout_95[1][0]                 \n",
      "                                                                 dot_146[0][0]                    \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 50, 64)       53632       concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 50, 64)       53632       concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 50, 64)       0           conv1d_59[0][0]                  \n",
      "                                                                 conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 50, 64)       0           conv1d_59[1][0]                  \n",
      "                                                                 conv1d_62[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 50, 64)       4160        multiply_55[0][0]                \n",
      "                                                                 multiply_56[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 50, 64)       0           conv1d_56[0][0]                  \n",
      "                                                                 conv1d_56[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_148 (Dot)                   (None, 50, 50)       0           dropout_96[0][0]                 \n",
      "                                                                 dropout_96[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 50, 50)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_50 (Permute)            (None, 50, 50)       0           lambda_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 50, 50)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_150 (Dot)                   (None, 50, 64)       0           permute_50[0][0]                 \n",
      "                                                                 dropout_96[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_149 (Dot)                   (None, 50, 64)       0           lambda_115[0][0]                 \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_201 (Concatenate)   (None, 50, 407)      0           dropout_96[0][0]                 \n",
      "                                                                 dot_150[0][0]                    \n",
      "                                                                 concatenate_199[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_202 (Concatenate)   (None, 50, 407)      0           dropout_96[1][0]                 \n",
      "                                                                 dot_149[0][0]                    \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 50, 64)       78208       concatenate_201[0][0]            \n",
      "                                                                 concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 50, 64)       78208       concatenate_201[0][0]            \n",
      "                                                                 concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 50, 64)       0           conv1d_60[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 50, 64)       0           conv1d_60[1][0]                  \n",
      "                                                                 conv1d_63[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 50, 64)       4160        multiply_57[0][0]                \n",
      "                                                                 multiply_58[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 50, 64)       0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_151 (Dot)                   (None, 50, 50)       0           dropout_97[0][0]                 \n",
      "                                                                 dropout_97[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 50, 50)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_51 (Permute)            (None, 50, 50)       0           lambda_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 50, 50)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_153 (Dot)                   (None, 50, 64)       0           permute_51[0][0]                 \n",
      "                                                                 dropout_97[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_152 (Dot)                   (None, 50, 64)       0           lambda_117[0][0]                 \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_203 (Concatenate)   (None, 50, 535)      0           dropout_97[0][0]                 \n",
      "                                                                 dot_153[0][0]                    \n",
      "                                                                 concatenate_201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_204 (Concatenate)   (None, 50, 535)      0           dropout_97[1][0]                 \n",
      "                                                                 dot_152[0][0]                    \n",
      "                                                                 concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 535)          0           concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 535)          0           concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_7 (A (None, 535)          535         concatenate_203[0][0]            \n",
      "                                                                 concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 535)          0           concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 535)          0           concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_205 (Concatenate)   (None, 1605)         0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_max_pooling1d_33[0][0]    \n",
      "                                                                 attention_weighted_average_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_206 (Concatenate)   (None, 1605)         0           global_average_pooling1d_34[0][0]\n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "                                                                 attention_weighted_average_7[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 1605)         0           concatenate_205[0][0]            \n",
      "                                                                 concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 1605)         0           concatenate_205[0][0]            \n",
      "                                                                 concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_207 (Concatenate)   (None, 6420)         0           concatenate_205[0][0]            \n",
      "                                                                 concatenate_206[0][0]            \n",
      "                                                                 lambda_119[0][0]                 \n",
      "                                                                 multiply_59[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 6420)         0           concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6420)         25680       dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 64)           410944      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 3)            195         dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.0225 - acc: 0.8817 - weighted_accuracy: 0.8762 - val_loss: 0.3072 - val_acc: 0.8627 - val_weighted_accuracy: 0.8537\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0229 - acc: 0.8786 - weighted_accuracy: 0.8730 - val_loss: 0.3076 - val_acc: 0.8619 - val_weighted_accuracy: 0.8507\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0228 - acc: 0.8787 - weighted_accuracy: 0.8732 - val_loss: 0.3014 - val_acc: 0.8633 - val_weighted_accuracy: 0.8536\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0227 - acc: 0.8795 - weighted_accuracy: 0.8742 - val_loss: 0.3046 - val_acc: 0.8634 - val_weighted_accuracy: 0.8547\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0226 - acc: 0.8802 - weighted_accuracy: 0.8746 - val_loss: 0.3001 - val_acc: 0.8678 - val_weighted_accuracy: 0.8547\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0225 - acc: 0.8799 - weighted_accuracy: 0.8746 - val_loss: 0.3080 - val_acc: 0.8603 - val_weighted_accuracy: 0.8538\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0224 - acc: 0.8802 - weighted_accuracy: 0.8749 - val_loss: 0.3043 - val_acc: 0.8653 - val_weighted_accuracy: 0.8550\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0223 - acc: 0.8804 - weighted_accuracy: 0.8754 - val_loss: 0.2958 - val_acc: 0.8690 - val_weighted_accuracy: 0.8535\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0222 - acc: 0.8817 - weighted_accuracy: 0.8766 - val_loss: 0.2963 - val_acc: 0.8694 - val_weighted_accuracy: 0.8525\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0221 - acc: 0.8810 - weighted_accuracy: 0.8759 - val_loss: 0.2974 - val_acc: 0.8674 - val_weighted_accuracy: 0.8514\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0220 - acc: 0.8829 - weighted_accuracy: 0.8779 - val_loss: 0.3084 - val_acc: 0.8618 - val_weighted_accuracy: 0.8526\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0219 - acc: 0.8828 - weighted_accuracy: 0.8778 - val_loss: 0.3051 - val_acc: 0.8628 - val_weighted_accuracy: 0.8560\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0218 - acc: 0.8834 - weighted_accuracy: 0.8784 - val_loss: 0.3006 - val_acc: 0.8640 - val_weighted_accuracy: 0.8546\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0217 - acc: 0.8836 - weighted_accuracy: 0.8786 - val_loss: 0.2976 - val_acc: 0.8659 - val_weighted_accuracy: 0.8557\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0217 - acc: 0.8841 - weighted_accuracy: 0.8792 - val_loss: 0.3002 - val_acc: 0.8667 - val_weighted_accuracy: 0.8584\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0217 - acc: 0.8843 - weighted_accuracy: 0.8794 - val_loss: 0.3023 - val_acc: 0.8647 - val_weighted_accuracy: 0.8531\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0215 - acc: 0.8841 - weighted_accuracy: 0.8795 - val_loss: 0.2944 - val_acc: 0.8698 - val_weighted_accuracy: 0.8599\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0215 - acc: 0.8849 - weighted_accuracy: 0.8803 - val_loss: 0.3059 - val_acc: 0.8631 - val_weighted_accuracy: 0.8590\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0215 - acc: 0.8854 - weighted_accuracy: 0.8808 - val_loss: 0.2971 - val_acc: 0.8677 - val_weighted_accuracy: 0.8558\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0213 - acc: 0.8857 - weighted_accuracy: 0.8812 - val_loss: 0.2932 - val_acc: 0.8682 - val_weighted_accuracy: 0.8520\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0213 - acc: 0.8850 - weighted_accuracy: 0.8806 - val_loss: 0.2894 - val_acc: 0.8707 - val_weighted_accuracy: 0.8566\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0213 - acc: 0.8863 - weighted_accuracy: 0.8819 - val_loss: 0.2966 - val_acc: 0.8660 - val_weighted_accuracy: 0.8544\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0213 - acc: 0.8855 - weighted_accuracy: 0.8811 - val_loss: 0.2987 - val_acc: 0.8652 - val_weighted_accuracy: 0.8492\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0212 - acc: 0.8860 - weighted_accuracy: 0.8817 - val_loss: 0.2929 - val_acc: 0.8679 - val_weighted_accuracy: 0.8591\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0211 - acc: 0.8869 - weighted_accuracy: 0.8829 - val_loss: 0.2977 - val_acc: 0.8679 - val_weighted_accuracy: 0.8552\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0211 - acc: 0.8870 - weighted_accuracy: 0.8829 - val_loss: 0.2969 - val_acc: 0.8672 - val_weighted_accuracy: 0.8580\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 120s 334us/step - loss: 0.0210 - acc: 0.8882 - weighted_accuracy: 0.8841 - val_loss: 0.2997 - val_acc: 0.8643 - val_weighted_accuracy: 0.8526\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_208 (Concatenate)   (None, 50, 151)      0           embedding_35[0][0]               \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_209 (Concatenate)   (None, 50, 151)      0           embedding_35[1][0]               \n",
      "                                                                 reshape_8[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_35 (SpatialDr (None, 50, 151)      0           concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 50, 151)      0           concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 50, 64)       0           conv1d_67[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 50, 64)       0           conv1d_67[1][0]                  \n",
      "                                                                 conv1d_70[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 50, 64)       4160        multiply_60[0][0]                \n",
      "                                                                 multiply_61[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 50, 64)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_154 (Dot)                   (None, 50, 50)       0           dropout_99[0][0]                 \n",
      "                                                                 dropout_99[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 50, 50)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_52 (Permute)            (None, 50, 50)       0           lambda_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 50, 50)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_156 (Dot)                   (None, 50, 64)       0           permute_52[0][0]                 \n",
      "                                                                 dropout_99[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_155 (Dot)                   (None, 50, 64)       0           lambda_120[0][0]                 \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_210 (Concatenate)   (None, 50, 279)      0           dropout_99[0][0]                 \n",
      "                                                                 dot_156[0][0]                    \n",
      "                                                                 spatial_dropout1d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_211 (Concatenate)   (None, 50, 279)      0           dropout_99[1][0]                 \n",
      "                                                                 dot_155[0][0]                    \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 50, 64)       53632       concatenate_210[0][0]            \n",
      "                                                                 concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 50, 64)       53632       concatenate_210[0][0]            \n",
      "                                                                 concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 50, 64)       0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 50, 64)       0           conv1d_68[1][0]                  \n",
      "                                                                 conv1d_71[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 50, 64)       4160        multiply_62[0][0]                \n",
      "                                                                 multiply_63[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 50, 64)       0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_157 (Dot)                   (None, 50, 50)       0           dropout_100[0][0]                \n",
      "                                                                 dropout_100[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 50, 50)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_53 (Permute)            (None, 50, 50)       0           lambda_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 50, 50)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_159 (Dot)                   (None, 50, 64)       0           permute_53[0][0]                 \n",
      "                                                                 dropout_100[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_158 (Dot)                   (None, 50, 64)       0           lambda_122[0][0]                 \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_212 (Concatenate)   (None, 50, 407)      0           dropout_100[0][0]                \n",
      "                                                                 dot_159[0][0]                    \n",
      "                                                                 concatenate_210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_213 (Concatenate)   (None, 50, 407)      0           dropout_100[1][0]                \n",
      "                                                                 dot_158[0][0]                    \n",
      "                                                                 concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 50, 64)       78208       concatenate_212[0][0]            \n",
      "                                                                 concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 50, 64)       78208       concatenate_212[0][0]            \n",
      "                                                                 concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 50, 64)       0           conv1d_69[0][0]                  \n",
      "                                                                 conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_65 (Multiply)          (None, 50, 64)       0           conv1d_69[1][0]                  \n",
      "                                                                 conv1d_72[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 50, 64)       4160        multiply_64[0][0]                \n",
      "                                                                 multiply_65[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 50, 64)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_160 (Dot)                   (None, 50, 50)       0           dropout_101[0][0]                \n",
      "                                                                 dropout_101[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 50, 50)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_54 (Permute)            (None, 50, 50)       0           lambda_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 50, 50)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_162 (Dot)                   (None, 50, 64)       0           permute_54[0][0]                 \n",
      "                                                                 dropout_101[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_161 (Dot)                   (None, 50, 64)       0           lambda_124[0][0]                 \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)   (None, 50, 535)      0           dropout_101[0][0]                \n",
      "                                                                 dot_162[0][0]                    \n",
      "                                                                 concatenate_212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_215 (Concatenate)   (None, 50, 535)      0           dropout_101[1][0]                \n",
      "                                                                 dot_161[0][0]                    \n",
      "                                                                 concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 535)          0           concatenate_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_35 (Global (None, 535)          0           concatenate_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_8 (A (None, 535)          535         concatenate_214[0][0]            \n",
      "                                                                 concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_36 (Gl (None, 535)          0           concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_36 (Global (None, 535)          0           concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_216 (Concatenate)   (None, 1605)         0           global_average_pooling1d_35[0][0]\n",
      "                                                                 global_max_pooling1d_35[0][0]    \n",
      "                                                                 attention_weighted_average_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_217 (Concatenate)   (None, 1605)         0           global_average_pooling1d_36[0][0]\n",
      "                                                                 global_max_pooling1d_36[0][0]    \n",
      "                                                                 attention_weighted_average_8[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 1605)         0           concatenate_216[0][0]            \n",
      "                                                                 concatenate_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_66 (Multiply)          (None, 1605)         0           concatenate_216[0][0]            \n",
      "                                                                 concatenate_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_218 (Concatenate)   (None, 6420)         0           concatenate_216[0][0]            \n",
      "                                                                 concatenate_217[0][0]            \n",
      "                                                                 lambda_126[0][0]                 \n",
      "                                                                 multiply_66[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 6420)         0           concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6420)         25680       dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 64)           410944      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 3)            195         dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.0232 - acc: 0.8705 - weighted_accuracy: 0.8644 - val_loss: 0.2997 - val_acc: 0.8632 - val_weighted_accuracy: 0.8499\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0235 - acc: 0.8705 - weighted_accuracy: 0.8647 - val_loss: 0.2967 - val_acc: 0.8636 - val_weighted_accuracy: 0.8506\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0234 - acc: 0.8719 - weighted_accuracy: 0.8663 - val_loss: 0.2947 - val_acc: 0.8674 - val_weighted_accuracy: 0.8550\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0232 - acc: 0.8735 - weighted_accuracy: 0.8684 - val_loss: 0.2924 - val_acc: 0.8672 - val_weighted_accuracy: 0.8511\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0230 - acc: 0.8744 - weighted_accuracy: 0.8693 - val_loss: 0.2939 - val_acc: 0.8666 - val_weighted_accuracy: 0.8561\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0229 - acc: 0.8758 - weighted_accuracy: 0.8708 - val_loss: 0.2915 - val_acc: 0.8688 - val_weighted_accuracy: 0.8575\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0227 - acc: 0.8769 - weighted_accuracy: 0.8719 - val_loss: 0.2913 - val_acc: 0.8686 - val_weighted_accuracy: 0.8558\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0227 - acc: 0.8772 - weighted_accuracy: 0.8720 - val_loss: 0.2904 - val_acc: 0.8700 - val_weighted_accuracy: 0.8549\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0225 - acc: 0.8787 - weighted_accuracy: 0.8738 - val_loss: 0.2875 - val_acc: 0.8705 - val_weighted_accuracy: 0.8556\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0223 - acc: 0.8789 - weighted_accuracy: 0.8744 - val_loss: 0.2851 - val_acc: 0.8743 - val_weighted_accuracy: 0.8553\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0221 - acc: 0.8808 - weighted_accuracy: 0.8760 - val_loss: 0.2895 - val_acc: 0.8721 - val_weighted_accuracy: 0.8579\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 121s 336us/step - loss: 0.0220 - acc: 0.8808 - weighted_accuracy: 0.8765 - val_loss: 0.2877 - val_acc: 0.8720 - val_weighted_accuracy: 0.8586\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0220 - acc: 0.8809 - weighted_accuracy: 0.8764 - val_loss: 0.2993 - val_acc: 0.8663 - val_weighted_accuracy: 0.8579\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0219 - acc: 0.8810 - weighted_accuracy: 0.8767 - val_loss: 0.3053 - val_acc: 0.8592 - val_weighted_accuracy: 0.8396\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0218 - acc: 0.8821 - weighted_accuracy: 0.8776 - val_loss: 0.2918 - val_acc: 0.8684 - val_weighted_accuracy: 0.8562\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0217 - acc: 0.8829 - weighted_accuracy: 0.8786 - val_loss: 0.2846 - val_acc: 0.8733 - val_weighted_accuracy: 0.8564\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0216 - acc: 0.8841 - weighted_accuracy: 0.8795 - val_loss: 0.2845 - val_acc: 0.8728 - val_weighted_accuracy: 0.8564\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0216 - acc: 0.8829 - weighted_accuracy: 0.8783 - val_loss: 0.2874 - val_acc: 0.8714 - val_weighted_accuracy: 0.8601\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0215 - acc: 0.8839 - weighted_accuracy: 0.8794 - val_loss: 0.2792 - val_acc: 0.8752 - val_weighted_accuracy: 0.8592\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0214 - acc: 0.8846 - weighted_accuracy: 0.8805 - val_loss: 0.2852 - val_acc: 0.8730 - val_weighted_accuracy: 0.8591\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0214 - acc: 0.8849 - weighted_accuracy: 0.8810 - val_loss: 0.2816 - val_acc: 0.8738 - val_weighted_accuracy: 0.8533\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0214 - acc: 0.8840 - weighted_accuracy: 0.8798 - val_loss: 0.2812 - val_acc: 0.8761 - val_weighted_accuracy: 0.8550\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0213 - acc: 0.8845 - weighted_accuracy: 0.8808 - val_loss: 0.2930 - val_acc: 0.8665 - val_weighted_accuracy: 0.8520\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0213 - acc: 0.8852 - weighted_accuracy: 0.8810 - val_loss: 0.2862 - val_acc: 0.8735 - val_weighted_accuracy: 0.8617\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0212 - acc: 0.8859 - weighted_accuracy: 0.8821 - val_loss: 0.2887 - val_acc: 0.8720 - val_weighted_accuracy: 0.8569\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0212 - acc: 0.8856 - weighted_accuracy: 0.8816 - val_loss: 0.2910 - val_acc: 0.8673 - val_weighted_accuracy: 0.8546\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0212 - acc: 0.8853 - weighted_accuracy: 0.8816 - val_loss: 0.2860 - val_acc: 0.8708 - val_weighted_accuracy: 0.8569\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0211 - acc: 0.8858 - weighted_accuracy: 0.8820 - val_loss: 0.2853 - val_acc: 0.8757 - val_weighted_accuracy: 0.8615\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0210 - acc: 0.8860 - weighted_accuracy: 0.8824 - val_loss: 0.2825 - val_acc: 0.8742 - val_weighted_accuracy: 0.8596\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0210 - acc: 0.8862 - weighted_accuracy: 0.8826 - val_loss: 0.2936 - val_acc: 0.8661 - val_weighted_accuracy: 0.8458\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 121s 335us/step - loss: 0.0209 - acc: 0.8869 - weighted_accuracy: 0.8831 - val_loss: 0.2891 - val_acc: 0.8686 - val_weighted_accuracy: 0.8571\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8876 - weighted_accuracy: 0.8837 - val_loss: 0.2779 - val_acc: 0.8782 - val_weighted_accuracy: 0.8601\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8865 - weighted_accuracy: 0.8830 - val_loss: 0.2817 - val_acc: 0.8741 - val_weighted_accuracy: 0.8609\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 121s 334us/step - loss: 0.0209 - acc: 0.8868 - weighted_accuracy: 0.8831 - val_loss: 0.2796 - val_acc: 0.8754 - val_weighted_accuracy: 0.8614\n",
      "score 0.8537928059735456\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 7s 82us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "80126/80126 [==============================] - 6s 70us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2][:, -1]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2][:, -1]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PS3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_ESIM(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    #input_encoded = BatchNormalization()(input_layer_3)\n",
    "    input_encoded = Dense(2016, activation='elu')(input_layer_3)\n",
    "    input_encoded = Dropout(0.25)(input_encoded)\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    #q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    #q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    batch_norm = BatchNormalization(axis=-1)\n",
    "    q1_embed = batch_norm(q1_embed)\n",
    "    q2_embed = batch_norm(q2_embed)\n",
    "    \n",
    "    aggreation_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    " \n",
    "    q1_seq = aggreation_gru(q1_embed)\n",
    "    q2_seq = aggreation_gru(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "    q1_vec = Concatenate()([q1_seq, q2_aligned, substract(q1_seq, q2_aligned), Multiply()([q1_seq, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_seq, q1_aligned, substract(q2_seq, q1_aligned), Multiply()([q2_seq, q1_aligned])])\n",
    "    \n",
    "    compare_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    "    \n",
    "    q1_rep = compare_gru(q1_vec)\n",
    "    q2_rep = compare_gru(q2_vec)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5, amsgrad=True), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 50, 150)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 50, 150)      0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 150)      600         spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 144)      129024      batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 50, 50)       0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 50, 50)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 50, 144)      0           permute_1[0][0]                  \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 50, 144)      0           lambda_1[0][0]                   \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 50, 144)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 50, 144)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50, 144)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 50, 144)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 576)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_3[0][0]                      \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 50, 576)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 144)      374400      concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 144)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 144)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 144)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 144)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 288)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 288)          0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 576)          0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 576)          2304        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          147712      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            771         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 175s 487us/step - loss: 0.0200 - acc: 0.8897 - weighted_accuracy: 0.8847 - val_loss: 0.3073 - val_acc: 0.8615 - val_weighted_accuracy: 0.8539\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0187 - acc: 0.8978 - weighted_accuracy: 0.8939 - val_loss: 0.2906 - val_acc: 0.8703 - val_weighted_accuracy: 0.8590\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0178 - acc: 0.9052 - weighted_accuracy: 0.9022 - val_loss: 0.3017 - val_acc: 0.8665 - val_weighted_accuracy: 0.8598\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0171 - acc: 0.9093 - weighted_accuracy: 0.9071 - val_loss: 0.2890 - val_acc: 0.8714 - val_weighted_accuracy: 0.8603\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0164 - acc: 0.9133 - weighted_accuracy: 0.9116 - val_loss: 0.3033 - val_acc: 0.8627 - val_weighted_accuracy: 0.8555\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0159 - acc: 0.9168 - weighted_accuracy: 0.9158 - val_loss: 0.3128 - val_acc: 0.8615 - val_weighted_accuracy: 0.8554\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0155 - acc: 0.9194 - weighted_accuracy: 0.9187 - val_loss: 0.3086 - val_acc: 0.8652 - val_weighted_accuracy: 0.8575\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0150 - acc: 0.9227 - weighted_accuracy: 0.9226 - val_loss: 0.3241 - val_acc: 0.8576 - val_weighted_accuracy: 0.8535\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0146 - acc: 0.9251 - weighted_accuracy: 0.9254 - val_loss: 0.3024 - val_acc: 0.8691 - val_weighted_accuracy: 0.8589\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0142 - acc: 0.9279 - weighted_accuracy: 0.9282 - val_loss: 0.3045 - val_acc: 0.8684 - val_weighted_accuracy: 0.8589\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0139 - acc: 0.9298 - weighted_accuracy: 0.9305 - val_loss: 0.3277 - val_acc: 0.8650 - val_weighted_accuracy: 0.8552\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0136 - acc: 0.9315 - weighted_accuracy: 0.9324 - val_loss: 0.3079 - val_acc: 0.8705 - val_weighted_accuracy: 0.8582\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 155s 431us/step - loss: 0.0133 - acc: 0.9339 - weighted_accuracy: 0.9349 - val_loss: 0.3079 - val_acc: 0.8671 - val_weighted_accuracy: 0.8559\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0131 - acc: 0.9352 - weighted_accuracy: 0.9364 - val_loss: 0.3224 - val_acc: 0.8683 - val_weighted_accuracy: 0.8589\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 50, 150)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 50, 150)      0           embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50, 150)      600         spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 50, 144)      129024      batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_5[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 50, 50)       0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50, 50)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 50, 50)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50, 50)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 50, 144)      0           permute_2[0][0]                  \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 50, 144)      0           lambda_5[0][0]                   \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 50, 144)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 50, 144)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50, 144)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 50, 144)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 50, 576)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_6[0][0]                      \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 50, 576)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_5[0][0]                      \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 50, 144)      374400      concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 144)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 144)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 144)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 144)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 288)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 288)          0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 576)          0           concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 576)          2304        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          147712      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            771         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.0186 - acc: 0.9001 - weighted_accuracy: 0.8957 - val_loss: 0.3110 - val_acc: 0.8702 - val_weighted_accuracy: 0.8660\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0177 - acc: 0.9058 - weighted_accuracy: 0.9028 - val_loss: 0.2828 - val_acc: 0.8757 - val_weighted_accuracy: 0.8686\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0170 - acc: 0.9105 - weighted_accuracy: 0.9080 - val_loss: 0.2793 - val_acc: 0.8770 - val_weighted_accuracy: 0.8700\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0164 - acc: 0.9144 - weighted_accuracy: 0.9127 - val_loss: 0.2729 - val_acc: 0.8811 - val_weighted_accuracy: 0.8739\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0158 - acc: 0.9176 - weighted_accuracy: 0.9166 - val_loss: 0.2896 - val_acc: 0.8727 - val_weighted_accuracy: 0.8690\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0153 - acc: 0.9205 - weighted_accuracy: 0.9198 - val_loss: 0.2810 - val_acc: 0.8775 - val_weighted_accuracy: 0.8707\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0149 - acc: 0.9233 - weighted_accuracy: 0.9232 - val_loss: 0.2745 - val_acc: 0.8799 - val_weighted_accuracy: 0.8712\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0146 - acc: 0.9255 - weighted_accuracy: 0.9258 - val_loss: 0.2837 - val_acc: 0.8791 - val_weighted_accuracy: 0.8725\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0142 - acc: 0.9278 - weighted_accuracy: 0.9283 - val_loss: 0.2844 - val_acc: 0.8790 - val_weighted_accuracy: 0.8724\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0139 - acc: 0.9300 - weighted_accuracy: 0.9305 - val_loss: 0.2885 - val_acc: 0.8803 - val_weighted_accuracy: 0.8739\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 163s 453us/step - loss: 0.0136 - acc: 0.9323 - weighted_accuracy: 0.9333 - val_loss: 0.2917 - val_acc: 0.8785 - val_weighted_accuracy: 0.8715\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0132 - acc: 0.9342 - weighted_accuracy: 0.9355 - val_loss: 0.2931 - val_acc: 0.8803 - val_weighted_accuracy: 0.8708\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0129 - acc: 0.9360 - weighted_accuracy: 0.9374 - val_loss: 0.2861 - val_acc: 0.8794 - val_weighted_accuracy: 0.8707\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0127 - acc: 0.9382 - weighted_accuracy: 0.9396 - val_loss: 0.3046 - val_acc: 0.8739 - val_weighted_accuracy: 0.8677\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0124 - acc: 0.9394 - weighted_accuracy: 0.9408 - val_loss: 0.2972 - val_acc: 0.8784 - val_weighted_accuracy: 0.8693\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 155s 430us/step - loss: 0.0122 - acc: 0.9405 - weighted_accuracy: 0.9423 - val_loss: 0.2955 - val_acc: 0.8835 - val_weighted_accuracy: 0.8731\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0120 - acc: 0.9426 - weighted_accuracy: 0.9443 - val_loss: 0.3049 - val_acc: 0.8813 - val_weighted_accuracy: 0.8710\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.0118 - acc: 0.9437 - weighted_accuracy: 0.9454 - val_loss: 0.3080 - val_acc: 0.8822 - val_weighted_accuracy: 0.8719\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.0116 - acc: 0.9449 - weighted_accuracy: 0.9467 - val_loss: 0.2953 - val_acc: 0.8817 - val_weighted_accuracy: 0.8710\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 168s 466us/step - loss: 0.0114 - acc: 0.9460 - weighted_accuracy: 0.9478 - val_loss: 0.2981 - val_acc: 0.8820 - val_weighted_accuracy: 0.8703\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 50, 150)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 50, 150)      0           embedding_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 150)      600         spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 50, 144)      129024      batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_9[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 50, 50)       0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 50, 50)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 50, 50)       0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 50, 50)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 50, 144)      0           permute_3[0][0]                  \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 50, 144)      0           lambda_9[0][0]                   \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 50, 576)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_9[0][0]                      \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 50, 576)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_8[0][0]                      \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 50, 144)      374400      concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 288)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 288)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 576)          0           concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 576)          2304        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          147712      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            771         dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 171s 474us/step - loss: 0.0192 - acc: 0.8959 - weighted_accuracy: 0.8911 - val_loss: 0.3029 - val_acc: 0.8640 - val_weighted_accuracy: 0.8577\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 168s 466us/step - loss: 0.0182 - acc: 0.9025 - weighted_accuracy: 0.8987 - val_loss: 0.2952 - val_acc: 0.8680 - val_weighted_accuracy: 0.8605\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 168s 467us/step - loss: 0.0174 - acc: 0.9082 - weighted_accuracy: 0.9053 - val_loss: 0.3029 - val_acc: 0.8659 - val_weighted_accuracy: 0.8595\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 168s 467us/step - loss: 0.0168 - acc: 0.9114 - weighted_accuracy: 0.9093 - val_loss: 0.3089 - val_acc: 0.8610 - val_weighted_accuracy: 0.8577\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 168s 466us/step - loss: 0.0161 - acc: 0.9159 - weighted_accuracy: 0.9142 - val_loss: 0.3022 - val_acc: 0.8693 - val_weighted_accuracy: 0.8620\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 166s 460us/step - loss: 0.0157 - acc: 0.9188 - weighted_accuracy: 0.9175 - val_loss: 0.2935 - val_acc: 0.8722 - val_weighted_accuracy: 0.8616\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0152 - acc: 0.9218 - weighted_accuracy: 0.9211 - val_loss: 0.3090 - val_acc: 0.8676 - val_weighted_accuracy: 0.8613\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0148 - acc: 0.9241 - weighted_accuracy: 0.9237 - val_loss: 0.2965 - val_acc: 0.8717 - val_weighted_accuracy: 0.8600\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9268 - val_loss: 0.2965 - val_acc: 0.8685 - val_weighted_accuracy: 0.8592\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9296 - val_loss: 0.3125 - val_acc: 0.8641 - val_weighted_accuracy: 0.8587\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0137 - acc: 0.9305 - weighted_accuracy: 0.9314 - val_loss: 0.3087 - val_acc: 0.8676 - val_weighted_accuracy: 0.8596\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0135 - acc: 0.9321 - weighted_accuracy: 0.9331 - val_loss: 0.3024 - val_acc: 0.8702 - val_weighted_accuracy: 0.8610\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 156s 432us/step - loss: 0.0132 - acc: 0.9346 - weighted_accuracy: 0.9356 - val_loss: 0.3180 - val_acc: 0.8658 - val_weighted_accuracy: 0.8599\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0129 - acc: 0.9355 - weighted_accuracy: 0.9368 - val_loss: 0.3191 - val_acc: 0.8657 - val_weighted_accuracy: 0.8574\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0127 - acc: 0.9376 - weighted_accuracy: 0.9391 - val_loss: 0.3253 - val_acc: 0.8680 - val_weighted_accuracy: 0.8600\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 50, 150)      0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 50, 150)      0           embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 50, 150)      600         spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 50, 144)      129024      batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_13[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 50, 50)       0           bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 50, 50)       0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_12 (Dot)                    (None, 50, 144)      0           permute_4[0][0]                  \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 50, 144)      0           lambda_13[0][0]                  \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 50, 576)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_12[0][0]                     \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 50, 576)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_11[0][0]                     \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 50, 144)      374400      concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 288)          0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 288)          0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 576)          0           concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 576)          2304        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          147712      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          65792       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            771         dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 159s 441us/step - loss: 0.0175 - acc: 0.9078 - weighted_accuracy: 0.9041 - val_loss: 0.3190 - val_acc: 0.8588 - val_weighted_accuracy: 0.8566\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0169 - acc: 0.9113 - weighted_accuracy: 0.9083 - val_loss: 0.2914 - val_acc: 0.8715 - val_weighted_accuracy: 0.8636\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0162 - acc: 0.9157 - weighted_accuracy: 0.9138 - val_loss: 0.2932 - val_acc: 0.8700 - val_weighted_accuracy: 0.8625\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0157 - acc: 0.9189 - weighted_accuracy: 0.9175 - val_loss: 0.2904 - val_acc: 0.8719 - val_weighted_accuracy: 0.8650\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0152 - acc: 0.9217 - weighted_accuracy: 0.9206 - val_loss: 0.2944 - val_acc: 0.8722 - val_weighted_accuracy: 0.8670\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9236 - val_loss: 0.2994 - val_acc: 0.8690 - val_weighted_accuracy: 0.8654\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0144 - acc: 0.9265 - weighted_accuracy: 0.9265 - val_loss: 0.2935 - val_acc: 0.8694 - val_weighted_accuracy: 0.8633\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9294 - val_loss: 0.3015 - val_acc: 0.8727 - val_weighted_accuracy: 0.8638\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0137 - acc: 0.9310 - weighted_accuracy: 0.9316 - val_loss: 0.3105 - val_acc: 0.8693 - val_weighted_accuracy: 0.8623\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0134 - acc: 0.9334 - weighted_accuracy: 0.9343 - val_loss: 0.3148 - val_acc: 0.8712 - val_weighted_accuracy: 0.8639\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 164s 454us/step - loss: 0.0131 - acc: 0.9344 - weighted_accuracy: 0.9353 - val_loss: 0.3165 - val_acc: 0.8710 - val_weighted_accuracy: 0.8635\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 159s 441us/step - loss: 0.0128 - acc: 0.9363 - weighted_accuracy: 0.9374 - val_loss: 0.3084 - val_acc: 0.8719 - val_weighted_accuracy: 0.8647\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 160s 445us/step - loss: 0.0126 - acc: 0.9384 - weighted_accuracy: 0.9398 - val_loss: 0.3233 - val_acc: 0.8717 - val_weighted_accuracy: 0.8630\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 159s 441us/step - loss: 0.0124 - acc: 0.9390 - weighted_accuracy: 0.9402 - val_loss: 0.3287 - val_acc: 0.8694 - val_weighted_accuracy: 0.8618\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0121 - acc: 0.9414 - weighted_accuracy: 0.9428 - val_loss: 0.3237 - val_acc: 0.8718 - val_weighted_accuracy: 0.8637\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 50, 150)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 50, 150)      0           embedding_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50, 150)      600         spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 50, 144)      129024      batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_17[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 50, 50)       0           bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 50, 50)       0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 50, 144)      0           permute_5[0][0]                  \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 50, 144)      0           lambda_17[0][0]                  \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 50, 576)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_15[0][0]                     \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 50, 576)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_14[0][0]                     \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 50, 144)      374400      concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 288)          0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 288)          0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 576)          0           concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 576)          2304        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          147712      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          65792       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            771         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0184 - acc: 0.9013 - weighted_accuracy: 0.8969 - val_loss: 0.3105 - val_acc: 0.8604 - val_weighted_accuracy: 0.8503\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 161s 445us/step - loss: 0.0176 - acc: 0.9063 - weighted_accuracy: 0.9028 - val_loss: 0.3356 - val_acc: 0.8510 - val_weighted_accuracy: 0.8465\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.0169 - acc: 0.9110 - weighted_accuracy: 0.9083 - val_loss: 0.3184 - val_acc: 0.8603 - val_weighted_accuracy: 0.8547\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 164s 454us/step - loss: 0.0163 - acc: 0.9151 - weighted_accuracy: 0.9132 - val_loss: 0.3074 - val_acc: 0.8632 - val_weighted_accuracy: 0.8554\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 162s 449us/step - loss: 0.0157 - acc: 0.9183 - weighted_accuracy: 0.9169 - val_loss: 0.3132 - val_acc: 0.8624 - val_weighted_accuracy: 0.8569\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.0152 - acc: 0.9219 - weighted_accuracy: 0.9209 - val_loss: 0.3325 - val_acc: 0.8558 - val_weighted_accuracy: 0.8529\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 162s 448us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9237 - val_loss: 0.3156 - val_acc: 0.8621 - val_weighted_accuracy: 0.8563\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 161s 447us/step - loss: 0.0144 - acc: 0.9260 - weighted_accuracy: 0.9261 - val_loss: 0.3300 - val_acc: 0.8568 - val_weighted_accuracy: 0.8527\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 160s 445us/step - loss: 0.0140 - acc: 0.9295 - weighted_accuracy: 0.9296 - val_loss: 0.3100 - val_acc: 0.8637 - val_weighted_accuracy: 0.8549\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0138 - acc: 0.9302 - weighted_accuracy: 0.9307 - val_loss: 0.3206 - val_acc: 0.8638 - val_weighted_accuracy: 0.8561\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 160s 445us/step - loss: 0.0134 - acc: 0.9327 - weighted_accuracy: 0.9334 - val_loss: 0.3258 - val_acc: 0.8608 - val_weighted_accuracy: 0.8528\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 160s 443us/step - loss: 0.0131 - acc: 0.9348 - weighted_accuracy: 0.9358 - val_loss: 0.3254 - val_acc: 0.8587 - val_weighted_accuracy: 0.8516\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.0129 - acc: 0.9368 - weighted_accuracy: 0.9377 - val_loss: 0.3266 - val_acc: 0.8638 - val_weighted_accuracy: 0.8548\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.0126 - acc: 0.9380 - weighted_accuracy: 0.9391 - val_loss: 0.3408 - val_acc: 0.8602 - val_weighted_accuracy: 0.8523\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.0123 - acc: 0.9399 - weighted_accuracy: 0.9413 - val_loss: 0.3328 - val_acc: 0.8624 - val_weighted_accuracy: 0.8519\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 50, 150)      0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 50, 150)      0           embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 150)      600         spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 50, 144)      129024      batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_21[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_16 (Dot)                    (None, 50, 50)       0           bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 50, 50)       0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 50, 144)      0           permute_6[0][0]                  \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 50, 144)      0           lambda_21[0][0]                  \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 50, 576)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_18[0][0]                     \n",
      "                                                                 lambda_23[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 50, 576)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_17[0][0]                     \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 50, 144)      374400      concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 288)          0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 288)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 576)          0           concatenate_28[0][0]             \n",
      "                                                                 concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 576)          2304        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 256)          147712      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          65792       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 256)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 3)            771         dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 161s 446us/step - loss: 0.0184 - acc: 0.9017 - weighted_accuracy: 0.8974 - val_loss: 0.3333 - val_acc: 0.8481 - val_weighted_accuracy: 0.8425\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0175 - acc: 0.9071 - weighted_accuracy: 0.9038 - val_loss: 0.3270 - val_acc: 0.8515 - val_weighted_accuracy: 0.8453\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0168 - acc: 0.9110 - weighted_accuracy: 0.9084 - val_loss: 0.3239 - val_acc: 0.8536 - val_weighted_accuracy: 0.8440\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0162 - acc: 0.9158 - weighted_accuracy: 0.9141 - val_loss: 0.3234 - val_acc: 0.8558 - val_weighted_accuracy: 0.8412\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0157 - acc: 0.9189 - weighted_accuracy: 0.9175 - val_loss: 0.3173 - val_acc: 0.8567 - val_weighted_accuracy: 0.8430\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0152 - acc: 0.9217 - weighted_accuracy: 0.9208 - val_loss: 0.3242 - val_acc: 0.8576 - val_weighted_accuracy: 0.8455\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0148 - acc: 0.9238 - weighted_accuracy: 0.9233 - val_loss: 0.3171 - val_acc: 0.8591 - val_weighted_accuracy: 0.8470\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0144 - acc: 0.9269 - weighted_accuracy: 0.9267 - val_loss: 0.3145 - val_acc: 0.8616 - val_weighted_accuracy: 0.8450\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0140 - acc: 0.9291 - weighted_accuracy: 0.9292 - val_loss: 0.3310 - val_acc: 0.8537 - val_weighted_accuracy: 0.8455\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9310 - val_loss: 0.3201 - val_acc: 0.8594 - val_weighted_accuracy: 0.8452\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0134 - acc: 0.9334 - weighted_accuracy: 0.9341 - val_loss: 0.3383 - val_acc: 0.8607 - val_weighted_accuracy: 0.8479\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0131 - acc: 0.9347 - weighted_accuracy: 0.9354 - val_loss: 0.3267 - val_acc: 0.8629 - val_weighted_accuracy: 0.8498\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0129 - acc: 0.9363 - weighted_accuracy: 0.9373 - val_loss: 0.3417 - val_acc: 0.8611 - val_weighted_accuracy: 0.8475\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0126 - acc: 0.9381 - weighted_accuracy: 0.9394 - val_loss: 0.3336 - val_acc: 0.8598 - val_weighted_accuracy: 0.8460\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0124 - acc: 0.9393 - weighted_accuracy: 0.9407 - val_loss: 0.3419 - val_acc: 0.8547 - val_weighted_accuracy: 0.8416\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0122 - acc: 0.9407 - weighted_accuracy: 0.9419 - val_loss: 0.3523 - val_acc: 0.8579 - val_weighted_accuracy: 0.8441\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0119 - acc: 0.9427 - weighted_accuracy: 0.9444 - val_loss: 0.3330 - val_acc: 0.8610 - val_weighted_accuracy: 0.8454\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0117 - acc: 0.9445 - weighted_accuracy: 0.9462 - val_loss: 0.3441 - val_acc: 0.8588 - val_weighted_accuracy: 0.8448\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0115 - acc: 0.9453 - weighted_accuracy: 0.9470 - val_loss: 0.3471 - val_acc: 0.8564 - val_weighted_accuracy: 0.8426\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0113 - acc: 0.9470 - weighted_accuracy: 0.9486 - val_loss: 0.3412 - val_acc: 0.8584 - val_weighted_accuracy: 0.8438\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0111 - acc: 0.9479 - weighted_accuracy: 0.9495 - val_loss: 0.3592 - val_acc: 0.8578 - val_weighted_accuracy: 0.8445\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.0110 - acc: 0.9484 - weighted_accuracy: 0.9504 - val_loss: 0.3568 - val_acc: 0.8561 - val_weighted_accuracy: 0.8435\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 50, 150)      0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 50, 150)      0           embedding_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 50, 150)      600         spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 50, 144)      129024      batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_25[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 50, 50)       0           bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 50, 50)       0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 50, 144)      0           permute_7[0][0]                  \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 50, 144)      0           lambda_25[0][0]                  \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 50, 576)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_21[0][0]                     \n",
      "                                                                 lambda_27[0][0]                  \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 50, 576)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_20[0][0]                     \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 50, 144)      374400      concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 288)          0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 288)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 576)          0           concatenate_33[0][0]             \n",
      "                                                                 concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 576)          2304        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          147712      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 256)          65792       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 3)            771         dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.0192 - acc: 0.8957 - weighted_accuracy: 0.8909 - val_loss: 0.2831 - val_acc: 0.8737 - val_weighted_accuracy: 0.8576\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.0182 - acc: 0.9020 - weighted_accuracy: 0.8983 - val_loss: 0.3233 - val_acc: 0.8553 - val_weighted_accuracy: 0.8561\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.0174 - acc: 0.9079 - weighted_accuracy: 0.9048 - val_loss: 0.2897 - val_acc: 0.8695 - val_weighted_accuracy: 0.8628\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0167 - acc: 0.9123 - weighted_accuracy: 0.9101 - val_loss: 0.2807 - val_acc: 0.8746 - val_weighted_accuracy: 0.8666\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0162 - acc: 0.9153 - weighted_accuracy: 0.9137 - val_loss: 0.2953 - val_acc: 0.8705 - val_weighted_accuracy: 0.8655\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0156 - acc: 0.9189 - weighted_accuracy: 0.9180 - val_loss: 0.2951 - val_acc: 0.8690 - val_weighted_accuracy: 0.8623\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0152 - acc: 0.9216 - weighted_accuracy: 0.9211 - val_loss: 0.2877 - val_acc: 0.8737 - val_weighted_accuracy: 0.8665\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 164s 455us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9238 - val_loss: 0.2824 - val_acc: 0.8780 - val_weighted_accuracy: 0.8695\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 159s 441us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9264 - val_loss: 0.3062 - val_acc: 0.8710 - val_weighted_accuracy: 0.8645\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.0141 - acc: 0.9288 - weighted_accuracy: 0.9291 - val_loss: 0.3085 - val_acc: 0.8678 - val_weighted_accuracy: 0.8639\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 162s 450us/step - loss: 0.0137 - acc: 0.9303 - weighted_accuracy: 0.9309 - val_loss: 0.2968 - val_acc: 0.8767 - val_weighted_accuracy: 0.8694\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 164s 454us/step - loss: 0.0134 - acc: 0.9327 - weighted_accuracy: 0.9336 - val_loss: 0.2944 - val_acc: 0.8767 - val_weighted_accuracy: 0.8672\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 166s 460us/step - loss: 0.0131 - acc: 0.9345 - weighted_accuracy: 0.9355 - val_loss: 0.2908 - val_acc: 0.8765 - val_weighted_accuracy: 0.8654\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 161s 447us/step - loss: 0.0129 - acc: 0.9363 - weighted_accuracy: 0.9373 - val_loss: 0.2982 - val_acc: 0.8758 - val_weighted_accuracy: 0.8663\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 161s 445us/step - loss: 0.0126 - acc: 0.9381 - weighted_accuracy: 0.9396 - val_loss: 0.3040 - val_acc: 0.8766 - val_weighted_accuracy: 0.8670\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0124 - acc: 0.9394 - weighted_accuracy: 0.9408 - val_loss: 0.3074 - val_acc: 0.8726 - val_weighted_accuracy: 0.8676\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0122 - acc: 0.9409 - weighted_accuracy: 0.9427 - val_loss: 0.3130 - val_acc: 0.8747 - val_weighted_accuracy: 0.8679\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.0119 - acc: 0.9424 - weighted_accuracy: 0.9440 - val_loss: 0.3141 - val_acc: 0.8759 - val_weighted_accuracy: 0.8672\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 50, 150)      0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 50, 150)      0           embedding_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 50, 150)      600         spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 50, 144)      129024      batch_normalization_29[0][0]     \n",
      "                                                                 batch_normalization_29[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 50, 50)       0           bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (None, 50, 50)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 50, 144)      0           permute_8[0][0]                  \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 50, 144)      0           lambda_29[0][0]                  \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 50, 576)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 lambda_31[0][0]                  \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 50, 576)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 lambda_32[0][0]                  \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 50, 144)      374400      concatenate_36[0][0]             \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 288)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 288)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 576)          0           concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 576)          2304        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 256)          147712      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256)          1024        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 256)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 256)          65792       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256)          1024        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 256)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 3)            771         dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 163s 453us/step - loss: 0.0180 - acc: 0.9050 - weighted_accuracy: 0.9011 - val_loss: 0.2756 - val_acc: 0.8788 - val_weighted_accuracy: 0.8632\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.0172 - acc: 0.9090 - weighted_accuracy: 0.9063 - val_loss: 0.2821 - val_acc: 0.8750 - val_weighted_accuracy: 0.8649\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.0165 - acc: 0.9137 - weighted_accuracy: 0.9116 - val_loss: 0.2834 - val_acc: 0.8767 - val_weighted_accuracy: 0.8669\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0160 - acc: 0.9171 - weighted_accuracy: 0.9157 - val_loss: 0.2927 - val_acc: 0.8708 - val_weighted_accuracy: 0.8626\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.0154 - acc: 0.9201 - weighted_accuracy: 0.9191 - val_loss: 0.2865 - val_acc: 0.8736 - val_weighted_accuracy: 0.8660\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.0150 - acc: 0.9230 - weighted_accuracy: 0.9228 - val_loss: 0.2978 - val_acc: 0.8712 - val_weighted_accuracy: 0.8648\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0145 - acc: 0.9261 - weighted_accuracy: 0.9261 - val_loss: 0.2875 - val_acc: 0.8743 - val_weighted_accuracy: 0.8661\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.0142 - acc: 0.9274 - weighted_accuracy: 0.9277 - val_loss: 0.2913 - val_acc: 0.8718 - val_weighted_accuracy: 0.8642\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 159s 442us/step - loss: 0.0138 - acc: 0.9302 - weighted_accuracy: 0.9307 - val_loss: 0.2869 - val_acc: 0.8754 - val_weighted_accuracy: 0.8644\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.0135 - acc: 0.9325 - weighted_accuracy: 0.9333 - val_loss: 0.2852 - val_acc: 0.8788 - val_weighted_accuracy: 0.8682\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 161s 447us/step - loss: 0.0132 - acc: 0.9346 - weighted_accuracy: 0.9356 - val_loss: 0.2935 - val_acc: 0.8782 - val_weighted_accuracy: 0.8659\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 170s 470us/step - loss: 0.0129 - acc: 0.9366 - weighted_accuracy: 0.9378 - val_loss: 0.3092 - val_acc: 0.8738 - val_weighted_accuracy: 0.8640\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0127 - acc: 0.9373 - weighted_accuracy: 0.9386 - val_loss: 0.3005 - val_acc: 0.8718 - val_weighted_accuracy: 0.8621\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0124 - acc: 0.9395 - weighted_accuracy: 0.9409 - val_loss: 0.3022 - val_acc: 0.8754 - val_weighted_accuracy: 0.8651\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0122 - acc: 0.9410 - weighted_accuracy: 0.9425 - val_loss: 0.2959 - val_acc: 0.8803 - val_weighted_accuracy: 0.8667\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 163s 452us/step - loss: 0.0119 - acc: 0.9424 - weighted_accuracy: 0.9440 - val_loss: 0.3217 - val_acc: 0.8700 - val_weighted_accuracy: 0.8593\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 166s 459us/step - loss: 0.0118 - acc: 0.9437 - weighted_accuracy: 0.9453 - val_loss: 0.2993 - val_acc: 0.8770 - val_weighted_accuracy: 0.8632\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 163s 451us/step - loss: 0.0115 - acc: 0.9455 - weighted_accuracy: 0.9471 - val_loss: 0.3131 - val_acc: 0.8760 - val_weighted_accuracy: 0.8626\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.0114 - acc: 0.9464 - weighted_accuracy: 0.9481 - val_loss: 0.3293 - val_acc: 0.8708 - val_weighted_accuracy: 0.8604\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 159s 441us/step - loss: 0.0111 - acc: 0.9478 - weighted_accuracy: 0.9497 - val_loss: 0.3279 - val_acc: 0.8726 - val_weighted_accuracy: 0.8634\n",
      "score 0.8634594458079864\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 13s 165us/step\n",
      "80126/80126 [==============================] - 12s 156us/step\n",
      "80126/80126 [==============================] - 13s 158us/step\n",
      "80126/80126 [==============================] - 12s 156us/step\n",
      "80126/80126 [==============================] - 12s 150us/step\n",
      "80126/80126 [==============================] - 12s 150us/step\n",
      "80126/80126 [==============================] - 12s 150us/step\n",
      "80126/80126 [==============================] - 12s 150us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_ESIM(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "\n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PS3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "        self.class_weight = [0.93, 1.21]\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, batch_size, get_model_func, tests, em_test_features, pseudo_labels, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        #features = features[:, -1]\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:], tests[0]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:], tests[1]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:], tests[2]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:], em_test_features[0]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:], em_test_features[1]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:], pseudo_labels])\n",
    "\n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=None)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_weighted_accuracy', patience=patience)\n",
    "        fine_tune_model_path = self.model_stamp + \"-fine-tune-class_scaled-\" + str(fold_id) + '.h5'\n",
    "        \n",
    "        val_data = (val_x, val_y, weight_val) if weight_val is not None else (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(fine_tune_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         callbacks=[early_stopping, model_checkpoint],\n",
    "                         class_weight={0: 1/16, 1: 1/15, 2: 1/5})\n",
    "        bst_val_score = max(hist.history['val_weighted_accuracy'])\n",
    "        model.load_weights(fine_tune_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decomposable_attention(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    #input_encoded = BatchNormalization()(input_layer_3)\n",
    "    input_encoded = Dense(2016, activation='elu')(input_layer_3)\n",
    "    input_encoded = Dropout(0.25)(input_encoded)\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    #q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    #q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    q1_embed = th(q1_embed)\n",
    "    q2_embed = th(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_embed, q2_embed)\n",
    "    q1_vec = Concatenate()([q1_embed, q2_aligned, substract(q1_embed, q2_aligned), Multiply()([q1_embed, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_embed, q1_aligned, substract(q2_embed, q1_aligned), Multiply()([q2_embed, q1_aligned])])\n",
    "    \n",
    "    dense_compares = [\n",
    "        Dense(300, activation='elu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(200, activation='elu'),\n",
    "        Dropout(0.2),\n",
    "    ]\n",
    "\n",
    "    q1_compared = time_distributed(q1_vec, dense_compares)\n",
    "    q2_compared = time_distributed(q2_vec, dense_compares)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_compared, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_compared, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "\n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)    \n",
    "    \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5, amsgrad=True), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:200: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 50, 150)      0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 50, 150)      0           embedding_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 50, 150)      45300       spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 50, 50)       0           time_distributed_1[0][0]         \n",
      "                                                                 time_distributed_1[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 50, 50)       0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 50, 150)      0           permute_9[0][0]                  \n",
      "                                                                 time_distributed_1[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 50, 150)      0           lambda_33[0][0]                  \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 50, 150)      0           time_distributed_1[0][0]         \n",
      "                                                                 dot_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 50, 150)      0           time_distributed_1[0][0]         \n",
      "                                                                 dot_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 50, 150)      0           time_distributed_1[1][0]         \n",
      "                                                                 dot_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 50, 150)      0           time_distributed_1[1][0]         \n",
      "                                                                 dot_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 50, 600)      0           time_distributed_1[0][0]         \n",
      "                                                                 dot_27[0][0]                     \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 50, 600)      0           time_distributed_1[1][0]         \n",
      "                                                                 dot_26[0][0]                     \n",
      "                                                                 lambda_36[0][0]                  \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 50, 300)      180300      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 50, 300)      180300      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 50, 300)      0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 50, 300)      0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 50, 200)      60200       time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 50, 200)      60200       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 50, 200)      0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 50, 200)      0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 200)          0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 200)          0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 200)          0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 200)          0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 400)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 400)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 800)          0           concatenate_43[0][0]             \n",
      "                                                                 concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 800)          3200        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 256)          205056      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 256)          0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256)          1024        dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          65792       batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 256)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 3)            771         batch_normalization_35[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 84s 230us/step - loss: 0.0279 - acc: 0.8275 - weighted_accuracy: 0.8190 - val_loss: 0.3575 - val_acc: 0.8340 - val_weighted_accuracy: 0.8205\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0238 - acc: 0.8556 - weighted_accuracy: 0.8488 - val_loss: 0.3570 - val_acc: 0.8318 - val_weighted_accuracy: 0.8277\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0230 - acc: 0.8622 - weighted_accuracy: 0.8562 - val_loss: 0.3527 - val_acc: 0.8361 - val_weighted_accuracy: 0.8268\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0223 - acc: 0.8676 - weighted_accuracy: 0.8622 - val_loss: 0.3259 - val_acc: 0.8510 - val_weighted_accuracy: 0.8406\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0219 - acc: 0.8701 - weighted_accuracy: 0.8648 - val_loss: 0.3318 - val_acc: 0.8479 - val_weighted_accuracy: 0.8391\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0216 - acc: 0.8731 - weighted_accuracy: 0.8678 - val_loss: 0.3322 - val_acc: 0.8459 - val_weighted_accuracy: 0.8386\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0213 - acc: 0.8754 - weighted_accuracy: 0.8706 - val_loss: 0.3360 - val_acc: 0.8443 - val_weighted_accuracy: 0.8391\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0211 - acc: 0.8778 - weighted_accuracy: 0.8730 - val_loss: 0.3200 - val_acc: 0.8529 - val_weighted_accuracy: 0.8418\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0209 - acc: 0.8781 - weighted_accuracy: 0.8734 - val_loss: 0.3311 - val_acc: 0.8474 - val_weighted_accuracy: 0.8425\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0206 - acc: 0.8807 - weighted_accuracy: 0.8765 - val_loss: 0.3326 - val_acc: 0.8471 - val_weighted_accuracy: 0.8416\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0205 - acc: 0.8820 - weighted_accuracy: 0.8775 - val_loss: 0.3395 - val_acc: 0.8441 - val_weighted_accuracy: 0.8406\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0204 - acc: 0.8827 - weighted_accuracy: 0.8789 - val_loss: 0.3343 - val_acc: 0.8459 - val_weighted_accuracy: 0.8404\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0204 - acc: 0.8824 - weighted_accuracy: 0.8782 - val_loss: 0.3333 - val_acc: 0.8469 - val_weighted_accuracy: 0.8419\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0201 - acc: 0.8849 - weighted_accuracy: 0.8815 - val_loss: 0.3347 - val_acc: 0.8474 - val_weighted_accuracy: 0.8434\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0199 - acc: 0.8864 - weighted_accuracy: 0.8829 - val_loss: 0.3278 - val_acc: 0.8514 - val_weighted_accuracy: 0.8472\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0198 - acc: 0.8867 - weighted_accuracy: 0.8832 - val_loss: 0.3195 - val_acc: 0.8570 - val_weighted_accuracy: 0.8502\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0197 - acc: 0.8875 - weighted_accuracy: 0.8843 - val_loss: 0.3215 - val_acc: 0.8559 - val_weighted_accuracy: 0.8481\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0196 - acc: 0.8880 - weighted_accuracy: 0.8847 - val_loss: 0.3200 - val_acc: 0.8559 - val_weighted_accuracy: 0.8497\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0195 - acc: 0.8891 - weighted_accuracy: 0.8859 - val_loss: 0.3315 - val_acc: 0.8518 - val_weighted_accuracy: 0.8453\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0194 - acc: 0.8893 - weighted_accuracy: 0.8861 - val_loss: 0.3197 - val_acc: 0.8553 - val_weighted_accuracy: 0.8503\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0192 - acc: 0.8910 - weighted_accuracy: 0.8879 - val_loss: 0.3139 - val_acc: 0.8582 - val_weighted_accuracy: 0.8497\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0192 - acc: 0.8913 - weighted_accuracy: 0.8884 - val_loss: 0.3250 - val_acc: 0.8535 - val_weighted_accuracy: 0.8477\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0192 - acc: 0.8913 - weighted_accuracy: 0.8885 - val_loss: 0.3265 - val_acc: 0.8520 - val_weighted_accuracy: 0.8485\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0190 - acc: 0.8929 - weighted_accuracy: 0.8904 - val_loss: 0.3231 - val_acc: 0.8529 - val_weighted_accuracy: 0.8481\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0189 - acc: 0.8931 - weighted_accuracy: 0.8906 - val_loss: 0.3296 - val_acc: 0.8514 - val_weighted_accuracy: 0.8466\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0189 - acc: 0.8933 - weighted_accuracy: 0.8908 - val_loss: 0.3222 - val_acc: 0.8569 - val_weighted_accuracy: 0.8497\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0188 - acc: 0.8939 - weighted_accuracy: 0.8913 - val_loss: 0.3210 - val_acc: 0.8569 - val_weighted_accuracy: 0.8511\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0187 - acc: 0.8946 - weighted_accuracy: 0.8921 - val_loss: 0.3256 - val_acc: 0.8518 - val_weighted_accuracy: 0.8469\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0187 - acc: 0.8948 - weighted_accuracy: 0.8926 - val_loss: 0.3163 - val_acc: 0.8581 - val_weighted_accuracy: 0.8507\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0186 - acc: 0.8955 - weighted_accuracy: 0.8934 - val_loss: 0.3182 - val_acc: 0.8575 - val_weighted_accuracy: 0.8516\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0185 - acc: 0.8963 - weighted_accuracy: 0.8939 - val_loss: 0.3265 - val_acc: 0.8530 - val_weighted_accuracy: 0.8481\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0185 - acc: 0.8960 - weighted_accuracy: 0.8938 - val_loss: 0.3154 - val_acc: 0.8579 - val_weighted_accuracy: 0.8514\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0185 - acc: 0.8962 - weighted_accuracy: 0.8940 - val_loss: 0.3231 - val_acc: 0.8535 - val_weighted_accuracy: 0.8475\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0184 - acc: 0.8963 - weighted_accuracy: 0.8940 - val_loss: 0.3203 - val_acc: 0.8551 - val_weighted_accuracy: 0.8494\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0182 - acc: 0.8977 - weighted_accuracy: 0.8958 - val_loss: 0.3158 - val_acc: 0.8593 - val_weighted_accuracy: 0.8525\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0182 - acc: 0.8973 - weighted_accuracy: 0.8953 - val_loss: 0.3163 - val_acc: 0.8587 - val_weighted_accuracy: 0.8513\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0182 - acc: 0.8984 - weighted_accuracy: 0.8965 - val_loss: 0.3157 - val_acc: 0.8578 - val_weighted_accuracy: 0.8508\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0181 - acc: 0.8990 - weighted_accuracy: 0.8972 - val_loss: 0.3170 - val_acc: 0.8566 - val_weighted_accuracy: 0.8488\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0180 - acc: 0.8996 - weighted_accuracy: 0.8980 - val_loss: 0.3271 - val_acc: 0.8530 - val_weighted_accuracy: 0.8479\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0179 - acc: 0.9005 - weighted_accuracy: 0.8987 - val_loss: 0.3172 - val_acc: 0.8569 - val_weighted_accuracy: 0.8506\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0178 - acc: 0.9006 - weighted_accuracy: 0.8991 - val_loss: 0.3165 - val_acc: 0.8573 - val_weighted_accuracy: 0.8506\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0178 - acc: 0.9010 - weighted_accuracy: 0.8994 - val_loss: 0.3144 - val_acc: 0.8599 - val_weighted_accuracy: 0.8519\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0177 - acc: 0.9013 - weighted_accuracy: 0.8999 - val_loss: 0.3293 - val_acc: 0.8528 - val_weighted_accuracy: 0.8475\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0177 - acc: 0.9015 - weighted_accuracy: 0.9000 - val_loss: 0.3122 - val_acc: 0.8605 - val_weighted_accuracy: 0.8524\n",
      "Epoch 45/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0176 - acc: 0.9027 - weighted_accuracy: 0.9013 - val_loss: 0.3183 - val_acc: 0.8565 - val_weighted_accuracy: 0.8518\n",
      "Epoch 46/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0176 - acc: 0.9015 - weighted_accuracy: 0.9000 - val_loss: 0.3115 - val_acc: 0.8632 - val_weighted_accuracy: 0.8543\n",
      "Epoch 47/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0175 - acc: 0.9029 - weighted_accuracy: 0.9018 - val_loss: 0.3197 - val_acc: 0.8583 - val_weighted_accuracy: 0.8508\n",
      "Epoch 48/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0175 - acc: 0.9025 - weighted_accuracy: 0.9011 - val_loss: 0.3125 - val_acc: 0.8612 - val_weighted_accuracy: 0.8555\n",
      "Epoch 49/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0174 - acc: 0.9035 - weighted_accuracy: 0.9023 - val_loss: 0.3195 - val_acc: 0.8551 - val_weighted_accuracy: 0.8497\n",
      "Epoch 50/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0173 - acc: 0.9036 - weighted_accuracy: 0.9024 - val_loss: 0.3221 - val_acc: 0.8565 - val_weighted_accuracy: 0.8509\n",
      "Epoch 51/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0173 - acc: 0.9043 - weighted_accuracy: 0.9032 - val_loss: 0.3361 - val_acc: 0.8515 - val_weighted_accuracy: 0.8476\n",
      "Epoch 52/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0173 - acc: 0.9039 - weighted_accuracy: 0.9027 - val_loss: 0.3128 - val_acc: 0.8596 - val_weighted_accuracy: 0.8534\n",
      "Epoch 53/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0173 - acc: 0.9038 - weighted_accuracy: 0.9028 - val_loss: 0.3170 - val_acc: 0.8578 - val_weighted_accuracy: 0.8529\n",
      "Epoch 54/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0174 - acc: 0.9037 - weighted_accuracy: 0.9022 - val_loss: 0.3164 - val_acc: 0.8588 - val_weighted_accuracy: 0.8536\n",
      "Epoch 55/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0171 - acc: 0.9050 - weighted_accuracy: 0.9041 - val_loss: 0.3180 - val_acc: 0.8585 - val_weighted_accuracy: 0.8531\n",
      "Epoch 56/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0170 - acc: 0.9066 - weighted_accuracy: 0.9058 - val_loss: 0.3228 - val_acc: 0.8557 - val_weighted_accuracy: 0.8514\n",
      "Epoch 57/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0172 - acc: 0.9054 - weighted_accuracy: 0.9046 - val_loss: 0.3162 - val_acc: 0.8592 - val_weighted_accuracy: 0.8529\n",
      "Epoch 58/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0170 - acc: 0.9061 - weighted_accuracy: 0.9053 - val_loss: 0.3238 - val_acc: 0.8568 - val_weighted_accuracy: 0.8505\n",
      "Epoch 59/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0169 - acc: 0.9065 - weighted_accuracy: 0.9056 - val_loss: 0.3245 - val_acc: 0.8562 - val_weighted_accuracy: 0.8490\n",
      "Epoch 60/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0169 - acc: 0.9068 - weighted_accuracy: 0.9060 - val_loss: 0.3248 - val_acc: 0.8555 - val_weighted_accuracy: 0.8499\n",
      "Epoch 61/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0168 - acc: 0.9076 - weighted_accuracy: 0.9070 - val_loss: 0.3219 - val_acc: 0.8579 - val_weighted_accuracy: 0.8514\n",
      "Epoch 62/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0168 - acc: 0.9073 - weighted_accuracy: 0.9067 - val_loss: 0.3126 - val_acc: 0.8614 - val_weighted_accuracy: 0.8547\n",
      "Epoch 63/500\n",
      "365062/365062 [==============================] - 78s 214us/step - loss: 0.0167 - acc: 0.9077 - weighted_accuracy: 0.9072 - val_loss: 0.3261 - val_acc: 0.8561 - val_weighted_accuracy: 0.8517\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 50, 150)      0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 50, 150)      0           embedding_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 50, 50)       0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 50, 50)       0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 50, 150)      0           permute_10[0][0]                 \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 50, 150)      0           lambda_37[0][0]                  \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 50, 150)      0           time_distributed_10[0][0]        \n",
      "                                                                 dot_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 50, 150)      0           time_distributed_10[0][0]        \n",
      "                                                                 dot_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 50, 150)      0           time_distributed_10[1][0]        \n",
      "                                                                 dot_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 50, 150)      0           time_distributed_10[1][0]        \n",
      "                                                                 dot_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 50, 600)      0           time_distributed_10[0][0]        \n",
      "                                                                 dot_30[0][0]                     \n",
      "                                                                 lambda_39[0][0]                  \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 50, 600)      0           time_distributed_10[1][0]        \n",
      "                                                                 dot_29[0][0]                     \n",
      "                                                                 lambda_40[0][0]                  \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 50, 300)      180300      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 50, 300)      180300      concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 50, 300)      0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 50, 300)      0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 50, 200)      60200       time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 50, 200)      60200       time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 50, 200)      0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 50, 200)      0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 200)          0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 200)          0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 200)          0           time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 200)          0           time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 400)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 400)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 800)          0           concatenate_48[0][0]             \n",
      "                                                                 concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 800)          3200        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 256)          205056      batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 256)          1024        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 256)          65792       batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 256)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 256)          1024        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 3)            771         batch_normalization_38[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 82s 225us/step - loss: 0.0283 - acc: 0.8244 - weighted_accuracy: 0.8154 - val_loss: 0.3266 - val_acc: 0.8483 - val_weighted_accuracy: 0.8422\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0241 - acc: 0.8527 - weighted_accuracy: 0.8456 - val_loss: 0.3093 - val_acc: 0.8570 - val_weighted_accuracy: 0.8492\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0232 - acc: 0.8599 - weighted_accuracy: 0.8536 - val_loss: 0.2987 - val_acc: 0.8619 - val_weighted_accuracy: 0.8541\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0227 - acc: 0.8643 - weighted_accuracy: 0.8586 - val_loss: 0.2879 - val_acc: 0.8693 - val_weighted_accuracy: 0.8591\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0222 - acc: 0.8685 - weighted_accuracy: 0.8629 - val_loss: 0.2902 - val_acc: 0.8672 - val_weighted_accuracy: 0.8597\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0219 - acc: 0.8711 - weighted_accuracy: 0.8661 - val_loss: 0.2957 - val_acc: 0.8653 - val_weighted_accuracy: 0.8603\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0216 - acc: 0.8725 - weighted_accuracy: 0.8677 - val_loss: 0.2874 - val_acc: 0.8714 - val_weighted_accuracy: 0.8630\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0215 - acc: 0.8740 - weighted_accuracy: 0.8692 - val_loss: 0.2823 - val_acc: 0.8757 - val_weighted_accuracy: 0.8658\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0213 - acc: 0.8761 - weighted_accuracy: 0.8714 - val_loss: 0.2827 - val_acc: 0.8722 - val_weighted_accuracy: 0.8642\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0210 - acc: 0.8778 - weighted_accuracy: 0.8737 - val_loss: 0.2893 - val_acc: 0.8699 - val_weighted_accuracy: 0.8638\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0209 - acc: 0.8790 - weighted_accuracy: 0.8747 - val_loss: 0.2790 - val_acc: 0.8760 - val_weighted_accuracy: 0.8660\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0207 - acc: 0.8800 - weighted_accuracy: 0.8758 - val_loss: 0.2779 - val_acc: 0.8753 - val_weighted_accuracy: 0.8666\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0206 - acc: 0.8813 - weighted_accuracy: 0.8774 - val_loss: 0.2734 - val_acc: 0.8789 - val_weighted_accuracy: 0.8668\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0205 - acc: 0.8821 - weighted_accuracy: 0.8783 - val_loss: 0.2764 - val_acc: 0.8778 - val_weighted_accuracy: 0.8694\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0203 - acc: 0.8831 - weighted_accuracy: 0.8794 - val_loss: 0.2734 - val_acc: 0.8775 - val_weighted_accuracy: 0.8698\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0202 - acc: 0.8838 - weighted_accuracy: 0.8798 - val_loss: 0.2756 - val_acc: 0.8804 - val_weighted_accuracy: 0.8682\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0201 - acc: 0.8844 - weighted_accuracy: 0.8808 - val_loss: 0.2849 - val_acc: 0.8737 - val_weighted_accuracy: 0.8684\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0200 - acc: 0.8851 - weighted_accuracy: 0.8816 - val_loss: 0.2779 - val_acc: 0.8763 - val_weighted_accuracy: 0.8714\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0198 - acc: 0.8863 - weighted_accuracy: 0.8831 - val_loss: 0.2670 - val_acc: 0.8808 - val_weighted_accuracy: 0.8705\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0198 - acc: 0.8871 - weighted_accuracy: 0.8837 - val_loss: 0.2749 - val_acc: 0.8787 - val_weighted_accuracy: 0.8717\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0198 - acc: 0.8868 - weighted_accuracy: 0.8835 - val_loss: 0.2849 - val_acc: 0.8730 - val_weighted_accuracy: 0.8663\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0197 - acc: 0.8873 - weighted_accuracy: 0.8841 - val_loss: 0.2691 - val_acc: 0.8804 - val_weighted_accuracy: 0.8729\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0195 - acc: 0.8894 - weighted_accuracy: 0.8863 - val_loss: 0.2704 - val_acc: 0.8801 - val_weighted_accuracy: 0.8724\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0195 - acc: 0.8889 - weighted_accuracy: 0.8860 - val_loss: 0.2800 - val_acc: 0.8759 - val_weighted_accuracy: 0.8708\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0193 - acc: 0.8899 - weighted_accuracy: 0.8874 - val_loss: 0.2691 - val_acc: 0.8812 - val_weighted_accuracy: 0.8725\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0193 - acc: 0.8898 - weighted_accuracy: 0.8870 - val_loss: 0.2737 - val_acc: 0.8773 - val_weighted_accuracy: 0.8689\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 78s 215us/step - loss: 0.0192 - acc: 0.8914 - weighted_accuracy: 0.8887 - val_loss: 0.2746 - val_acc: 0.8795 - val_weighted_accuracy: 0.8718\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0190 - acc: 0.8926 - weighted_accuracy: 0.8901 - val_loss: 0.2737 - val_acc: 0.8798 - val_weighted_accuracy: 0.8716\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0190 - acc: 0.8927 - weighted_accuracy: 0.8902 - val_loss: 0.2707 - val_acc: 0.8799 - val_weighted_accuracy: 0.8733\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0189 - acc: 0.8934 - weighted_accuracy: 0.8911 - val_loss: 0.2673 - val_acc: 0.8829 - val_weighted_accuracy: 0.8744\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0189 - acc: 0.8936 - weighted_accuracy: 0.8912 - val_loss: 0.2692 - val_acc: 0.8809 - val_weighted_accuracy: 0.8725\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0187 - acc: 0.8943 - weighted_accuracy: 0.8919 - val_loss: 0.2701 - val_acc: 0.8803 - val_weighted_accuracy: 0.8728\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0187 - acc: 0.8935 - weighted_accuracy: 0.8912 - val_loss: 0.2711 - val_acc: 0.8800 - val_weighted_accuracy: 0.8722\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0186 - acc: 0.8944 - weighted_accuracy: 0.8922 - val_loss: 0.2709 - val_acc: 0.8802 - val_weighted_accuracy: 0.8737\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0186 - acc: 0.8960 - weighted_accuracy: 0.8939 - val_loss: 0.2634 - val_acc: 0.8854 - val_weighted_accuracy: 0.8753\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0185 - acc: 0.8957 - weighted_accuracy: 0.8935 - val_loss: 0.2630 - val_acc: 0.8842 - val_weighted_accuracy: 0.8744\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0185 - acc: 0.8959 - weighted_accuracy: 0.8940 - val_loss: 0.2659 - val_acc: 0.8836 - val_weighted_accuracy: 0.8755\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0184 - acc: 0.8968 - weighted_accuracy: 0.8949 - val_loss: 0.2657 - val_acc: 0.8828 - val_weighted_accuracy: 0.8744\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0183 - acc: 0.8972 - weighted_accuracy: 0.8952 - val_loss: 0.2683 - val_acc: 0.8823 - val_weighted_accuracy: 0.8732\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0183 - acc: 0.8971 - weighted_accuracy: 0.8953 - val_loss: 0.2694 - val_acc: 0.8843 - val_weighted_accuracy: 0.8744\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0182 - acc: 0.8981 - weighted_accuracy: 0.8965 - val_loss: 0.2660 - val_acc: 0.8850 - val_weighted_accuracy: 0.8764\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0181 - acc: 0.8990 - weighted_accuracy: 0.8974 - val_loss: 0.2718 - val_acc: 0.8806 - val_weighted_accuracy: 0.8727\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0180 - acc: 0.8996 - weighted_accuracy: 0.8981 - val_loss: 0.2667 - val_acc: 0.8830 - val_weighted_accuracy: 0.8737\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0180 - acc: 0.8994 - weighted_accuracy: 0.8980 - val_loss: 0.2716 - val_acc: 0.8810 - val_weighted_accuracy: 0.8737\n",
      "Epoch 45/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0179 - acc: 0.9002 - weighted_accuracy: 0.8987 - val_loss: 0.2709 - val_acc: 0.8826 - val_weighted_accuracy: 0.8760\n",
      "Epoch 46/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0179 - acc: 0.9003 - weighted_accuracy: 0.8988 - val_loss: 0.2653 - val_acc: 0.8842 - val_weighted_accuracy: 0.8753\n",
      "Epoch 47/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0179 - acc: 0.9007 - weighted_accuracy: 0.8996 - val_loss: 0.2647 - val_acc: 0.8849 - val_weighted_accuracy: 0.8773\n",
      "Epoch 48/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0177 - acc: 0.9012 - weighted_accuracy: 0.9000 - val_loss: 0.2645 - val_acc: 0.8854 - val_weighted_accuracy: 0.8755\n",
      "Epoch 49/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0177 - acc: 0.9009 - weighted_accuracy: 0.8996 - val_loss: 0.2643 - val_acc: 0.8858 - val_weighted_accuracy: 0.8776\n",
      "Epoch 50/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0178 - acc: 0.9008 - weighted_accuracy: 0.8996 - val_loss: 0.2681 - val_acc: 0.8841 - val_weighted_accuracy: 0.8759\n",
      "Epoch 51/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0177 - acc: 0.9014 - weighted_accuracy: 0.9002 - val_loss: 0.2701 - val_acc: 0.8826 - val_weighted_accuracy: 0.8754\n",
      "Epoch 52/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0176 - acc: 0.9027 - weighted_accuracy: 0.9016 - val_loss: 0.2676 - val_acc: 0.8844 - val_weighted_accuracy: 0.8761\n",
      "Epoch 53/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0175 - acc: 0.9024 - weighted_accuracy: 0.9015 - val_loss: 0.2629 - val_acc: 0.8867 - val_weighted_accuracy: 0.8779\n",
      "Epoch 54/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0175 - acc: 0.9035 - weighted_accuracy: 0.9024 - val_loss: 0.2663 - val_acc: 0.8844 - val_weighted_accuracy: 0.8762\n",
      "Epoch 55/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0174 - acc: 0.9032 - weighted_accuracy: 0.9020 - val_loss: 0.2605 - val_acc: 0.8861 - val_weighted_accuracy: 0.8758\n",
      "Epoch 56/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0174 - acc: 0.9033 - weighted_accuracy: 0.9023 - val_loss: 0.2637 - val_acc: 0.8860 - val_weighted_accuracy: 0.8768\n",
      "Epoch 57/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0173 - acc: 0.9048 - weighted_accuracy: 0.9040 - val_loss: 0.2616 - val_acc: 0.8876 - val_weighted_accuracy: 0.8770\n",
      "Epoch 58/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0173 - acc: 0.9042 - weighted_accuracy: 0.9035 - val_loss: 0.2640 - val_acc: 0.8865 - val_weighted_accuracy: 0.8765\n",
      "Epoch 59/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0173 - acc: 0.9045 - weighted_accuracy: 0.9037 - val_loss: 0.2670 - val_acc: 0.8840 - val_weighted_accuracy: 0.8753\n",
      "Epoch 60/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0172 - acc: 0.9050 - weighted_accuracy: 0.9041 - val_loss: 0.2646 - val_acc: 0.8859 - val_weighted_accuracy: 0.8761\n",
      "Epoch 61/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0172 - acc: 0.9057 - weighted_accuracy: 0.9048 - val_loss: 0.2667 - val_acc: 0.8829 - val_weighted_accuracy: 0.8743\n",
      "Epoch 62/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0171 - acc: 0.9059 - weighted_accuracy: 0.9053 - val_loss: 0.2633 - val_acc: 0.8859 - val_weighted_accuracy: 0.8769\n",
      "Epoch 63/500\n",
      "365062/365062 [==============================] - 79s 215us/step - loss: 0.0172 - acc: 0.9051 - weighted_accuracy: 0.9043 - val_loss: 0.2683 - val_acc: 0.8816 - val_weighted_accuracy: 0.8741\n",
      "Epoch 64/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0170 - acc: 0.9063 - weighted_accuracy: 0.9058 - val_loss: 0.2700 - val_acc: 0.8839 - val_weighted_accuracy: 0.8763\n",
      "Epoch 65/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0171 - acc: 0.9055 - weighted_accuracy: 0.9049 - val_loss: 0.2645 - val_acc: 0.8866 - val_weighted_accuracy: 0.8775\n",
      "Epoch 66/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0170 - acc: 0.9063 - weighted_accuracy: 0.9057 - val_loss: 0.2622 - val_acc: 0.8859 - val_weighted_accuracy: 0.8768\n",
      "Epoch 67/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0169 - acc: 0.9066 - weighted_accuracy: 0.9061 - val_loss: 0.2701 - val_acc: 0.8827 - val_weighted_accuracy: 0.8754\n",
      "Epoch 68/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0169 - acc: 0.9068 - weighted_accuracy: 0.9064 - val_loss: 0.2739 - val_acc: 0.8805 - val_weighted_accuracy: 0.8726\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 50, 150)      0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 50, 150)      0           embedding_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 50, 50)       0           time_distributed_19[0][0]        \n",
      "                                                                 time_distributed_19[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 50, 50)       0           lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 50, 150)      0           permute_11[0][0]                 \n",
      "                                                                 time_distributed_19[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 50, 150)      0           lambda_41[0][0]                  \n",
      "                                                                 time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50, 150)      0           time_distributed_19[0][0]        \n",
      "                                                                 dot_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 50, 150)      0           time_distributed_19[0][0]        \n",
      "                                                                 dot_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50, 150)      0           time_distributed_19[1][0]        \n",
      "                                                                 dot_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 50, 150)      0           time_distributed_19[1][0]        \n",
      "                                                                 dot_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 50, 600)      0           time_distributed_19[0][0]        \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 lambda_43[0][0]                  \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 50, 600)      0           time_distributed_19[1][0]        \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 lambda_44[0][0]                  \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 50, 300)      180300      concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 50, 300)      180300      concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 50, 300)      0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 50, 300)      0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 50, 200)      60200       time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 50, 200)      60200       time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 50, 200)      0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 50, 200)      0           time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 200)          0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 200)          0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 200)          0           time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 200)          0           time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 400)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 400)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 800)          0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 800)          3200        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          205056      batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 256)          0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 256)          1024        dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 256)          65792       batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 256)          0           dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 256)          1024        dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 3)            771         batch_normalization_41[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 83s 227us/step - loss: 0.0279 - acc: 0.8291 - weighted_accuracy: 0.8201 - val_loss: 0.4250 - val_acc: 0.7950 - val_weighted_accuracy: 0.7989\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0239 - acc: 0.8563 - weighted_accuracy: 0.8490 - val_loss: 0.3442 - val_acc: 0.8357 - val_weighted_accuracy: 0.8314\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0229 - acc: 0.8635 - weighted_accuracy: 0.8571 - val_loss: 0.3453 - val_acc: 0.8367 - val_weighted_accuracy: 0.8332\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0224 - acc: 0.8670 - weighted_accuracy: 0.8612 - val_loss: 0.3385 - val_acc: 0.8397 - val_weighted_accuracy: 0.8357\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0220 - acc: 0.8704 - weighted_accuracy: 0.8649 - val_loss: 0.3316 - val_acc: 0.8458 - val_weighted_accuracy: 0.8392\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0216 - acc: 0.8735 - weighted_accuracy: 0.8683 - val_loss: 0.3411 - val_acc: 0.8391 - val_weighted_accuracy: 0.8353\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0214 - acc: 0.8753 - weighted_accuracy: 0.8702 - val_loss: 0.3318 - val_acc: 0.8447 - val_weighted_accuracy: 0.8387\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0211 - acc: 0.8775 - weighted_accuracy: 0.8726 - val_loss: 0.3359 - val_acc: 0.8407 - val_weighted_accuracy: 0.8359\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0210 - acc: 0.8785 - weighted_accuracy: 0.8738 - val_loss: 0.3439 - val_acc: 0.8343 - val_weighted_accuracy: 0.8326\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0207 - acc: 0.8807 - weighted_accuracy: 0.8762 - val_loss: 0.3295 - val_acc: 0.8472 - val_weighted_accuracy: 0.8425\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0205 - acc: 0.8815 - weighted_accuracy: 0.8772 - val_loss: 0.3264 - val_acc: 0.8482 - val_weighted_accuracy: 0.8432\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0203 - acc: 0.8834 - weighted_accuracy: 0.8788 - val_loss: 0.3297 - val_acc: 0.8481 - val_weighted_accuracy: 0.8436\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0202 - acc: 0.8843 - weighted_accuracy: 0.8800 - val_loss: 0.3234 - val_acc: 0.8512 - val_weighted_accuracy: 0.8446\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0202 - acc: 0.8848 - weighted_accuracy: 0.8808 - val_loss: 0.3172 - val_acc: 0.8515 - val_weighted_accuracy: 0.8458\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0200 - acc: 0.8860 - weighted_accuracy: 0.8821 - val_loss: 0.3264 - val_acc: 0.8466 - val_weighted_accuracy: 0.8433\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0198 - acc: 0.8868 - weighted_accuracy: 0.8830 - val_loss: 0.3292 - val_acc: 0.8461 - val_weighted_accuracy: 0.8432\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0197 - acc: 0.8878 - weighted_accuracy: 0.8839 - val_loss: 0.3156 - val_acc: 0.8532 - val_weighted_accuracy: 0.8454\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0196 - acc: 0.8884 - weighted_accuracy: 0.8846 - val_loss: 0.3279 - val_acc: 0.8468 - val_weighted_accuracy: 0.8440\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0195 - acc: 0.8901 - weighted_accuracy: 0.8865 - val_loss: 0.3111 - val_acc: 0.8546 - val_weighted_accuracy: 0.8473\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0194 - acc: 0.8904 - weighted_accuracy: 0.8870 - val_loss: 0.3325 - val_acc: 0.8476 - val_weighted_accuracy: 0.8457\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0194 - acc: 0.8908 - weighted_accuracy: 0.8875 - val_loss: 0.3198 - val_acc: 0.8499 - val_weighted_accuracy: 0.8444\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0193 - acc: 0.8909 - weighted_accuracy: 0.8878 - val_loss: 0.3127 - val_acc: 0.8561 - val_weighted_accuracy: 0.8506\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0191 - acc: 0.8926 - weighted_accuracy: 0.8892 - val_loss: 0.3237 - val_acc: 0.8515 - val_weighted_accuracy: 0.8479\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0190 - acc: 0.8935 - weighted_accuracy: 0.8907 - val_loss: 0.3131 - val_acc: 0.8567 - val_weighted_accuracy: 0.8510\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0189 - acc: 0.8932 - weighted_accuracy: 0.8905 - val_loss: 0.3145 - val_acc: 0.8551 - val_weighted_accuracy: 0.8505\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0189 - acc: 0.8939 - weighted_accuracy: 0.8910 - val_loss: 0.3150 - val_acc: 0.8560 - val_weighted_accuracy: 0.8504\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0188 - acc: 0.8950 - weighted_accuracy: 0.8922 - val_loss: 0.3209 - val_acc: 0.8513 - val_weighted_accuracy: 0.8477\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0188 - acc: 0.8946 - weighted_accuracy: 0.8919 - val_loss: 0.3230 - val_acc: 0.8510 - val_weighted_accuracy: 0.8465\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0186 - acc: 0.8957 - weighted_accuracy: 0.8928 - val_loss: 0.3238 - val_acc: 0.8487 - val_weighted_accuracy: 0.8465\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0186 - acc: 0.8956 - weighted_accuracy: 0.8929 - val_loss: 0.3162 - val_acc: 0.8536 - val_weighted_accuracy: 0.8496\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0185 - acc: 0.8967 - weighted_accuracy: 0.8942 - val_loss: 0.3168 - val_acc: 0.8555 - val_weighted_accuracy: 0.8488\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0185 - acc: 0.8972 - weighted_accuracy: 0.8947 - val_loss: 0.3122 - val_acc: 0.8564 - val_weighted_accuracy: 0.8512\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0183 - acc: 0.8981 - weighted_accuracy: 0.8958 - val_loss: 0.3207 - val_acc: 0.8518 - val_weighted_accuracy: 0.8485\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0182 - acc: 0.8981 - weighted_accuracy: 0.8958 - val_loss: 0.3112 - val_acc: 0.8582 - val_weighted_accuracy: 0.8530\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0182 - acc: 0.8983 - weighted_accuracy: 0.8959 - val_loss: 0.3256 - val_acc: 0.8501 - val_weighted_accuracy: 0.8455\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0181 - acc: 0.8990 - weighted_accuracy: 0.8971 - val_loss: 0.3190 - val_acc: 0.8528 - val_weighted_accuracy: 0.8460\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0180 - acc: 0.9001 - weighted_accuracy: 0.8978 - val_loss: 0.3229 - val_acc: 0.8521 - val_weighted_accuracy: 0.8475\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0180 - acc: 0.8994 - weighted_accuracy: 0.8973 - val_loss: 0.3178 - val_acc: 0.8543 - val_weighted_accuracy: 0.8482\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0180 - acc: 0.9003 - weighted_accuracy: 0.8982 - val_loss: 0.3235 - val_acc: 0.8509 - val_weighted_accuracy: 0.8462\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0179 - acc: 0.9005 - weighted_accuracy: 0.8986 - val_loss: 0.3171 - val_acc: 0.8546 - val_weighted_accuracy: 0.8505\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0178 - acc: 0.9010 - weighted_accuracy: 0.8991 - val_loss: 0.3157 - val_acc: 0.8554 - val_weighted_accuracy: 0.8516\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0178 - acc: 0.9018 - weighted_accuracy: 0.8998 - val_loss: 0.3243 - val_acc: 0.8487 - val_weighted_accuracy: 0.8453\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0177 - acc: 0.9018 - weighted_accuracy: 0.9001 - val_loss: 0.3131 - val_acc: 0.8562 - val_weighted_accuracy: 0.8490\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0177 - acc: 0.9026 - weighted_accuracy: 0.9009 - val_loss: 0.3145 - val_acc: 0.8560 - val_weighted_accuracy: 0.8506\n",
      "Epoch 45/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0176 - acc: 0.9030 - weighted_accuracy: 0.9011 - val_loss: 0.3173 - val_acc: 0.8552 - val_weighted_accuracy: 0.8513\n",
      "Epoch 46/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0175 - acc: 0.9030 - weighted_accuracy: 0.9013 - val_loss: 0.3201 - val_acc: 0.8533 - val_weighted_accuracy: 0.8495\n",
      "Epoch 47/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0175 - acc: 0.9034 - weighted_accuracy: 0.9019 - val_loss: 0.3141 - val_acc: 0.8569 - val_weighted_accuracy: 0.8500\n",
      "Epoch 48/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0175 - acc: 0.9043 - weighted_accuracy: 0.9028 - val_loss: 0.3145 - val_acc: 0.8566 - val_weighted_accuracy: 0.8511\n",
      "Epoch 49/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0174 - acc: 0.9040 - weighted_accuracy: 0.9025 - val_loss: 0.3139 - val_acc: 0.8566 - val_weighted_accuracy: 0.8499\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 50, 150)      0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 50, 150)      0           embedding_31[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 50, 50)       0           time_distributed_28[0][0]        \n",
      "                                                                 time_distributed_28[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 50, 50)       0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 50, 150)      0           permute_12[0][0]                 \n",
      "                                                                 time_distributed_28[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 50, 150)      0           lambda_45[0][0]                  \n",
      "                                                                 time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50, 150)      0           time_distributed_28[0][0]        \n",
      "                                                                 dot_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 50, 150)      0           time_distributed_28[0][0]        \n",
      "                                                                 dot_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50, 150)      0           time_distributed_28[1][0]        \n",
      "                                                                 dot_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 50, 150)      0           time_distributed_28[1][0]        \n",
      "                                                                 dot_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 50, 600)      0           time_distributed_28[0][0]        \n",
      "                                                                 dot_36[0][0]                     \n",
      "                                                                 lambda_47[0][0]                  \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 50, 600)      0           time_distributed_28[1][0]        \n",
      "                                                                 dot_35[0][0]                     \n",
      "                                                                 lambda_48[0][0]                  \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, 50, 300)      180300      concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, 50, 300)      180300      concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, 50, 300)      0           time_distributed_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, 50, 300)      0           time_distributed_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, 50, 200)      60200       time_distributed_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistri (None, 50, 200)      60200       time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, 50, 200)      0           time_distributed_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, 50, 200)      0           time_distributed_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 200)          0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 200)          0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 200)          0           time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 200)          0           time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 400)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 400)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 800)          0           concatenate_58[0][0]             \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 800)          3200        concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 256)          205056      batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 256)          0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 256)          1024        dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 256)          65792       batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 256)          0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 256)          1024        dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 3)            771         batch_normalization_44[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 83s 228us/step - loss: 0.0280 - acc: 0.8275 - weighted_accuracy: 0.8186 - val_loss: 0.3491 - val_acc: 0.8350 - val_weighted_accuracy: 0.8295\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0238 - acc: 0.8553 - weighted_accuracy: 0.8483 - val_loss: 0.3475 - val_acc: 0.8363 - val_weighted_accuracy: 0.8343\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0230 - acc: 0.8618 - weighted_accuracy: 0.8554 - val_loss: 0.3465 - val_acc: 0.8388 - val_weighted_accuracy: 0.8378\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0224 - acc: 0.8669 - weighted_accuracy: 0.8609 - val_loss: 0.3155 - val_acc: 0.8545 - val_weighted_accuracy: 0.8467\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0220 - acc: 0.8707 - weighted_accuracy: 0.8653 - val_loss: 0.3203 - val_acc: 0.8530 - val_weighted_accuracy: 0.8459\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0217 - acc: 0.8727 - weighted_accuracy: 0.8676 - val_loss: 0.3122 - val_acc: 0.8566 - val_weighted_accuracy: 0.8460\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0214 - acc: 0.8749 - weighted_accuracy: 0.8697 - val_loss: 0.3272 - val_acc: 0.8500 - val_weighted_accuracy: 0.8467\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 79s 216us/step - loss: 0.0211 - acc: 0.8769 - weighted_accuracy: 0.8722 - val_loss: 0.3191 - val_acc: 0.8557 - val_weighted_accuracy: 0.8477\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0210 - acc: 0.8777 - weighted_accuracy: 0.8733 - val_loss: 0.3259 - val_acc: 0.8495 - val_weighted_accuracy: 0.8443\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0208 - acc: 0.8794 - weighted_accuracy: 0.8750 - val_loss: 0.3094 - val_acc: 0.8568 - val_weighted_accuracy: 0.8505\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0206 - acc: 0.8812 - weighted_accuracy: 0.8768 - val_loss: 0.3124 - val_acc: 0.8564 - val_weighted_accuracy: 0.8502\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0205 - acc: 0.8814 - weighted_accuracy: 0.8770 - val_loss: 0.3202 - val_acc: 0.8505 - val_weighted_accuracy: 0.8483\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0203 - acc: 0.8831 - weighted_accuracy: 0.8792 - val_loss: 0.3146 - val_acc: 0.8561 - val_weighted_accuracy: 0.8509\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0203 - acc: 0.8841 - weighted_accuracy: 0.8799 - val_loss: 0.3060 - val_acc: 0.8623 - val_weighted_accuracy: 0.8545\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0203 - acc: 0.8830 - weighted_accuracy: 0.8786 - val_loss: 0.3083 - val_acc: 0.8603 - val_weighted_accuracy: 0.8534\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0200 - acc: 0.8857 - weighted_accuracy: 0.8818 - val_loss: 0.3021 - val_acc: 0.8628 - val_weighted_accuracy: 0.8563\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0199 - acc: 0.8871 - weighted_accuracy: 0.8834 - val_loss: 0.3154 - val_acc: 0.8560 - val_weighted_accuracy: 0.8513\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0198 - acc: 0.8869 - weighted_accuracy: 0.8833 - val_loss: 0.3131 - val_acc: 0.8569 - val_weighted_accuracy: 0.8495\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0197 - acc: 0.8881 - weighted_accuracy: 0.8844 - val_loss: 0.3084 - val_acc: 0.8611 - val_weighted_accuracy: 0.8536\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0196 - acc: 0.8888 - weighted_accuracy: 0.8854 - val_loss: 0.3095 - val_acc: 0.8602 - val_weighted_accuracy: 0.8553\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0194 - acc: 0.8898 - weighted_accuracy: 0.8864 - val_loss: 0.3258 - val_acc: 0.8510 - val_weighted_accuracy: 0.8505\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0193 - acc: 0.8902 - weighted_accuracy: 0.8870 - val_loss: 0.2989 - val_acc: 0.8667 - val_weighted_accuracy: 0.8578\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0192 - acc: 0.8913 - weighted_accuracy: 0.8884 - val_loss: 0.2988 - val_acc: 0.8664 - val_weighted_accuracy: 0.8583\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0192 - acc: 0.8913 - weighted_accuracy: 0.8884 - val_loss: 0.3075 - val_acc: 0.8612 - val_weighted_accuracy: 0.8568\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0191 - acc: 0.8914 - weighted_accuracy: 0.8885 - val_loss: 0.3040 - val_acc: 0.8616 - val_weighted_accuracy: 0.8555\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0190 - acc: 0.8926 - weighted_accuracy: 0.8896 - val_loss: 0.3037 - val_acc: 0.8601 - val_weighted_accuracy: 0.8544\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0190 - acc: 0.8925 - weighted_accuracy: 0.8895 - val_loss: 0.3180 - val_acc: 0.8533 - val_weighted_accuracy: 0.8505\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0189 - acc: 0.8939 - weighted_accuracy: 0.8910 - val_loss: 0.3070 - val_acc: 0.8608 - val_weighted_accuracy: 0.8562\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0188 - acc: 0.8947 - weighted_accuracy: 0.8919 - val_loss: 0.3085 - val_acc: 0.8594 - val_weighted_accuracy: 0.8547\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0186 - acc: 0.8953 - weighted_accuracy: 0.8925 - val_loss: 0.3142 - val_acc: 0.8598 - val_weighted_accuracy: 0.8542\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0187 - acc: 0.8946 - weighted_accuracy: 0.8918 - val_loss: 0.2965 - val_acc: 0.8668 - val_weighted_accuracy: 0.8578\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0186 - acc: 0.8953 - weighted_accuracy: 0.8928 - val_loss: 0.3097 - val_acc: 0.8604 - val_weighted_accuracy: 0.8566\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0185 - acc: 0.8955 - weighted_accuracy: 0.8931 - val_loss: 0.3083 - val_acc: 0.8590 - val_weighted_accuracy: 0.8545\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0184 - acc: 0.8975 - weighted_accuracy: 0.8953 - val_loss: 0.3037 - val_acc: 0.8631 - val_weighted_accuracy: 0.8567\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0183 - acc: 0.8973 - weighted_accuracy: 0.8950 - val_loss: 0.3055 - val_acc: 0.8598 - val_weighted_accuracy: 0.8541\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0182 - acc: 0.8984 - weighted_accuracy: 0.8961 - val_loss: 0.3073 - val_acc: 0.8626 - val_weighted_accuracy: 0.8565\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0182 - acc: 0.8977 - weighted_accuracy: 0.8956 - val_loss: 0.3031 - val_acc: 0.8617 - val_weighted_accuracy: 0.8545\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0182 - acc: 0.8987 - weighted_accuracy: 0.8965 - val_loss: 0.3129 - val_acc: 0.8573 - val_weighted_accuracy: 0.8548\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, 50, 150)      0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, 50, 150)      0           embedding_33[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 50, 50)       0           time_distributed_37[0][0]        \n",
      "                                                                 time_distributed_37[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 50, 50)       0           lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 50, 150)      0           permute_13[0][0]                 \n",
      "                                                                 time_distributed_37[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 50, 150)      0           lambda_49[0][0]                  \n",
      "                                                                 time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 150)      0           time_distributed_37[0][0]        \n",
      "                                                                 dot_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 50, 150)      0           time_distributed_37[0][0]        \n",
      "                                                                 dot_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 150)      0           time_distributed_37[1][0]        \n",
      "                                                                 dot_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 50, 150)      0           time_distributed_37[1][0]        \n",
      "                                                                 dot_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 50, 600)      0           time_distributed_37[0][0]        \n",
      "                                                                 dot_39[0][0]                     \n",
      "                                                                 lambda_51[0][0]                  \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 50, 600)      0           time_distributed_37[1][0]        \n",
      "                                                                 dot_38[0][0]                     \n",
      "                                                                 lambda_52[0][0]                  \n",
      "                                                                 multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, 50, 300)      180300      concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, 50, 300)      180300      concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, 50, 300)      0           time_distributed_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistri (None, 50, 300)      0           time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, 50, 200)      60200       time_distributed_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, 50, 200)      60200       time_distributed_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 50, 200)      0           time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistri (None, 50, 200)      0           time_distributed_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 200)          0           time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 200)          0           time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 200)          0           time_distributed_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 200)          0           time_distributed_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 400)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 400)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 800)          0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 800)          3200        concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 256)          205056      batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 256)          0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 256)          1024        dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 256)          65792       batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 256)          0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 256)          1024        dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 3)            771         batch_normalization_47[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 84s 229us/step - loss: 0.0281 - acc: 0.8277 - weighted_accuracy: 0.8186 - val_loss: 0.3466 - val_acc: 0.8335 - val_weighted_accuracy: 0.8277\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0238 - acc: 0.8557 - weighted_accuracy: 0.8490 - val_loss: 0.3314 - val_acc: 0.8420 - val_weighted_accuracy: 0.8327\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0229 - acc: 0.8626 - weighted_accuracy: 0.8564 - val_loss: 0.3306 - val_acc: 0.8453 - val_weighted_accuracy: 0.8380\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0223 - acc: 0.8677 - weighted_accuracy: 0.8619 - val_loss: 0.3121 - val_acc: 0.8539 - val_weighted_accuracy: 0.8400\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0219 - acc: 0.8705 - weighted_accuracy: 0.8653 - val_loss: 0.3231 - val_acc: 0.8499 - val_weighted_accuracy: 0.8421\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0216 - acc: 0.8741 - weighted_accuracy: 0.8688 - val_loss: 0.3317 - val_acc: 0.8435 - val_weighted_accuracy: 0.8419\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0216 - acc: 0.8745 - weighted_accuracy: 0.8694 - val_loss: 0.3221 - val_acc: 0.8524 - val_weighted_accuracy: 0.8464\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0212 - acc: 0.8768 - weighted_accuracy: 0.8721 - val_loss: 0.3255 - val_acc: 0.8460 - val_weighted_accuracy: 0.8432\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0210 - acc: 0.8788 - weighted_accuracy: 0.8741 - val_loss: 0.3127 - val_acc: 0.8562 - val_weighted_accuracy: 0.8486\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0208 - acc: 0.8800 - weighted_accuracy: 0.8755 - val_loss: 0.3125 - val_acc: 0.8541 - val_weighted_accuracy: 0.8471\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0206 - acc: 0.8813 - weighted_accuracy: 0.8771 - val_loss: 0.3062 - val_acc: 0.8584 - val_weighted_accuracy: 0.8491\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0204 - acc: 0.8824 - weighted_accuracy: 0.8782 - val_loss: 0.3099 - val_acc: 0.8572 - val_weighted_accuracy: 0.8496\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0203 - acc: 0.8843 - weighted_accuracy: 0.8800 - val_loss: 0.3296 - val_acc: 0.8442 - val_weighted_accuracy: 0.8423\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0202 - acc: 0.8843 - weighted_accuracy: 0.8805 - val_loss: 0.3165 - val_acc: 0.8544 - val_weighted_accuracy: 0.8494\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0201 - acc: 0.8853 - weighted_accuracy: 0.8816 - val_loss: 0.3082 - val_acc: 0.8592 - val_weighted_accuracy: 0.8497\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0199 - acc: 0.8863 - weighted_accuracy: 0.8827 - val_loss: 0.3074 - val_acc: 0.8594 - val_weighted_accuracy: 0.8494\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0198 - acc: 0.8869 - weighted_accuracy: 0.8834 - val_loss: 0.3142 - val_acc: 0.8532 - val_weighted_accuracy: 0.8482\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0197 - acc: 0.8881 - weighted_accuracy: 0.8846 - val_loss: 0.3042 - val_acc: 0.8603 - val_weighted_accuracy: 0.8509\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0196 - acc: 0.8889 - weighted_accuracy: 0.8854 - val_loss: 0.3138 - val_acc: 0.8554 - val_weighted_accuracy: 0.8501\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0195 - acc: 0.8892 - weighted_accuracy: 0.8860 - val_loss: 0.3161 - val_acc: 0.8523 - val_weighted_accuracy: 0.8484\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0194 - acc: 0.8895 - weighted_accuracy: 0.8865 - val_loss: 0.3088 - val_acc: 0.8564 - val_weighted_accuracy: 0.8518\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0194 - acc: 0.8907 - weighted_accuracy: 0.8879 - val_loss: 0.3149 - val_acc: 0.8532 - val_weighted_accuracy: 0.8495\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0193 - acc: 0.8914 - weighted_accuracy: 0.8882 - val_loss: 0.3091 - val_acc: 0.8569 - val_weighted_accuracy: 0.8526\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0192 - acc: 0.8916 - weighted_accuracy: 0.8888 - val_loss: 0.3005 - val_acc: 0.8586 - val_weighted_accuracy: 0.8520\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0190 - acc: 0.8927 - weighted_accuracy: 0.8899 - val_loss: 0.3105 - val_acc: 0.8554 - val_weighted_accuracy: 0.8513\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0190 - acc: 0.8927 - weighted_accuracy: 0.8898 - val_loss: 0.3034 - val_acc: 0.8600 - val_weighted_accuracy: 0.8523\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0189 - acc: 0.8932 - weighted_accuracy: 0.8904 - val_loss: 0.3119 - val_acc: 0.8562 - val_weighted_accuracy: 0.8519\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0189 - acc: 0.8940 - weighted_accuracy: 0.8915 - val_loss: 0.3048 - val_acc: 0.8610 - val_weighted_accuracy: 0.8550\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0188 - acc: 0.8945 - weighted_accuracy: 0.8919 - val_loss: 0.3095 - val_acc: 0.8564 - val_weighted_accuracy: 0.8517\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0187 - acc: 0.8948 - weighted_accuracy: 0.8924 - val_loss: 0.3093 - val_acc: 0.8558 - val_weighted_accuracy: 0.8493\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0186 - acc: 0.8956 - weighted_accuracy: 0.8933 - val_loss: 0.3060 - val_acc: 0.8612 - val_weighted_accuracy: 0.8546\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0185 - acc: 0.8965 - weighted_accuracy: 0.8943 - val_loss: 0.3009 - val_acc: 0.8637 - val_weighted_accuracy: 0.8550\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0185 - acc: 0.8959 - weighted_accuracy: 0.8936 - val_loss: 0.2987 - val_acc: 0.8643 - val_weighted_accuracy: 0.8547\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0184 - acc: 0.8974 - weighted_accuracy: 0.8952 - val_loss: 0.3031 - val_acc: 0.8618 - val_weighted_accuracy: 0.8549\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0183 - acc: 0.8975 - weighted_accuracy: 0.8952 - val_loss: 0.3101 - val_acc: 0.8593 - val_weighted_accuracy: 0.8536\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0182 - acc: 0.8982 - weighted_accuracy: 0.8962 - val_loss: 0.3035 - val_acc: 0.8600 - val_weighted_accuracy: 0.8528\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0182 - acc: 0.8984 - weighted_accuracy: 0.8964 - val_loss: 0.2973 - val_acc: 0.8649 - val_weighted_accuracy: 0.8553\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0181 - acc: 0.8987 - weighted_accuracy: 0.8969 - val_loss: 0.3007 - val_acc: 0.8638 - val_weighted_accuracy: 0.8556\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0180 - acc: 0.8990 - weighted_accuracy: 0.8971 - val_loss: 0.3053 - val_acc: 0.8598 - val_weighted_accuracy: 0.8547\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0180 - acc: 0.8999 - weighted_accuracy: 0.8982 - val_loss: 0.3034 - val_acc: 0.8593 - val_weighted_accuracy: 0.8530\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0180 - acc: 0.9003 - weighted_accuracy: 0.8986 - val_loss: 0.3036 - val_acc: 0.8605 - val_weighted_accuracy: 0.8538\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0178 - acc: 0.9006 - weighted_accuracy: 0.8989 - val_loss: 0.3093 - val_acc: 0.8570 - val_weighted_accuracy: 0.8507\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0179 - acc: 0.9007 - weighted_accuracy: 0.8991 - val_loss: 0.3054 - val_acc: 0.8589 - val_weighted_accuracy: 0.8518\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0178 - acc: 0.9013 - weighted_accuracy: 0.8998 - val_loss: 0.3085 - val_acc: 0.8579 - val_weighted_accuracy: 0.8540\n",
      "Epoch 45/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0178 - acc: 0.9012 - weighted_accuracy: 0.8997 - val_loss: 0.3049 - val_acc: 0.8602 - val_weighted_accuracy: 0.8536\n",
      "Epoch 46/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0177 - acc: 0.9021 - weighted_accuracy: 0.9008 - val_loss: 0.3113 - val_acc: 0.8572 - val_weighted_accuracy: 0.8526\n",
      "Epoch 47/500\n",
      "365062/365062 [==============================] - 80s 220us/step - loss: 0.0176 - acc: 0.9023 - weighted_accuracy: 0.9011 - val_loss: 0.3054 - val_acc: 0.8610 - val_weighted_accuracy: 0.8544\n",
      "Epoch 48/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0175 - acc: 0.9029 - weighted_accuracy: 0.9015 - val_loss: 0.3037 - val_acc: 0.8626 - val_weighted_accuracy: 0.8568\n",
      "Epoch 49/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0176 - acc: 0.9025 - weighted_accuracy: 0.9012 - val_loss: 0.3021 - val_acc: 0.8639 - val_weighted_accuracy: 0.8558\n",
      "Epoch 50/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0174 - acc: 0.9041 - weighted_accuracy: 0.9030 - val_loss: 0.3049 - val_acc: 0.8613 - val_weighted_accuracy: 0.8545\n",
      "Epoch 51/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0175 - acc: 0.9034 - weighted_accuracy: 0.9022 - val_loss: 0.3036 - val_acc: 0.8606 - val_weighted_accuracy: 0.8527\n",
      "Epoch 52/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0174 - acc: 0.9034 - weighted_accuracy: 0.9023 - val_loss: 0.3029 - val_acc: 0.8645 - val_weighted_accuracy: 0.8570\n",
      "Epoch 53/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0174 - acc: 0.9038 - weighted_accuracy: 0.9027 - val_loss: 0.3052 - val_acc: 0.8604 - val_weighted_accuracy: 0.8547\n",
      "Epoch 54/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0173 - acc: 0.9041 - weighted_accuracy: 0.9032 - val_loss: 0.3052 - val_acc: 0.8634 - val_weighted_accuracy: 0.8567\n",
      "Epoch 55/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0172 - acc: 0.9046 - weighted_accuracy: 0.9037 - val_loss: 0.3026 - val_acc: 0.8627 - val_weighted_accuracy: 0.8555\n",
      "Epoch 56/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0172 - acc: 0.9053 - weighted_accuracy: 0.9045 - val_loss: 0.3089 - val_acc: 0.8598 - val_weighted_accuracy: 0.8535\n",
      "Epoch 57/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0171 - acc: 0.9055 - weighted_accuracy: 0.9043 - val_loss: 0.3048 - val_acc: 0.8609 - val_weighted_accuracy: 0.8543\n",
      "Epoch 58/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0171 - acc: 0.9060 - weighted_accuracy: 0.9051 - val_loss: 0.3055 - val_acc: 0.8631 - val_weighted_accuracy: 0.8557\n",
      "Epoch 59/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0171 - acc: 0.9064 - weighted_accuracy: 0.9054 - val_loss: 0.2975 - val_acc: 0.8663 - val_weighted_accuracy: 0.8590\n",
      "Epoch 60/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0171 - acc: 0.9057 - weighted_accuracy: 0.9049 - val_loss: 0.3002 - val_acc: 0.8631 - val_weighted_accuracy: 0.8556\n",
      "Epoch 61/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0170 - acc: 0.9067 - weighted_accuracy: 0.9058 - val_loss: 0.3008 - val_acc: 0.8663 - val_weighted_accuracy: 0.8583\n",
      "Epoch 62/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0169 - acc: 0.9073 - weighted_accuracy: 0.9065 - val_loss: 0.3017 - val_acc: 0.8647 - val_weighted_accuracy: 0.8564\n",
      "Epoch 63/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0168 - acc: 0.9077 - weighted_accuracy: 0.9071 - val_loss: 0.3071 - val_acc: 0.8645 - val_weighted_accuracy: 0.8572\n",
      "Epoch 64/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0169 - acc: 0.9077 - weighted_accuracy: 0.9068 - val_loss: 0.3058 - val_acc: 0.8630 - val_weighted_accuracy: 0.8559\n",
      "Epoch 65/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0168 - acc: 0.9081 - weighted_accuracy: 0.9076 - val_loss: 0.3090 - val_acc: 0.8611 - val_weighted_accuracy: 0.8552\n",
      "Epoch 66/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0167 - acc: 0.9083 - weighted_accuracy: 0.9077 - val_loss: 0.3091 - val_acc: 0.8608 - val_weighted_accuracy: 0.8536\n",
      "Epoch 67/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0167 - acc: 0.9082 - weighted_accuracy: 0.9076 - val_loss: 0.3013 - val_acc: 0.8663 - val_weighted_accuracy: 0.8576\n",
      "Epoch 68/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0166 - acc: 0.9087 - weighted_accuracy: 0.9079 - val_loss: 0.3053 - val_acc: 0.8620 - val_weighted_accuracy: 0.8554\n",
      "Epoch 69/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0167 - acc: 0.9079 - weighted_accuracy: 0.9074 - val_loss: 0.3023 - val_acc: 0.8652 - val_weighted_accuracy: 0.8579\n",
      "Epoch 70/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0166 - acc: 0.9091 - weighted_accuracy: 0.9087 - val_loss: 0.3037 - val_acc: 0.8650 - val_weighted_accuracy: 0.8562\n",
      "Epoch 71/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0165 - acc: 0.9098 - weighted_accuracy: 0.9094 - val_loss: 0.3061 - val_acc: 0.8615 - val_weighted_accuracy: 0.8548\n",
      "Epoch 72/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0165 - acc: 0.9102 - weighted_accuracy: 0.9096 - val_loss: 0.3029 - val_acc: 0.8626 - val_weighted_accuracy: 0.8550\n",
      "Epoch 73/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0165 - acc: 0.9098 - weighted_accuracy: 0.9093 - val_loss: 0.3020 - val_acc: 0.8661 - val_weighted_accuracy: 0.8587\n",
      "Epoch 74/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0165 - acc: 0.9107 - weighted_accuracy: 0.9101 - val_loss: 0.3039 - val_acc: 0.8639 - val_weighted_accuracy: 0.8572\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_35 (SpatialDr (None, 50, 150)      0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 50, 150)      0           embedding_35[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 50, 50)       0           time_distributed_46[0][0]        \n",
      "                                                                 time_distributed_46[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 50, 50)       0           lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 50, 150)      0           permute_14[0][0]                 \n",
      "                                                                 time_distributed_46[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 50, 150)      0           lambda_53[0][0]                  \n",
      "                                                                 time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 150)      0           time_distributed_46[0][0]        \n",
      "                                                                 dot_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 50, 150)      0           time_distributed_46[0][0]        \n",
      "                                                                 dot_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 50, 150)      0           time_distributed_46[1][0]        \n",
      "                                                                 dot_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 50, 150)      0           time_distributed_46[1][0]        \n",
      "                                                                 dot_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 50, 600)      0           time_distributed_46[0][0]        \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 lambda_55[0][0]                  \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 50, 600)      0           time_distributed_46[1][0]        \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistri (None, 50, 300)      180300      concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistri (None, 50, 300)      180300      concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistri (None, 50, 300)      0           time_distributed_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, 50, 300)      0           time_distributed_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, 50, 200)      60200       time_distributed_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, 50, 200)      60200       time_distributed_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistri (None, 50, 200)      0           time_distributed_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistri (None, 50, 200)      0           time_distributed_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 200)          0           time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 200)          0           time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 200)          0           time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 200)          0           time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 400)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 400)          0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 800)          0           concatenate_68[0][0]             \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 800)          3200        concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 256)          205056      batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 256)          0           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256)          1024        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 256)          65792       batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 256)          0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 256)          1024        dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 3)            771         batch_normalization_50[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 84s 230us/step - loss: 0.0278 - acc: 0.8290 - weighted_accuracy: 0.8201 - val_loss: 0.3670 - val_acc: 0.8237 - val_weighted_accuracy: 0.8181\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0238 - acc: 0.8554 - weighted_accuracy: 0.8485 - val_loss: 0.3475 - val_acc: 0.8348 - val_weighted_accuracy: 0.8262\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0228 - acc: 0.8632 - weighted_accuracy: 0.8569 - val_loss: 0.3513 - val_acc: 0.8317 - val_weighted_accuracy: 0.8258\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0223 - acc: 0.8672 - weighted_accuracy: 0.8617 - val_loss: 0.3442 - val_acc: 0.8391 - val_weighted_accuracy: 0.8323\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 87s 239us/step - loss: 0.0218 - acc: 0.8715 - weighted_accuracy: 0.8660 - val_loss: 0.3373 - val_acc: 0.8405 - val_weighted_accuracy: 0.8338\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 91s 249us/step - loss: 0.0215 - acc: 0.8737 - weighted_accuracy: 0.8684 - val_loss: 0.3334 - val_acc: 0.8445 - val_weighted_accuracy: 0.8367\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 92s 252us/step - loss: 0.0213 - acc: 0.8766 - weighted_accuracy: 0.8714 - val_loss: 0.3503 - val_acc: 0.8375 - val_weighted_accuracy: 0.8338\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0210 - acc: 0.8789 - weighted_accuracy: 0.8737 - val_loss: 0.3379 - val_acc: 0.8433 - val_weighted_accuracy: 0.8376\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 85s 232us/step - loss: 0.0209 - acc: 0.8795 - weighted_accuracy: 0.8743 - val_loss: 0.3493 - val_acc: 0.8366 - val_weighted_accuracy: 0.8368\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 82s 225us/step - loss: 0.0208 - acc: 0.8796 - weighted_accuracy: 0.8746 - val_loss: 0.3319 - val_acc: 0.8469 - val_weighted_accuracy: 0.8404\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 80s 220us/step - loss: 0.0205 - acc: 0.8816 - weighted_accuracy: 0.8772 - val_loss: 0.3316 - val_acc: 0.8466 - val_weighted_accuracy: 0.8403\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 81s 223us/step - loss: 0.0203 - acc: 0.8836 - weighted_accuracy: 0.8791 - val_loss: 0.3349 - val_acc: 0.8444 - val_weighted_accuracy: 0.8373\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 83s 228us/step - loss: 0.0202 - acc: 0.8841 - weighted_accuracy: 0.8799 - val_loss: 0.3482 - val_acc: 0.8360 - val_weighted_accuracy: 0.8327\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0201 - acc: 0.8854 - weighted_accuracy: 0.8810 - val_loss: 0.3283 - val_acc: 0.8482 - val_weighted_accuracy: 0.8432\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 81s 222us/step - loss: 0.0200 - acc: 0.8857 - weighted_accuracy: 0.8817 - val_loss: 0.3329 - val_acc: 0.8456 - val_weighted_accuracy: 0.8411\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 84s 229us/step - loss: 0.0198 - acc: 0.8870 - weighted_accuracy: 0.8832 - val_loss: 0.3320 - val_acc: 0.8441 - val_weighted_accuracy: 0.8394\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 84s 229us/step - loss: 0.0196 - acc: 0.8880 - weighted_accuracy: 0.8842 - val_loss: 0.3298 - val_acc: 0.8478 - val_weighted_accuracy: 0.8403\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 81s 223us/step - loss: 0.0196 - acc: 0.8885 - weighted_accuracy: 0.8849 - val_loss: 0.3327 - val_acc: 0.8442 - val_weighted_accuracy: 0.8389\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 82s 224us/step - loss: 0.0196 - acc: 0.8884 - weighted_accuracy: 0.8847 - val_loss: 0.3208 - val_acc: 0.8539 - val_weighted_accuracy: 0.8450\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 83s 228us/step - loss: 0.0194 - acc: 0.8895 - weighted_accuracy: 0.8860 - val_loss: 0.3376 - val_acc: 0.8431 - val_weighted_accuracy: 0.8388\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 82s 224us/step - loss: 0.0193 - acc: 0.8910 - weighted_accuracy: 0.8875 - val_loss: 0.3363 - val_acc: 0.8467 - val_weighted_accuracy: 0.8421\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 82s 225us/step - loss: 0.0192 - acc: 0.8912 - weighted_accuracy: 0.8879 - val_loss: 0.3233 - val_acc: 0.8518 - val_weighted_accuracy: 0.8459\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0191 - acc: 0.8921 - weighted_accuracy: 0.8888 - val_loss: 0.3414 - val_acc: 0.8434 - val_weighted_accuracy: 0.8395\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0190 - acc: 0.8925 - weighted_accuracy: 0.8891 - val_loss: 0.3430 - val_acc: 0.8480 - val_weighted_accuracy: 0.8407\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 81s 222us/step - loss: 0.0190 - acc: 0.8927 - weighted_accuracy: 0.8895 - val_loss: 0.3251 - val_acc: 0.8514 - val_weighted_accuracy: 0.8450\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 80s 220us/step - loss: 0.0189 - acc: 0.8937 - weighted_accuracy: 0.8908 - val_loss: 0.3339 - val_acc: 0.8457 - val_weighted_accuracy: 0.8404\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0188 - acc: 0.8937 - weighted_accuracy: 0.8906 - val_loss: 0.3270 - val_acc: 0.8498 - val_weighted_accuracy: 0.8431\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 81s 222us/step - loss: 0.0188 - acc: 0.8947 - weighted_accuracy: 0.8917 - val_loss: 0.3244 - val_acc: 0.8513 - val_weighted_accuracy: 0.8429\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0187 - acc: 0.8948 - weighted_accuracy: 0.8918 - val_loss: 0.3171 - val_acc: 0.8541 - val_weighted_accuracy: 0.8469\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 85s 232us/step - loss: 0.0186 - acc: 0.8952 - weighted_accuracy: 0.8921 - val_loss: 0.3231 - val_acc: 0.8500 - val_weighted_accuracy: 0.8420\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 84s 229us/step - loss: 0.0185 - acc: 0.8961 - weighted_accuracy: 0.8934 - val_loss: 0.3206 - val_acc: 0.8518 - val_weighted_accuracy: 0.8456\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 86s 236us/step - loss: 0.0185 - acc: 0.8960 - weighted_accuracy: 0.8935 - val_loss: 0.3249 - val_acc: 0.8511 - val_weighted_accuracy: 0.8459\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0184 - acc: 0.8969 - weighted_accuracy: 0.8943 - val_loss: 0.3272 - val_acc: 0.8485 - val_weighted_accuracy: 0.8433\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0184 - acc: 0.8963 - weighted_accuracy: 0.8937 - val_loss: 0.3309 - val_acc: 0.8461 - val_weighted_accuracy: 0.8434\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 86s 235us/step - loss: 0.0184 - acc: 0.8971 - weighted_accuracy: 0.8947 - val_loss: 0.3277 - val_acc: 0.8473 - val_weighted_accuracy: 0.8438\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0182 - acc: 0.8983 - weighted_accuracy: 0.8958 - val_loss: 0.3260 - val_acc: 0.8510 - val_weighted_accuracy: 0.8456\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0182 - acc: 0.8992 - weighted_accuracy: 0.8967 - val_loss: 0.3273 - val_acc: 0.8496 - val_weighted_accuracy: 0.8457\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0181 - acc: 0.8985 - weighted_accuracy: 0.8963 - val_loss: 0.3223 - val_acc: 0.8502 - val_weighted_accuracy: 0.8411\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0180 - acc: 0.8993 - weighted_accuracy: 0.8972 - val_loss: 0.3200 - val_acc: 0.8523 - val_weighted_accuracy: 0.8444\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0180 - acc: 0.9002 - weighted_accuracy: 0.8981 - val_loss: 0.3269 - val_acc: 0.8492 - val_weighted_accuracy: 0.8443\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0179 - acc: 0.9000 - weighted_accuracy: 0.8980 - val_loss: 0.3294 - val_acc: 0.8487 - val_weighted_accuracy: 0.8435\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0178 - acc: 0.9012 - weighted_accuracy: 0.8992 - val_loss: 0.3222 - val_acc: 0.8517 - val_weighted_accuracy: 0.8440\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0178 - acc: 0.9013 - weighted_accuracy: 0.8993 - val_loss: 0.3226 - val_acc: 0.8519 - val_weighted_accuracy: 0.8453\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 79s 217us/step - loss: 0.0177 - acc: 0.9019 - weighted_accuracy: 0.9001 - val_loss: 0.3188 - val_acc: 0.8535 - val_weighted_accuracy: 0.8461\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 50, 150)      0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 50, 150)      0           embedding_37[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 50, 50)       0           time_distributed_55[0][0]        \n",
      "                                                                 time_distributed_55[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 50, 50)       0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 50, 150)      0           permute_15[0][0]                 \n",
      "                                                                 time_distributed_55[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 50, 150)      0           lambda_57[0][0]                  \n",
      "                                                                 time_distributed_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50, 150)      0           time_distributed_55[0][0]        \n",
      "                                                                 dot_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 50, 150)      0           time_distributed_55[0][0]        \n",
      "                                                                 dot_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 50, 150)      0           time_distributed_55[1][0]        \n",
      "                                                                 dot_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 50, 150)      0           time_distributed_55[1][0]        \n",
      "                                                                 dot_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 50, 600)      0           time_distributed_55[0][0]        \n",
      "                                                                 dot_45[0][0]                     \n",
      "                                                                 lambda_59[0][0]                  \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 50, 600)      0           time_distributed_55[1][0]        \n",
      "                                                                 dot_44[0][0]                     \n",
      "                                                                 lambda_60[0][0]                  \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, 50, 300)      180300      concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, 50, 300)      180300      concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 50, 300)      0           time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, 50, 300)      0           time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 50, 200)      60200       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, 50, 200)      60200       time_distributed_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 50, 200)      0           time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, 50, 200)      0           time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 200)          0           time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 200)          0           time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 200)          0           time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 200)          0           time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 400)          0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 400)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 800)          0           concatenate_73[0][0]             \n",
      "                                                                 concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 800)          3200        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 256)          205056      batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 256)          0           dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 256)          1024        dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 256)          65792       batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 256)          0           dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 256)          1024        dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 3)            771         batch_normalization_53[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 84s 230us/step - loss: 0.0279 - acc: 0.8289 - weighted_accuracy: 0.8195 - val_loss: 0.3788 - val_acc: 0.8208 - val_weighted_accuracy: 0.8073\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0237 - acc: 0.8561 - weighted_accuracy: 0.8493 - val_loss: 0.3625 - val_acc: 0.8225 - val_weighted_accuracy: 0.8123\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0229 - acc: 0.8627 - weighted_accuracy: 0.8566 - val_loss: 0.3600 - val_acc: 0.8279 - val_weighted_accuracy: 0.8191\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0223 - acc: 0.8680 - weighted_accuracy: 0.8622 - val_loss: 0.3449 - val_acc: 0.8358 - val_weighted_accuracy: 0.8233\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 84s 231us/step - loss: 0.0219 - acc: 0.8709 - weighted_accuracy: 0.8656 - val_loss: 0.3621 - val_acc: 0.8247 - val_weighted_accuracy: 0.8223\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 83s 229us/step - loss: 0.0216 - acc: 0.8730 - weighted_accuracy: 0.8678 - val_loss: 0.3511 - val_acc: 0.8308 - val_weighted_accuracy: 0.8233\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0213 - acc: 0.8750 - weighted_accuracy: 0.8701 - val_loss: 0.3674 - val_acc: 0.8216 - val_weighted_accuracy: 0.8157\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0211 - acc: 0.8765 - weighted_accuracy: 0.8715 - val_loss: 0.3422 - val_acc: 0.8350 - val_weighted_accuracy: 0.8229\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0209 - acc: 0.8786 - weighted_accuracy: 0.8738 - val_loss: 0.3412 - val_acc: 0.8369 - val_weighted_accuracy: 0.8272\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0207 - acc: 0.8809 - weighted_accuracy: 0.8762 - val_loss: 0.3510 - val_acc: 0.8317 - val_weighted_accuracy: 0.8261\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0205 - acc: 0.8817 - weighted_accuracy: 0.8772 - val_loss: 0.3470 - val_acc: 0.8360 - val_weighted_accuracy: 0.8228\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0204 - acc: 0.8825 - weighted_accuracy: 0.8783 - val_loss: 0.3569 - val_acc: 0.8311 - val_weighted_accuracy: 0.8264\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0203 - acc: 0.8839 - weighted_accuracy: 0.8800 - val_loss: 0.3487 - val_acc: 0.8368 - val_weighted_accuracy: 0.8254\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0201 - acc: 0.8851 - weighted_accuracy: 0.8810 - val_loss: 0.3379 - val_acc: 0.8410 - val_weighted_accuracy: 0.8298\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0200 - acc: 0.8861 - weighted_accuracy: 0.8821 - val_loss: 0.3386 - val_acc: 0.8416 - val_weighted_accuracy: 0.8330\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0198 - acc: 0.8872 - weighted_accuracy: 0.8832 - val_loss: 0.3419 - val_acc: 0.8386 - val_weighted_accuracy: 0.8309\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0198 - acc: 0.8873 - weighted_accuracy: 0.8836 - val_loss: 0.3415 - val_acc: 0.8405 - val_weighted_accuracy: 0.8317\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0196 - acc: 0.8882 - weighted_accuracy: 0.8846 - val_loss: 0.3574 - val_acc: 0.8333 - val_weighted_accuracy: 0.8300\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0195 - acc: 0.8890 - weighted_accuracy: 0.8856 - val_loss: 0.3343 - val_acc: 0.8424 - val_weighted_accuracy: 0.8327\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0194 - acc: 0.8901 - weighted_accuracy: 0.8868 - val_loss: 0.3294 - val_acc: 0.8431 - val_weighted_accuracy: 0.8334\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0193 - acc: 0.8914 - weighted_accuracy: 0.8880 - val_loss: 0.3347 - val_acc: 0.8426 - val_weighted_accuracy: 0.8329\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0192 - acc: 0.8920 - weighted_accuracy: 0.8890 - val_loss: 0.3410 - val_acc: 0.8379 - val_weighted_accuracy: 0.8315\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0191 - acc: 0.8924 - weighted_accuracy: 0.8893 - val_loss: 0.3412 - val_acc: 0.8386 - val_weighted_accuracy: 0.8318\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0190 - acc: 0.8937 - weighted_accuracy: 0.8908 - val_loss: 0.3354 - val_acc: 0.8421 - val_weighted_accuracy: 0.8300\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0189 - acc: 0.8943 - weighted_accuracy: 0.8914 - val_loss: 0.3452 - val_acc: 0.8377 - val_weighted_accuracy: 0.8291\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0189 - acc: 0.8938 - weighted_accuracy: 0.8910 - val_loss: 0.3340 - val_acc: 0.8435 - val_weighted_accuracy: 0.8340\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0188 - acc: 0.8947 - weighted_accuracy: 0.8921 - val_loss: 0.3351 - val_acc: 0.8409 - val_weighted_accuracy: 0.8329\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0187 - acc: 0.8951 - weighted_accuracy: 0.8925 - val_loss: 0.3351 - val_acc: 0.8435 - val_weighted_accuracy: 0.8323\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0186 - acc: 0.8955 - weighted_accuracy: 0.8927 - val_loss: 0.3404 - val_acc: 0.8415 - val_weighted_accuracy: 0.8339\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0186 - acc: 0.8952 - weighted_accuracy: 0.8924 - val_loss: 0.3359 - val_acc: 0.8435 - val_weighted_accuracy: 0.8344\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0185 - acc: 0.8967 - weighted_accuracy: 0.8943 - val_loss: 0.3335 - val_acc: 0.8444 - val_weighted_accuracy: 0.8327\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0184 - acc: 0.8970 - weighted_accuracy: 0.8946 - val_loss: 0.3386 - val_acc: 0.8449 - val_weighted_accuracy: 0.8364\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0183 - acc: 0.8977 - weighted_accuracy: 0.8953 - val_loss: 0.3293 - val_acc: 0.8489 - val_weighted_accuracy: 0.8366\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0182 - acc: 0.8983 - weighted_accuracy: 0.8960 - val_loss: 0.3330 - val_acc: 0.8444 - val_weighted_accuracy: 0.8333\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0182 - acc: 0.8988 - weighted_accuracy: 0.8967 - val_loss: 0.3372 - val_acc: 0.8452 - val_weighted_accuracy: 0.8359\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0181 - acc: 0.8990 - weighted_accuracy: 0.8966 - val_loss: 0.3337 - val_acc: 0.8452 - val_weighted_accuracy: 0.8333\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0180 - acc: 0.8998 - weighted_accuracy: 0.8978 - val_loss: 0.3351 - val_acc: 0.8449 - val_weighted_accuracy: 0.8351\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0181 - acc: 0.8994 - weighted_accuracy: 0.8972 - val_loss: 0.3419 - val_acc: 0.8429 - val_weighted_accuracy: 0.8332\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0179 - acc: 0.9003 - weighted_accuracy: 0.8985 - val_loss: 0.3363 - val_acc: 0.8442 - val_weighted_accuracy: 0.8341\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0179 - acc: 0.9005 - weighted_accuracy: 0.8984 - val_loss: 0.3400 - val_acc: 0.8435 - val_weighted_accuracy: 0.8352\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0178 - acc: 0.9012 - weighted_accuracy: 0.8995 - val_loss: 0.3345 - val_acc: 0.8450 - val_weighted_accuracy: 0.8347\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0178 - acc: 0.9012 - weighted_accuracy: 0.8992 - val_loss: 0.3415 - val_acc: 0.8425 - val_weighted_accuracy: 0.8361\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0177 - acc: 0.9014 - weighted_accuracy: 0.8996 - val_loss: 0.3354 - val_acc: 0.8435 - val_weighted_accuracy: 0.8349\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0176 - acc: 0.9028 - weighted_accuracy: 0.9012 - val_loss: 0.3311 - val_acc: 0.8479 - val_weighted_accuracy: 0.8377\n",
      "Epoch 45/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0175 - acc: 0.9030 - weighted_accuracy: 0.9014 - val_loss: 0.3381 - val_acc: 0.8440 - val_weighted_accuracy: 0.8341\n",
      "Epoch 46/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0175 - acc: 0.9035 - weighted_accuracy: 0.9021 - val_loss: 0.3357 - val_acc: 0.8439 - val_weighted_accuracy: 0.8352\n",
      "Epoch 47/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0175 - acc: 0.9031 - weighted_accuracy: 0.9016 - val_loss: 0.3282 - val_acc: 0.8490 - val_weighted_accuracy: 0.8374\n",
      "Epoch 48/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0174 - acc: 0.9034 - weighted_accuracy: 0.9021 - val_loss: 0.3318 - val_acc: 0.8473 - val_weighted_accuracy: 0.8388\n",
      "Epoch 49/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0173 - acc: 0.9046 - weighted_accuracy: 0.9031 - val_loss: 0.3285 - val_acc: 0.8477 - val_weighted_accuracy: 0.8384\n",
      "Epoch 50/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0174 - acc: 0.9040 - weighted_accuracy: 0.9026 - val_loss: 0.3306 - val_acc: 0.8477 - val_weighted_accuracy: 0.8373\n",
      "Epoch 51/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0173 - acc: 0.9043 - weighted_accuracy: 0.9029 - val_loss: 0.3341 - val_acc: 0.8472 - val_weighted_accuracy: 0.8387\n",
      "Epoch 52/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0172 - acc: 0.9052 - weighted_accuracy: 0.9037 - val_loss: 0.3352 - val_acc: 0.8483 - val_weighted_accuracy: 0.8367\n",
      "Epoch 53/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0171 - acc: 0.9059 - weighted_accuracy: 0.9045 - val_loss: 0.3386 - val_acc: 0.8437 - val_weighted_accuracy: 0.8358\n",
      "Epoch 54/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0171 - acc: 0.9060 - weighted_accuracy: 0.9047 - val_loss: 0.3376 - val_acc: 0.8450 - val_weighted_accuracy: 0.8332\n",
      "Epoch 55/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0171 - acc: 0.9057 - weighted_accuracy: 0.9046 - val_loss: 0.3268 - val_acc: 0.8489 - val_weighted_accuracy: 0.8389\n",
      "Epoch 56/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0170 - acc: 0.9058 - weighted_accuracy: 0.9047 - val_loss: 0.3339 - val_acc: 0.8477 - val_weighted_accuracy: 0.8384\n",
      "Epoch 57/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0170 - acc: 0.9070 - weighted_accuracy: 0.9058 - val_loss: 0.3280 - val_acc: 0.8481 - val_weighted_accuracy: 0.8372\n",
      "Epoch 58/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0169 - acc: 0.9073 - weighted_accuracy: 0.9064 - val_loss: 0.3319 - val_acc: 0.8490 - val_weighted_accuracy: 0.8374\n",
      "Epoch 59/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0169 - acc: 0.9072 - weighted_accuracy: 0.9061 - val_loss: 0.3322 - val_acc: 0.8499 - val_weighted_accuracy: 0.8374\n",
      "Epoch 60/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0168 - acc: 0.9077 - weighted_accuracy: 0.9069 - val_loss: 0.3377 - val_acc: 0.8460 - val_weighted_accuracy: 0.8368\n",
      "Epoch 61/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0168 - acc: 0.9077 - weighted_accuracy: 0.9068 - val_loss: 0.3397 - val_acc: 0.8436 - val_weighted_accuracy: 0.8348\n",
      "Epoch 62/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0167 - acc: 0.9081 - weighted_accuracy: 0.9072 - val_loss: 0.3344 - val_acc: 0.8466 - val_weighted_accuracy: 0.8361\n",
      "Epoch 63/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0167 - acc: 0.9091 - weighted_accuracy: 0.9084 - val_loss: 0.3372 - val_acc: 0.8434 - val_weighted_accuracy: 0.8331\n",
      "Epoch 64/500\n",
      "365062/365062 [==============================] - 79s 218us/step - loss: 0.0166 - acc: 0.9092 - weighted_accuracy: 0.9084 - val_loss: 0.3334 - val_acc: 0.8455 - val_weighted_accuracy: 0.8361\n",
      "Epoch 65/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0166 - acc: 0.9089 - weighted_accuracy: 0.9084 - val_loss: 0.3302 - val_acc: 0.8501 - val_weighted_accuracy: 0.8351\n",
      "Epoch 66/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0166 - acc: 0.9095 - weighted_accuracy: 0.9087 - val_loss: 0.3357 - val_acc: 0.8482 - val_weighted_accuracy: 0.8375\n",
      "Epoch 67/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0165 - acc: 0.9100 - weighted_accuracy: 0.9095 - val_loss: 0.3354 - val_acc: 0.8459 - val_weighted_accuracy: 0.8369\n",
      "Epoch 68/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0165 - acc: 0.9105 - weighted_accuracy: 0.9100 - val_loss: 0.3304 - val_acc: 0.8518 - val_weighted_accuracy: 0.8379\n",
      "Epoch 69/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0165 - acc: 0.9100 - weighted_accuracy: 0.9093 - val_loss: 0.3305 - val_acc: 0.8498 - val_weighted_accuracy: 0.8372\n",
      "Epoch 70/500\n",
      "365062/365062 [==============================] - 80s 218us/step - loss: 0.0164 - acc: 0.9102 - weighted_accuracy: 0.9096 - val_loss: 0.3378 - val_acc: 0.8463 - val_weighted_accuracy: 0.8351\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 50, 150)      0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_40 (SpatialDr (None, 50, 150)      0           embedding_39[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_39[0][0]       \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 50, 50)       0           time_distributed_64[0][0]        \n",
      "                                                                 time_distributed_64[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 50, 50)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 50, 150)      0           permute_16[0][0]                 \n",
      "                                                                 time_distributed_64[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 50, 150)      0           lambda_61[0][0]                  \n",
      "                                                                 time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 50, 150)      0           time_distributed_64[0][0]        \n",
      "                                                                 dot_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 50, 150)      0           time_distributed_64[0][0]        \n",
      "                                                                 dot_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50, 150)      0           time_distributed_64[1][0]        \n",
      "                                                                 dot_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 50, 150)      0           time_distributed_64[1][0]        \n",
      "                                                                 dot_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 50, 600)      0           time_distributed_64[0][0]        \n",
      "                                                                 dot_48[0][0]                     \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 50, 600)      0           time_distributed_64[1][0]        \n",
      "                                                                 dot_47[0][0]                     \n",
      "                                                                 lambda_64[0][0]                  \n",
      "                                                                 multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistri (None, 50, 300)      180300      concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, 50, 300)      180300      concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, 50, 300)      0           time_distributed_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_70 (TimeDistri (None, 50, 300)      0           time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 50, 200)      60200       time_distributed_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_71 (TimeDistri (None, 50, 200)      60200       time_distributed_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 50, 200)      0           time_distributed_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_72 (TimeDistri (None, 50, 200)      0           time_distributed_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 200)          0           time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 200)          0           time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 200)          0           time_distributed_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 200)          0           time_distributed_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 400)          0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 400)          0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 800)          0           concatenate_78[0][0]             \n",
      "                                                                 concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 800)          3200        concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 256)          205056      batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 256)          0           dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 256)          1024        dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 256)          65792       batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 256)          0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256)          1024        dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 3)            771         batch_normalization_56[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365062 samples, validate on 35616 samples\n",
      "Epoch 1/500\n",
      "365062/365062 [==============================] - 85s 232us/step - loss: 0.0279 - acc: 0.8283 - weighted_accuracy: 0.8190 - val_loss: 0.3614 - val_acc: 0.8254 - val_weighted_accuracy: 0.8259\n",
      "Epoch 2/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0238 - acc: 0.8546 - weighted_accuracy: 0.8474 - val_loss: 0.3373 - val_acc: 0.8432 - val_weighted_accuracy: 0.8386\n",
      "Epoch 3/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0230 - acc: 0.8617 - weighted_accuracy: 0.8551 - val_loss: 0.3670 - val_acc: 0.8247 - val_weighted_accuracy: 0.8289\n",
      "Epoch 4/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0225 - acc: 0.8661 - weighted_accuracy: 0.8599 - val_loss: 0.3512 - val_acc: 0.8345 - val_weighted_accuracy: 0.8370\n",
      "Epoch 5/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0220 - acc: 0.8699 - weighted_accuracy: 0.8641 - val_loss: 0.3322 - val_acc: 0.8475 - val_weighted_accuracy: 0.8460\n",
      "Epoch 6/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0217 - acc: 0.8721 - weighted_accuracy: 0.8667 - val_loss: 0.3421 - val_acc: 0.8409 - val_weighted_accuracy: 0.8421\n",
      "Epoch 7/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0214 - acc: 0.8745 - weighted_accuracy: 0.8692 - val_loss: 0.3248 - val_acc: 0.8519 - val_weighted_accuracy: 0.8499\n",
      "Epoch 8/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0212 - acc: 0.8764 - weighted_accuracy: 0.8715 - val_loss: 0.3286 - val_acc: 0.8512 - val_weighted_accuracy: 0.8512\n",
      "Epoch 9/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0211 - acc: 0.8766 - weighted_accuracy: 0.8715 - val_loss: 0.3277 - val_acc: 0.8491 - val_weighted_accuracy: 0.8488\n",
      "Epoch 10/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0208 - acc: 0.8798 - weighted_accuracy: 0.8753 - val_loss: 0.3130 - val_acc: 0.8573 - val_weighted_accuracy: 0.8522\n",
      "Epoch 11/500\n",
      "365062/365062 [==============================] - 80s 219us/step - loss: 0.0207 - acc: 0.8801 - weighted_accuracy: 0.8756 - val_loss: 0.3116 - val_acc: 0.8586 - val_weighted_accuracy: 0.8517\n",
      "Epoch 12/500\n",
      "365062/365062 [==============================] - 83s 227us/step - loss: 0.0205 - acc: 0.8813 - weighted_accuracy: 0.8769 - val_loss: 0.3155 - val_acc: 0.8563 - val_weighted_accuracy: 0.8542\n",
      "Epoch 13/500\n",
      "365062/365062 [==============================] - 82s 224us/step - loss: 0.0203 - acc: 0.8827 - weighted_accuracy: 0.8784 - val_loss: 0.3230 - val_acc: 0.8494 - val_weighted_accuracy: 0.8500\n",
      "Epoch 14/500\n",
      "365062/365062 [==============================] - 80s 221us/step - loss: 0.0202 - acc: 0.8835 - weighted_accuracy: 0.8793 - val_loss: 0.3108 - val_acc: 0.8587 - val_weighted_accuracy: 0.8568\n",
      "Epoch 15/500\n",
      "365062/365062 [==============================] - 81s 221us/step - loss: 0.0201 - acc: 0.8845 - weighted_accuracy: 0.8804 - val_loss: 0.3315 - val_acc: 0.8472 - val_weighted_accuracy: 0.8497\n",
      "Epoch 16/500\n",
      "365062/365062 [==============================] - 82s 226us/step - loss: 0.0200 - acc: 0.8858 - weighted_accuracy: 0.8819 - val_loss: 0.3138 - val_acc: 0.8565 - val_weighted_accuracy: 0.8549\n",
      "Epoch 17/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0198 - acc: 0.8863 - weighted_accuracy: 0.8827 - val_loss: 0.3117 - val_acc: 0.8581 - val_weighted_accuracy: 0.8564\n",
      "Epoch 18/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0197 - acc: 0.8879 - weighted_accuracy: 0.8844 - val_loss: 0.3068 - val_acc: 0.8598 - val_weighted_accuracy: 0.8563\n",
      "Epoch 19/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0196 - acc: 0.8884 - weighted_accuracy: 0.8847 - val_loss: 0.3197 - val_acc: 0.8541 - val_weighted_accuracy: 0.8539\n",
      "Epoch 20/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0195 - acc: 0.8887 - weighted_accuracy: 0.8852 - val_loss: 0.3131 - val_acc: 0.8572 - val_weighted_accuracy: 0.8552\n",
      "Epoch 21/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0194 - acc: 0.8893 - weighted_accuracy: 0.8859 - val_loss: 0.3131 - val_acc: 0.8581 - val_weighted_accuracy: 0.8556\n",
      "Epoch 22/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0193 - acc: 0.8899 - weighted_accuracy: 0.8866 - val_loss: 0.3107 - val_acc: 0.8578 - val_weighted_accuracy: 0.8565\n",
      "Epoch 23/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0193 - acc: 0.8907 - weighted_accuracy: 0.8876 - val_loss: 0.3082 - val_acc: 0.8603 - val_weighted_accuracy: 0.8587\n",
      "Epoch 24/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0191 - acc: 0.8918 - weighted_accuracy: 0.8887 - val_loss: 0.2990 - val_acc: 0.8648 - val_weighted_accuracy: 0.8589\n",
      "Epoch 25/500\n",
      "365062/365062 [==============================] - 85s 234us/step - loss: 0.0191 - acc: 0.8919 - weighted_accuracy: 0.8887 - val_loss: 0.3078 - val_acc: 0.8600 - val_weighted_accuracy: 0.8596\n",
      "Epoch 26/500\n",
      "365062/365062 [==============================] - 86s 236us/step - loss: 0.0190 - acc: 0.8931 - weighted_accuracy: 0.8902 - val_loss: 0.3033 - val_acc: 0.8619 - val_weighted_accuracy: 0.8592\n",
      "Epoch 27/500\n",
      "365062/365062 [==============================] - 87s 240us/step - loss: 0.0189 - acc: 0.8929 - weighted_accuracy: 0.8901 - val_loss: 0.3099 - val_acc: 0.8603 - val_weighted_accuracy: 0.8589\n",
      "Epoch 28/500\n",
      "365062/365062 [==============================] - 87s 238us/step - loss: 0.0188 - acc: 0.8940 - weighted_accuracy: 0.8914 - val_loss: 0.3036 - val_acc: 0.8637 - val_weighted_accuracy: 0.8608\n",
      "Epoch 29/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0188 - acc: 0.8945 - weighted_accuracy: 0.8917 - val_loss: 0.3016 - val_acc: 0.8644 - val_weighted_accuracy: 0.8619\n",
      "Epoch 30/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0187 - acc: 0.8946 - weighted_accuracy: 0.8920 - val_loss: 0.3096 - val_acc: 0.8598 - val_weighted_accuracy: 0.8593\n",
      "Epoch 31/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0187 - acc: 0.8950 - weighted_accuracy: 0.8925 - val_loss: 0.3057 - val_acc: 0.8616 - val_weighted_accuracy: 0.8604\n",
      "Epoch 32/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0186 - acc: 0.8955 - weighted_accuracy: 0.8931 - val_loss: 0.3156 - val_acc: 0.8576 - val_weighted_accuracy: 0.8569\n",
      "Epoch 33/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0185 - acc: 0.8963 - weighted_accuracy: 0.8938 - val_loss: 0.3075 - val_acc: 0.8610 - val_weighted_accuracy: 0.8569\n",
      "Epoch 34/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0185 - acc: 0.8961 - weighted_accuracy: 0.8938 - val_loss: 0.3120 - val_acc: 0.8591 - val_weighted_accuracy: 0.8576\n",
      "Epoch 35/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0184 - acc: 0.8967 - weighted_accuracy: 0.8947 - val_loss: 0.3055 - val_acc: 0.8602 - val_weighted_accuracy: 0.8571\n",
      "Epoch 36/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0182 - acc: 0.8980 - weighted_accuracy: 0.8960 - val_loss: 0.3150 - val_acc: 0.8562 - val_weighted_accuracy: 0.8553\n",
      "Epoch 37/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0182 - acc: 0.8976 - weighted_accuracy: 0.8956 - val_loss: 0.3158 - val_acc: 0.8576 - val_weighted_accuracy: 0.8573\n",
      "Epoch 38/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0182 - acc: 0.8980 - weighted_accuracy: 0.8958 - val_loss: 0.3049 - val_acc: 0.8627 - val_weighted_accuracy: 0.8589\n",
      "Epoch 39/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0181 - acc: 0.8995 - weighted_accuracy: 0.8971 - val_loss: 0.3210 - val_acc: 0.8530 - val_weighted_accuracy: 0.8531\n",
      "Epoch 40/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0181 - acc: 0.8995 - weighted_accuracy: 0.8976 - val_loss: 0.3018 - val_acc: 0.8642 - val_weighted_accuracy: 0.8603\n",
      "Epoch 41/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0180 - acc: 0.9000 - weighted_accuracy: 0.8978 - val_loss: 0.3101 - val_acc: 0.8578 - val_weighted_accuracy: 0.8564\n",
      "Epoch 42/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0179 - acc: 0.8997 - weighted_accuracy: 0.8978 - val_loss: 0.3060 - val_acc: 0.8601 - val_weighted_accuracy: 0.8573\n",
      "Epoch 43/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0179 - acc: 0.9001 - weighted_accuracy: 0.8987 - val_loss: 0.3080 - val_acc: 0.8597 - val_weighted_accuracy: 0.8572\n",
      "Epoch 44/500\n",
      "365062/365062 [==============================] - 85s 233us/step - loss: 0.0179 - acc: 0.9004 - weighted_accuracy: 0.8987 - val_loss: 0.3101 - val_acc: 0.8603 - val_weighted_accuracy: 0.8583\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_41 (SpatialDr (None, 50, 150)      0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_42 (SpatialDr (None, 50, 150)      0           embedding_41[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_73 (TimeDistri (None, 50, 150)      45300       spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 50, 50)       0           time_distributed_73[0][0]        \n",
      "                                                                 time_distributed_73[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 50, 50)       0           lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 50, 150)      0           permute_17[0][0]                 \n",
      "                                                                 time_distributed_73[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 50, 150)      0           lambda_65[0][0]                  \n",
      "                                                                 time_distributed_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 50, 150)      0           time_distributed_73[0][0]        \n",
      "                                                                 dot_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 50, 150)      0           time_distributed_73[0][0]        \n",
      "                                                                 dot_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50, 150)      0           time_distributed_73[1][0]        \n",
      "                                                                 dot_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 50, 150)      0           time_distributed_73[1][0]        \n",
      "                                                                 dot_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 50, 600)      0           time_distributed_73[0][0]        \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 50, 600)      0           time_distributed_73[1][0]        \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 lambda_68[0][0]                  \n",
      "                                                                 multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_74 (TimeDistri (None, 50, 300)      180300      concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_78 (TimeDistri (None, 50, 300)      180300      concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_75 (TimeDistri (None, 50, 300)      0           time_distributed_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_79 (TimeDistri (None, 50, 300)      0           time_distributed_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_76 (TimeDistri (None, 50, 200)      60200       time_distributed_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_80 (TimeDistri (None, 50, 200)      60200       time_distributed_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_77 (TimeDistri (None, 50, 200)      0           time_distributed_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_81 (TimeDistri (None, 50, 200)      0           time_distributed_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 200)          0           time_distributed_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 200)          0           time_distributed_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 200)          0           time_distributed_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 200)          0           time_distributed_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 400)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_max_pooling1d_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 400)          0           global_average_pooling1d_34[0][0]\n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 800)          0           concatenate_83[0][0]             \n",
      "                                                                 concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 800)          3200        concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 256)          205056      batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 256)          0           dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 256)          1024        dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 256)          65792       batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 256)          0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 256)          1024        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 3)            771         batch_normalization_59[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,312,667\n",
      "Trainable params: 560,043\n",
      "Non-trainable params: 752,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 365054 samples, validate on 35624 samples\n",
      "Epoch 1/500\n",
      "365054/365054 [==============================] - 90s 247us/step - loss: 0.0282 - acc: 0.8261 - weighted_accuracy: 0.8174 - val_loss: 0.3971 - val_acc: 0.8074 - val_weighted_accuracy: 0.8102\n",
      "Epoch 2/500\n",
      "365054/365054 [==============================] - 85s 233us/step - loss: 0.0240 - acc: 0.8538 - weighted_accuracy: 0.8471 - val_loss: 0.3328 - val_acc: 0.8410 - val_weighted_accuracy: 0.8371\n",
      "Epoch 3/500\n",
      "365054/365054 [==============================] - 85s 234us/step - loss: 0.0231 - acc: 0.8614 - weighted_accuracy: 0.8552 - val_loss: 0.3466 - val_acc: 0.8364 - val_weighted_accuracy: 0.8372\n",
      "Epoch 4/500\n",
      "365054/365054 [==============================] - 85s 233us/step - loss: 0.0225 - acc: 0.8657 - weighted_accuracy: 0.8599 - val_loss: 0.3283 - val_acc: 0.8458 - val_weighted_accuracy: 0.8422\n",
      "Epoch 5/500\n",
      "365054/365054 [==============================] - 85s 233us/step - loss: 0.0221 - acc: 0.8694 - weighted_accuracy: 0.8640 - val_loss: 0.3129 - val_acc: 0.8527 - val_weighted_accuracy: 0.8471\n",
      "Epoch 6/500\n",
      "365054/365054 [==============================] - 85s 233us/step - loss: 0.0217 - acc: 0.8717 - weighted_accuracy: 0.8671 - val_loss: 0.3039 - val_acc: 0.8575 - val_weighted_accuracy: 0.8492\n",
      "Epoch 7/500\n",
      "365054/365054 [==============================] - 83s 228us/step - loss: 0.0215 - acc: 0.8748 - weighted_accuracy: 0.8701 - val_loss: 0.3142 - val_acc: 0.8539 - val_weighted_accuracy: 0.8507\n",
      "Epoch 8/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0212 - acc: 0.8761 - weighted_accuracy: 0.8716 - val_loss: 0.3110 - val_acc: 0.8538 - val_weighted_accuracy: 0.8497\n",
      "Epoch 9/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0210 - acc: 0.8776 - weighted_accuracy: 0.8730 - val_loss: 0.3312 - val_acc: 0.8462 - val_weighted_accuracy: 0.8461\n",
      "Epoch 10/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0209 - acc: 0.8794 - weighted_accuracy: 0.8749 - val_loss: 0.3087 - val_acc: 0.8546 - val_weighted_accuracy: 0.8499\n",
      "Epoch 11/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0207 - acc: 0.8806 - weighted_accuracy: 0.8765 - val_loss: 0.3061 - val_acc: 0.8568 - val_weighted_accuracy: 0.8502\n",
      "Epoch 12/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0206 - acc: 0.8809 - weighted_accuracy: 0.8769 - val_loss: 0.2978 - val_acc: 0.8636 - val_weighted_accuracy: 0.8553\n",
      "Epoch 13/500\n",
      "365054/365054 [==============================] - 86s 235us/step - loss: 0.0203 - acc: 0.8831 - weighted_accuracy: 0.8792 - val_loss: 0.2952 - val_acc: 0.8657 - val_weighted_accuracy: 0.8581\n",
      "Epoch 14/500\n",
      "365054/365054 [==============================] - 83s 226us/step - loss: 0.0202 - acc: 0.8841 - weighted_accuracy: 0.8806 - val_loss: 0.2961 - val_acc: 0.8642 - val_weighted_accuracy: 0.8568\n",
      "Epoch 15/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0201 - acc: 0.8841 - weighted_accuracy: 0.8807 - val_loss: 0.2966 - val_acc: 0.8629 - val_weighted_accuracy: 0.8565\n",
      "Epoch 16/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0200 - acc: 0.8856 - weighted_accuracy: 0.8822 - val_loss: 0.3069 - val_acc: 0.8594 - val_weighted_accuracy: 0.8539\n",
      "Epoch 17/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0199 - acc: 0.8855 - weighted_accuracy: 0.8822 - val_loss: 0.2884 - val_acc: 0.8690 - val_weighted_accuracy: 0.8601\n",
      "Epoch 18/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0198 - acc: 0.8865 - weighted_accuracy: 0.8833 - val_loss: 0.3062 - val_acc: 0.8588 - val_weighted_accuracy: 0.8524\n",
      "Epoch 19/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0197 - acc: 0.8884 - weighted_accuracy: 0.8852 - val_loss: 0.2997 - val_acc: 0.8629 - val_weighted_accuracy: 0.8573\n",
      "Epoch 20/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0195 - acc: 0.8886 - weighted_accuracy: 0.8856 - val_loss: 0.3016 - val_acc: 0.8593 - val_weighted_accuracy: 0.8527\n",
      "Epoch 21/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0195 - acc: 0.8888 - weighted_accuracy: 0.8860 - val_loss: 0.3007 - val_acc: 0.8618 - val_weighted_accuracy: 0.8543\n",
      "Epoch 22/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0193 - acc: 0.8896 - weighted_accuracy: 0.8867 - val_loss: 0.2848 - val_acc: 0.8712 - val_weighted_accuracy: 0.8610\n",
      "Epoch 23/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0193 - acc: 0.8904 - weighted_accuracy: 0.8876 - val_loss: 0.3001 - val_acc: 0.8623 - val_weighted_accuracy: 0.8563\n",
      "Epoch 24/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0192 - acc: 0.8913 - weighted_accuracy: 0.8887 - val_loss: 0.2979 - val_acc: 0.8654 - val_weighted_accuracy: 0.8581\n",
      "Epoch 25/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0191 - acc: 0.8916 - weighted_accuracy: 0.8888 - val_loss: 0.2956 - val_acc: 0.8660 - val_weighted_accuracy: 0.8583\n",
      "Epoch 26/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0190 - acc: 0.8922 - weighted_accuracy: 0.8897 - val_loss: 0.3003 - val_acc: 0.8626 - val_weighted_accuracy: 0.8558\n",
      "Epoch 27/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0189 - acc: 0.8932 - weighted_accuracy: 0.8911 - val_loss: 0.2973 - val_acc: 0.8647 - val_weighted_accuracy: 0.8573\n",
      "Epoch 28/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0188 - acc: 0.8936 - weighted_accuracy: 0.8912 - val_loss: 0.2936 - val_acc: 0.8681 - val_weighted_accuracy: 0.8610\n",
      "Epoch 29/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0188 - acc: 0.8937 - weighted_accuracy: 0.8915 - val_loss: 0.2969 - val_acc: 0.8647 - val_weighted_accuracy: 0.8575\n",
      "Epoch 30/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0187 - acc: 0.8943 - weighted_accuracy: 0.8920 - val_loss: 0.2927 - val_acc: 0.8671 - val_weighted_accuracy: 0.8596\n",
      "Epoch 31/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0187 - acc: 0.8945 - weighted_accuracy: 0.8919 - val_loss: 0.2968 - val_acc: 0.8659 - val_weighted_accuracy: 0.8593\n",
      "Epoch 32/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0186 - acc: 0.8955 - weighted_accuracy: 0.8934 - val_loss: 0.2928 - val_acc: 0.8681 - val_weighted_accuracy: 0.8587\n",
      "Epoch 33/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0186 - acc: 0.8956 - weighted_accuracy: 0.8933 - val_loss: 0.2995 - val_acc: 0.8667 - val_weighted_accuracy: 0.8578\n",
      "Epoch 34/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0184 - acc: 0.8966 - weighted_accuracy: 0.8948 - val_loss: 0.2942 - val_acc: 0.8669 - val_weighted_accuracy: 0.8597\n",
      "Epoch 35/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0184 - acc: 0.8968 - weighted_accuracy: 0.8948 - val_loss: 0.3098 - val_acc: 0.8608 - val_weighted_accuracy: 0.8548\n",
      "Epoch 36/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0183 - acc: 0.8977 - weighted_accuracy: 0.8957 - val_loss: 0.2935 - val_acc: 0.8662 - val_weighted_accuracy: 0.8572\n",
      "Epoch 37/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0182 - acc: 0.8974 - weighted_accuracy: 0.8955 - val_loss: 0.2797 - val_acc: 0.8758 - val_weighted_accuracy: 0.8644\n",
      "Epoch 38/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0181 - acc: 0.8982 - weighted_accuracy: 0.8965 - val_loss: 0.2868 - val_acc: 0.8728 - val_weighted_accuracy: 0.8638\n",
      "Epoch 39/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0181 - acc: 0.8989 - weighted_accuracy: 0.8972 - val_loss: 0.2901 - val_acc: 0.8703 - val_weighted_accuracy: 0.8614\n",
      "Epoch 40/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0181 - acc: 0.8987 - weighted_accuracy: 0.8969 - val_loss: 0.2884 - val_acc: 0.8703 - val_weighted_accuracy: 0.8632\n",
      "Epoch 41/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0180 - acc: 0.8995 - weighted_accuracy: 0.8980 - val_loss: 0.2905 - val_acc: 0.8706 - val_weighted_accuracy: 0.8620\n",
      "Epoch 42/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0179 - acc: 0.8997 - weighted_accuracy: 0.8983 - val_loss: 0.2861 - val_acc: 0.8740 - val_weighted_accuracy: 0.8664\n",
      "Epoch 43/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0178 - acc: 0.9004 - weighted_accuracy: 0.8991 - val_loss: 0.2907 - val_acc: 0.8705 - val_weighted_accuracy: 0.8620\n",
      "Epoch 44/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0178 - acc: 0.9009 - weighted_accuracy: 0.8994 - val_loss: 0.2913 - val_acc: 0.8711 - val_weighted_accuracy: 0.8641\n",
      "Epoch 45/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0178 - acc: 0.9013 - weighted_accuracy: 0.8998 - val_loss: 0.3012 - val_acc: 0.8648 - val_weighted_accuracy: 0.8595\n",
      "Epoch 46/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0177 - acc: 0.9013 - weighted_accuracy: 0.9002 - val_loss: 0.2917 - val_acc: 0.8716 - val_weighted_accuracy: 0.8634\n",
      "Epoch 47/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0177 - acc: 0.9018 - weighted_accuracy: 0.9006 - val_loss: 0.2910 - val_acc: 0.8724 - val_weighted_accuracy: 0.8632\n",
      "Epoch 48/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0176 - acc: 0.9023 - weighted_accuracy: 0.9013 - val_loss: 0.2949 - val_acc: 0.8694 - val_weighted_accuracy: 0.8614\n",
      "Epoch 49/500\n",
      "365054/365054 [==============================] - 80s 220us/step - loss: 0.0175 - acc: 0.9035 - weighted_accuracy: 0.9025 - val_loss: 0.2891 - val_acc: 0.8704 - val_weighted_accuracy: 0.8641\n",
      "Epoch 50/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0175 - acc: 0.9030 - weighted_accuracy: 0.9019 - val_loss: 0.2917 - val_acc: 0.8697 - val_weighted_accuracy: 0.8623\n",
      "Epoch 51/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0175 - acc: 0.9026 - weighted_accuracy: 0.9017 - val_loss: 0.2949 - val_acc: 0.8686 - val_weighted_accuracy: 0.8616\n",
      "Epoch 52/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0175 - acc: 0.9024 - weighted_accuracy: 0.9015 - val_loss: 0.3000 - val_acc: 0.8671 - val_weighted_accuracy: 0.8589\n",
      "Epoch 53/500\n",
      "365054/365054 [==============================] - 80s 220us/step - loss: 0.0174 - acc: 0.9034 - weighted_accuracy: 0.9023 - val_loss: 0.2853 - val_acc: 0.8746 - val_weighted_accuracy: 0.8646\n",
      "Epoch 54/500\n",
      "365054/365054 [==============================] - 80s 220us/step - loss: 0.0173 - acc: 0.9043 - weighted_accuracy: 0.9033 - val_loss: 0.3005 - val_acc: 0.8681 - val_weighted_accuracy: 0.8623\n",
      "Epoch 55/500\n",
      "365054/365054 [==============================] - 81s 221us/step - loss: 0.0173 - acc: 0.9044 - weighted_accuracy: 0.9032 - val_loss: 0.2820 - val_acc: 0.8758 - val_weighted_accuracy: 0.8665\n",
      "Epoch 56/500\n",
      "365054/365054 [==============================] - 80s 220us/step - loss: 0.0172 - acc: 0.9053 - weighted_accuracy: 0.9045 - val_loss: 0.2844 - val_acc: 0.8731 - val_weighted_accuracy: 0.8648\n",
      "Epoch 57/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0172 - acc: 0.9051 - weighted_accuracy: 0.9041 - val_loss: 0.2907 - val_acc: 0.8704 - val_weighted_accuracy: 0.8637\n",
      "Epoch 58/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0171 - acc: 0.9052 - weighted_accuracy: 0.9045 - val_loss: 0.2889 - val_acc: 0.8714 - val_weighted_accuracy: 0.8642\n",
      "Epoch 59/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0171 - acc: 0.9056 - weighted_accuracy: 0.9049 - val_loss: 0.2851 - val_acc: 0.8736 - val_weighted_accuracy: 0.8651\n",
      "Epoch 60/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0170 - acc: 0.9061 - weighted_accuracy: 0.9053 - val_loss: 0.2856 - val_acc: 0.8746 - val_weighted_accuracy: 0.8647\n",
      "Epoch 61/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0170 - acc: 0.9064 - weighted_accuracy: 0.9055 - val_loss: 0.2874 - val_acc: 0.8736 - val_weighted_accuracy: 0.8641\n",
      "Epoch 62/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0170 - acc: 0.9063 - weighted_accuracy: 0.9055 - val_loss: 0.2819 - val_acc: 0.8755 - val_weighted_accuracy: 0.8648\n",
      "Epoch 63/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0169 - acc: 0.9064 - weighted_accuracy: 0.9060 - val_loss: 0.2847 - val_acc: 0.8737 - val_weighted_accuracy: 0.8637\n",
      "Epoch 64/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0168 - acc: 0.9078 - weighted_accuracy: 0.9072 - val_loss: 0.3053 - val_acc: 0.8642 - val_weighted_accuracy: 0.8594\n",
      "Epoch 65/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0168 - acc: 0.9071 - weighted_accuracy: 0.9066 - val_loss: 0.2825 - val_acc: 0.8756 - val_weighted_accuracy: 0.8653\n",
      "Epoch 66/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0168 - acc: 0.9078 - weighted_accuracy: 0.9074 - val_loss: 0.2831 - val_acc: 0.8749 - val_weighted_accuracy: 0.8652\n",
      "Epoch 67/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0167 - acc: 0.9083 - weighted_accuracy: 0.9079 - val_loss: 0.2883 - val_acc: 0.8725 - val_weighted_accuracy: 0.8626\n",
      "Epoch 68/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0167 - acc: 0.9083 - weighted_accuracy: 0.9078 - val_loss: 0.2881 - val_acc: 0.8743 - val_weighted_accuracy: 0.8640\n",
      "Epoch 69/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0166 - acc: 0.9090 - weighted_accuracy: 0.9087 - val_loss: 0.2948 - val_acc: 0.8690 - val_weighted_accuracy: 0.8626\n",
      "Epoch 70/500\n",
      "365054/365054 [==============================] - 80s 219us/step - loss: 0.0166 - acc: 0.9091 - weighted_accuracy: 0.9089 - val_loss: 0.2833 - val_acc: 0.8742 - val_weighted_accuracy: 0.8643\n",
      "score 0.857550968788034\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 53us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 53us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "80126/80126 [==============================] - 4s 52us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 9\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-DecomposalbeAttention-NoMeta-ClassWeighted-NoEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_decomposable_attention(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=15)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"3Embedding-DecomposalbeAttention-NoMeta-ClassWeighted-NoEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
