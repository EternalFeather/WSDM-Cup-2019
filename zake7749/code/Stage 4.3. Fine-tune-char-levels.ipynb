{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import pandas as pd\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from iwillwin.trainer.supervised_trainer import KerasModelTrainer\n",
    "from iwillwin.data_utils.data_helpers import CharDataTransformer, DataTransformer, DataLoader\n",
    "from iwillwin.model.sim_zoos import *\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, MaxPooling1D, CuDNNLSTM, Embedding, Add, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from iwillwin.config import dataset_config, model_config\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.legacy.layers import Highway\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 5000\n",
    "EMBEDDING_DIM = 150\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "OUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataHelper] Apply normalization on value-type columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Kaggle\\WSDM-zh\\code\\iwillwin\\data_utils\\data_helpers.py:132: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_df = pd.concat((train_df, test_df))\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing preprocessing...\n",
      "Transforming words to indices...\n",
      "Shape of data tensor: (320552, 50) (320552, 50)\n",
      "Shape of label tensor: (320552,)\n",
      "Preprocessed.\n",
      "Number of unique words 5196\n"
     ]
    }
   ],
   "source": [
    "data_transformer = CharDataTransformer(max_num_words=NB_WORDS, max_sequence_length=MAX_SEQUENCE_LENGTH, char_level=False,\n",
    "                                   normalization=True, features_processed=True)\n",
    "trains, tests, labels = data_transformer.prepare_data(dual=False)\n",
    "print(\"Number of unique words\", len(data_transformer.tokenizer.index_docs))\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "['.gitkeep', 'fasttext-50-win3.vec', 'zh-wordvec-50-cbow-windowsize50.vec', 'zh-wordvec-50-skipgram-windowsize7.vec']\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings\")\n",
    "print(os.listdir(\"../data/wordvec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "skip_gram_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-skipgram-windowsize7.vec')\n",
    "cbow_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-cbow-windowsize50.vec')\n",
    "fasttext_embeddings = data_loader.load_embedding('../data/wordvec/fasttext-50-win3.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(embeddings_index, nb_words=NB_WORDS, word_index=data_transformer.tokenizer.word_index):\n",
    "    #nb_words = min(nb_words, len(embeddings_index))\n",
    "    embedding_matrix = np.random.rand(nb_words, 50)\n",
    "    embedding_matrix = np.zeros((nb_words, 50))\n",
    "    \n",
    "    word_index = data_transformer.tokenizer.word_index\n",
    "    null_words = open('null-word.txt', 'w', encoding='utf-8')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words:\n",
    "            null_words.write(word + '\\n')\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            null_words.write(word + '\\n')\n",
    "    print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n"
     ]
    }
   ],
   "source": [
    "cbow_matrix = build_embedding_matrix(cbow_embeddings)\n",
    "skipgram_matrix = build_embedding_matrix(skip_gram_embeddings)\n",
    "fasttext_matrix = build_embedding_matrix(fasttext_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings = np.concatenate((cbow_matrix, skipgram_matrix, fasttext_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings[0] = np.array([0] * 150) # zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tricky features\n",
    "\n",
    "## Rumor words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/dataset/train.csv')\n",
    "test_df = pd.read_csv('../data/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "rumor_words = ['辟谣', '谣言', '勿传', '假的']\n",
    "\n",
    "def is_rumor(text):\n",
    "    if type(text) != str:\n",
    "        print(text, type(text))\n",
    "        return 0\n",
    "    for rumor_word in rumor_words:\n",
    "        if rumor_word in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def has_split_symbol(text):\n",
    "    if type(text) != str:\n",
    "        return 0\n",
    "    if '|' in text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['has_|'] = df['title2_zh'].apply(has_split_symbol)\n",
    "    df['has_rumor_words'] = df['title2_zh'].apply(is_rumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_has_rumor = train_df.has_rumor_words.values\n",
    "test_has_rumor = test_df.has_rumor_words.values\n",
    "\n",
    "trick_trains_features = np.concatenate((trains[2], train_has_rumor.reshape((-1, 1))), axis=1)\n",
    "trick_tests_features = np.concatenate((tests[2], test_has_rumor.reshape((-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _build_exact_match_sequences(sent_1, sent_2):\n",
    "    sent_1_char_set = set(sent_1)\n",
    "    sent_2_char_set = set(sent_2)\n",
    "    intersection = sent_1_char_set & sent_2_char_set\n",
    "    \n",
    "    sent_1_em = np.zeros_like(sent_1)\n",
    "    sent_2_em = np.zeros_like(sent_2)\n",
    "\n",
    "    for i in range(len(sent_1)):\n",
    "        if sent_1[i] == 0:\n",
    "            continue\n",
    "        if sent_1[i] in intersection:\n",
    "            sent_1_em[i] = 1\n",
    "    \n",
    "    for i in range(len(sent_2)):\n",
    "        if sent_2[i] == 0:\n",
    "            continue        \n",
    "        if sent_2[i] in intersection:\n",
    "            sent_2_em[i] = 1\n",
    "    \n",
    "    return sent_1_em, sent_2_em\n",
    "\n",
    "def build_exact_match_sequences(sents_1, sents_2):\n",
    "    sents_1_em, sents_2_em = [], []\n",
    "    for sent_1, sent_2 in zip(sents_1, sents_2):\n",
    "        sent_1_em, sent_2_em = _build_exact_match_sequences(sent_1, sent_2)\n",
    "        sents_1_em.append(sent_1_em)\n",
    "        sents_2_em.append(sent_2_em)\n",
    "    return np.array(sents_1_em), np.array(sents_2_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_1_ems, trains_2_ems = build_exact_match_sequences(trains[0], trains[1])\n",
    "tests_1_ems, tests_2_ems = build_exact_match_sequences(tests[0], tests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train em (320552, 50) (320552, 50)\n",
      "Shape of test em (80126, 50) (80126, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train em\", trains_1_ems.shape, trains_2_ems.shape)\n",
    "print(\"Shape of test em\", tests_1_ems.shape, tests_2_ems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_train_features = (trains_1_ems, trains_2_ems)\n",
    "em_test_features = (tests_1_ems, tests_2_ems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class_weight.compute_class_weight('balanced', [0, 1, 2], labels.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Ensemble Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_inputs = pd.read_csv(\"../data/ensemble/second_level/FirstLevelPseudoLabels.csv\")\n",
    "pseudo_labels = ensemble_inputs[['unrelated', 'agreed', 'disagreed']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trick or Treat!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tricky = True\n",
    "\n",
    "if use_tricky:\n",
    "    trains = (trains[0], trains[1], trick_trains_features)\n",
    "    tests = (tests[0], tests[1], trick_tests_features)\n",
    "else:\n",
    "    trains = (trains[0], trains[1], trains[2])\n",
    "    tests = (tests[0], tests[1], tests[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "        self.class_weight = [0.93, 1.21]\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, batch_size, get_model_func, tests, em_test_features, pseudo_labels, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        #features = features[:, -1]\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:], tests[0]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:], tests[1]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:], tests[2]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:], em_test_features[0]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:], em_test_features[1]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:], pseudo_labels])\n",
    "\n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=None)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        bst_model_path = self.model_stamp + str(fold_id) + '.h5'\n",
    "        model.load_weights(bst_model_path)\n",
    "        print(\"Load the model from \", bst_model_path)\n",
    "        fine_tune_model_path = self.model_stamp + \"-fine-tune-\" + str(fold_id) + '.h5'\n",
    "        \n",
    "        val_data = (val_x, val_y, weight_val) if weight_val is not None else (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(fine_tune_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         callbacks=[early_stopping, model_checkpoint],\n",
    "                         class_weight=class_weight)\n",
    "        bst_val_score = min(hist.history['val_loss'])\n",
    "        model.load_weights(fine_tune_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = tf.nn.leaky_relu(K.conv1d(u_vecs, self.W))\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = K.tanh(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "    \n",
    "def get_padding_mask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def unchanged_shape(input_shape):\n",
    "    \"Function for Lambda layer\"\n",
    "    return input_shape\n",
    "\n",
    "def substract(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: x[0] - x[1])([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def eldistance(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: K.sqrt(K.square(x[0] - x[1])))([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def submult(input_1, input_2):\n",
    "    \"Get multiplication and subtraction then concatenate results\"\n",
    "    mult = Multiply()([input_1, input_2])\n",
    "    add = Add()([input_1, input_2])\n",
    "    sub = substract(input_1, input_2)\n",
    "    distance = eldistance(input_1, input_2)\n",
    "    \n",
    "    dual = Concatenate()([input_1, input_2])\n",
    "    dual = Dense(32, activation='relu')(dual)\n",
    "    dual = Dropout(0.5)(dual)\n",
    "    dual = Dense(8, activation='relu')(dual)\n",
    "    \n",
    "    out_= Concatenate()([sub, mult, ])\n",
    "    return out_\n",
    "\n",
    "def apply_multiple(input_, layers):\n",
    "    \"Apply layers to input then concatenate result\"\n",
    "    if not len(layers) > 1:\n",
    "        raise ValueError('Layers list should contain more than 1 layer')\n",
    "    else:\n",
    "        agg_ = []\n",
    "        for layer in layers:\n",
    "            agg_.append(layer(input_))\n",
    "        out_ = Concatenate()(agg_)\n",
    "    return out_\n",
    "\n",
    "def time_distributed(input_, layers):\n",
    "    \"Apply a list of layers in TimeDistributed mode\"\n",
    "    out_ = []\n",
    "    node_ = input_\n",
    "    for layer_ in layers:\n",
    "        node_ = TimeDistributed(layer_)(node_)\n",
    "    out_ = node_\n",
    "    return out_\n",
    "\n",
    "def soft_attention_alignment(input_1, input_2):\n",
    "    \"Align text representation with neural soft attention\"\n",
    "    attention = Dot(axes=-1)([input_1, input_2])\n",
    "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
    "                     output_shape=unchanged_shape)(attention)\n",
    "    w_att_2 = Permute((2, 1))(Lambda(lambda x: softmax(x, axis=2),\n",
    "                             output_shape=unchanged_shape)(attention))\n",
    "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
    "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
    "    return in1_aligned, in2_aligned    \n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q1_c = Input(shape=(max_sequence_length, 11), name='first_sentences_char')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q2_c = Input(shape=(max_sequence_length, 11), name='second_sentences_char')\n",
    "    input_layer_3 = Input(shape=(len(model_config.META_FEATURES),), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words,\n",
    "                            embedding_dim,\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=True)\n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.5)(q1_embed)\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.5)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    \n",
    "    q1_encoded = th(q1_embed,)    \n",
    "    q2_encoded = th(q2_embed,)\n",
    "    \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
    "    q1_encoded = Concatenate()([q2_aligned, q1_encoded])\n",
    "    q2_encoded = Concatenate()([q1_aligned, q2_encoded])  \n",
    "    \n",
    "    cnn_init = Conv1D(32, 1, strides=1, padding='same', activation='relu')\n",
    "    q1_seq = cnn_init(q1_encoded)\n",
    "    q2_seq = cnn_init(q2_encoded)\n",
    "    \n",
    "    cnns = [Conv1D(1, 3, strides=1, padding='same', activation='relu') for i in range(10)]\n",
    "    \n",
    "    for idx, cnn in enumerate(cnns):\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        q1_encoded = Concatenate()([q1_seq, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_seq, q1_aligned, q2_encoded])            \n",
    "        q1_seq = cnn(q1_encoded)\n",
    "        q2_seq = cnn(q2_encoded)    \n",
    "    \n",
    "    \n",
    "    capsule_pooling = Capsule(num_capsule=8, dim_capsule=100, routings=3, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    \n",
    "    #q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])\n",
    "    #q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi, ])\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_darnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    #q1_embed = Dropout(0.2)(th(q1_embed,))\n",
    "    #q2_embed = Dropout(0.2)(th(q2_embed,))    \n",
    "    \n",
    "    rnns = [CuDNNGRU(42, return_sequences=True) for i in range(3)]\n",
    "    \n",
    "    q1_res = []\n",
    "    q2_res = []\n",
    "    \n",
    "    \n",
    "    for idx, rnn in enumerate(rnns):\n",
    "        q1_seq = rnn(q1_embed)\n",
    "        q1_seq = Dropout(0.1)(q1_seq)\n",
    "        q2_seq = rnn(q2_embed)\n",
    "        q2_seq = Dropout(0.1)(q2_seq)\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        \n",
    "        q1_res.append(q2_aligned)\n",
    "        q1_res.append(q1_seq)\n",
    "        \n",
    "        q2_res.append(q1_aligned)\n",
    "        q2_res.append(q2_seq)\n",
    "        \n",
    "        q1_embed = Concatenate()([q1_seq, q2_aligned, q1_embed])\n",
    "        q2_embed = Concatenate()([q2_seq, q1_aligned, q2_embed])            \n",
    "        \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    q1_res = Concatenate()(q1_res)\n",
    "    q2_res = Concatenate()(q2_res)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.1)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    \n",
    "    y_pred = K.cast(y_pred > 0.5, 'int32') # Hard\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    \n",
    "    res = K.cast(K.equal(y_pred, y_true), 'float32') * weight_mask / K.sum(weight_mask)\n",
    "    res = K.sum(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_manager = ModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:200: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 50, 151)      0           embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 50, 151)      0           embedding_3[1][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 50, 151)      0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 50, 151)      0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)          (None, 50, 42)       24570       spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50, 42)       0           cu_dnngru_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 50, 42)       0           cu_dnngru_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 50, 50)       0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 50, 50)       0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_12 (Dot)                    (None, 50, 42)       0           permute_4[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 50, 42)       0           lambda_8[0][0]                   \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 50, 235)      0           dropout_8[0][0]                  \n",
      "                                                                 dot_12[0][0]                     \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 50, 235)      0           dropout_9[0][0]                  \n",
      "                                                                 dot_11[0][0]                     \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)          (None, 50, 42)       35154       concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 50, 42)       0           cu_dnngru_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 50, 42)       0           cu_dnngru_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 50, 50)       0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 50, 50)       0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 50, 42)       0           permute_5[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 50, 42)       0           lambda_10[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 50, 319)      0           dropout_10[0][0]                 \n",
      "                                                                 dot_15[0][0]                     \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 50, 319)      0           dropout_11[0][0]                 \n",
      "                                                                 dot_14[0][0]                     \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)          (None, 50, 42)       45738       concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 50, 42)       0           cu_dnngru_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 50, 42)       0           cu_dnngru_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_16 (Dot)                    (None, 50, 50)       0           dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 50, 50)       0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 50, 42)       0           permute_6[0][0]                  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 50, 42)       0           lambda_12[0][0]                  \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 50, 252)      0           dot_12[0][0]                     \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dot_15[0][0]                     \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dot_18[0][0]                     \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 50, 252)      0           dot_11[0][0]                     \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dot_14[0][0]                     \n",
      "                                                                 dropout_11[0][0]                 \n",
      "                                                                 dot_17[0][0]                     \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 252)          0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 252)          0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 252)          0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 252)          0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 504)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 504)          0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 504)          0           concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 504)          0           concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 2016)         0           concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 2016)         0           concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          516352      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            771         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2757 - acc: 0.8895 - weighted_accuracy: 0.7093 - val_loss: 0.3010 - val_acc: 0.8625 - val_weighted_accuracy: 0.8477\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2728 - acc: 0.8914 - weighted_accuracy: 0.7093 - val_loss: 0.3027 - val_acc: 0.8591 - val_weighted_accuracy: 0.8485\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2707 - acc: 0.8927 - weighted_accuracy: 0.7099 - val_loss: 0.2933 - val_acc: 0.8656 - val_weighted_accuracy: 0.8466\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2696 - acc: 0.8935 - weighted_accuracy: 0.7104 - val_loss: 0.2956 - val_acc: 0.8661 - val_weighted_accuracy: 0.8447\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2684 - acc: 0.8941 - weighted_accuracy: 0.7105 - val_loss: 0.2942 - val_acc: 0.8632 - val_weighted_accuracy: 0.8472\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2668 - acc: 0.8947 - weighted_accuracy: 0.7113 - val_loss: 0.2991 - val_acc: 0.8623 - val_weighted_accuracy: 0.8449\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2656 - acc: 0.8960 - weighted_accuracy: 0.7128 - val_loss: 0.3016 - val_acc: 0.8645 - val_weighted_accuracy: 0.8476\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2647 - acc: 0.8960 - weighted_accuracy: 0.7125 - val_loss: 0.2984 - val_acc: 0.8661 - val_weighted_accuracy: 0.8512\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2634 - acc: 0.8972 - weighted_accuracy: 0.7133 - val_loss: 0.2971 - val_acc: 0.8683 - val_weighted_accuracy: 0.8514\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2629 - acc: 0.8969 - weighted_accuracy: 0.7131 - val_loss: 0.2977 - val_acc: 0.8637 - val_weighted_accuracy: 0.8472\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2623 - acc: 0.8969 - weighted_accuracy: 0.7129 - val_loss: 0.2908 - val_acc: 0.8693 - val_weighted_accuracy: 0.8519\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2611 - acc: 0.8986 - weighted_accuracy: 0.7140 - val_loss: 0.2986 - val_acc: 0.8651 - val_weighted_accuracy: 0.8532\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2614 - acc: 0.8978 - weighted_accuracy: 0.7134 - val_loss: 0.3010 - val_acc: 0.8653 - val_weighted_accuracy: 0.8520\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2601 - acc: 0.8986 - weighted_accuracy: 0.7140 - val_loss: 0.3001 - val_acc: 0.8665 - val_weighted_accuracy: 0.8485\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2594 - acc: 0.8994 - weighted_accuracy: 0.7152 - val_loss: 0.2880 - val_acc: 0.8692 - val_weighted_accuracy: 0.8502\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2593 - acc: 0.8995 - weighted_accuracy: 0.7153 - val_loss: 0.3043 - val_acc: 0.8647 - val_weighted_accuracy: 0.8475\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2587 - acc: 0.8989 - weighted_accuracy: 0.7147 - val_loss: 0.2983 - val_acc: 0.8663 - val_weighted_accuracy: 0.8533\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2586 - acc: 0.8990 - weighted_accuracy: 0.7148 - val_loss: 0.3026 - val_acc: 0.8659 - val_weighted_accuracy: 0.8550\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2578 - acc: 0.8998 - weighted_accuracy: 0.7158 - val_loss: 0.3029 - val_acc: 0.8630 - val_weighted_accuracy: 0.8457\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2574 - acc: 0.9005 - weighted_accuracy: 0.7161 - val_loss: 0.3046 - val_acc: 0.8612 - val_weighted_accuracy: 0.8493\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2570 - acc: 0.9002 - weighted_accuracy: 0.7160 - val_loss: 0.3019 - val_acc: 0.8642 - val_weighted_accuracy: 0.8515\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2573 - acc: 0.9001 - weighted_accuracy: 0.7160 - val_loss: 0.2928 - val_acc: 0.8690 - val_weighted_accuracy: 0.8508\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2562 - acc: 0.9004 - weighted_accuracy: 0.7165 - val_loss: 0.2935 - val_acc: 0.8684 - val_weighted_accuracy: 0.8493\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2561 - acc: 0.9006 - weighted_accuracy: 0.7162 - val_loss: 0.2976 - val_acc: 0.8642 - val_weighted_accuracy: 0.8486\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2557 - acc: 0.9013 - weighted_accuracy: 0.7169 - val_loss: 0.2978 - val_acc: 0.8643 - val_weighted_accuracy: 0.8500\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 50, 151)      0           embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 50, 151)      0           embedding_5[1][0]                \n",
      "                                                                 embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 50, 151)      0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 50, 151)      0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)          (None, 50, 42)       24570       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 50, 42)       0           cu_dnngru_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 50, 42)       0           cu_dnngru_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 50, 50)       0           dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 50, 50)       0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 50, 42)       0           permute_7[0][0]                  \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 50, 42)       0           lambda_15[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 50, 235)      0           dropout_15[0][0]                 \n",
      "                                                                 dot_21[0][0]                     \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 50, 235)      0           dropout_16[0][0]                 \n",
      "                                                                 dot_20[0][0]                     \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)          (None, 50, 42)       35154       concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 50, 42)       0           cu_dnngru_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 50, 42)       0           cu_dnngru_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 50, 50)       0           dropout_17[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (None, 50, 50)       0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 50, 42)       0           permute_8[0][0]                  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 50, 42)       0           lambda_17[0][0]                  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 50, 319)      0           dropout_17[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 50, 319)      0           dropout_18[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_9 (CuDNNGRU)          (None, 50, 42)       45738       concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 50, 42)       0           cu_dnngru_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 50, 42)       0           cu_dnngru_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 50, 50)       0           dropout_19[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 50, 50)       0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 50, 42)       0           permute_9[0][0]                  \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 50, 42)       0           lambda_19[0][0]                  \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 50, 252)      0           dot_21[0][0]                     \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 dropout_17[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 50, 252)      0           dot_20[0][0]                     \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 dropout_18[0][0]                 \n",
      "                                                                 dot_26[0][0]                     \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 252)          0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 252)          0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 252)          0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 252)          0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 504)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 504)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 504)          0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 504)          0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 2016)         0           concatenate_37[0][0]             \n",
      "                                                                 concatenate_38[0][0]             \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 2016)         0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          516352      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            771         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2600 - acc: 0.8972 - weighted_accuracy: 0.7201 - val_loss: 0.2815 - val_acc: 0.8766 - val_weighted_accuracy: 0.8600\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2604 - acc: 0.8973 - weighted_accuracy: 0.7177 - val_loss: 0.2821 - val_acc: 0.8762 - val_weighted_accuracy: 0.8593\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2604 - acc: 0.8974 - weighted_accuracy: 0.7173 - val_loss: 0.2754 - val_acc: 0.8791 - val_weighted_accuracy: 0.8614\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2596 - acc: 0.8982 - weighted_accuracy: 0.7177 - val_loss: 0.2868 - val_acc: 0.8734 - val_weighted_accuracy: 0.8569\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2598 - acc: 0.8981 - weighted_accuracy: 0.7175 - val_loss: 0.2821 - val_acc: 0.8762 - val_weighted_accuracy: 0.8601\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2599 - acc: 0.8984 - weighted_accuracy: 0.7171 - val_loss: 0.2820 - val_acc: 0.8738 - val_weighted_accuracy: 0.8589\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2590 - acc: 0.8983 - weighted_accuracy: 0.7179 - val_loss: 0.2821 - val_acc: 0.8768 - val_weighted_accuracy: 0.8614\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2592 - acc: 0.8988 - weighted_accuracy: 0.7176 - val_loss: 0.2874 - val_acc: 0.8749 - val_weighted_accuracy: 0.8645\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2590 - acc: 0.8989 - weighted_accuracy: 0.7176 - val_loss: 0.2816 - val_acc: 0.8771 - val_weighted_accuracy: 0.8640\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2591 - acc: 0.8986 - weighted_accuracy: 0.7170 - val_loss: 0.2719 - val_acc: 0.8820 - val_weighted_accuracy: 0.8637\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2581 - acc: 0.8987 - weighted_accuracy: 0.7175 - val_loss: 0.2745 - val_acc: 0.8800 - val_weighted_accuracy: 0.8648\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2583 - acc: 0.8988 - weighted_accuracy: 0.7173 - val_loss: 0.2765 - val_acc: 0.8805 - val_weighted_accuracy: 0.8659\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2588 - acc: 0.8990 - weighted_accuracy: 0.7170 - val_loss: 0.2757 - val_acc: 0.8800 - val_weighted_accuracy: 0.8669\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2584 - acc: 0.8992 - weighted_accuracy: 0.7170 - val_loss: 0.2792 - val_acc: 0.8780 - val_weighted_accuracy: 0.8644\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2580 - acc: 0.8991 - weighted_accuracy: 0.7166 - val_loss: 0.2795 - val_acc: 0.8752 - val_weighted_accuracy: 0.8631\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2573 - acc: 0.8997 - weighted_accuracy: 0.7171 - val_loss: 0.2693 - val_acc: 0.8836 - val_weighted_accuracy: 0.8621\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2578 - acc: 0.8992 - weighted_accuracy: 0.7173 - val_loss: 0.2787 - val_acc: 0.8772 - val_weighted_accuracy: 0.8620\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2573 - acc: 0.8991 - weighted_accuracy: 0.7175 - val_loss: 0.2794 - val_acc: 0.8750 - val_weighted_accuracy: 0.8609\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 128s 356us/step - loss: 0.2572 - acc: 0.8995 - weighted_accuracy: 0.7169 - val_loss: 0.2744 - val_acc: 0.8804 - val_weighted_accuracy: 0.8637\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 128s 355us/step - loss: 0.2568 - acc: 0.9002 - weighted_accuracy: 0.7176 - val_loss: 0.2790 - val_acc: 0.8780 - val_weighted_accuracy: 0.8596\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2571 - acc: 0.9001 - weighted_accuracy: 0.7174 - val_loss: 0.2755 - val_acc: 0.8804 - val_weighted_accuracy: 0.8606\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2573 - acc: 0.8996 - weighted_accuracy: 0.7171 - val_loss: 0.2773 - val_acc: 0.8780 - val_weighted_accuracy: 0.8585\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2565 - acc: 0.9002 - weighted_accuracy: 0.7180 - val_loss: 0.2768 - val_acc: 0.8783 - val_weighted_accuracy: 0.8638\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2572 - acc: 0.8998 - weighted_accuracy: 0.7172 - val_loss: 0.2794 - val_acc: 0.8777 - val_weighted_accuracy: 0.8605\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2562 - acc: 0.9002 - weighted_accuracy: 0.7177 - val_loss: 0.2759 - val_acc: 0.8780 - val_weighted_accuracy: 0.8632\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2564 - acc: 0.8996 - weighted_accuracy: 0.7174 - val_loss: 0.2777 - val_acc: 0.8762 - val_weighted_accuracy: 0.8562\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 50, 151)      0           embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 50, 151)      0           embedding_7[1][0]                \n",
      "                                                                 embedding_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 50, 151)      0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 50, 151)      0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 50, 50)       0           dropout_22[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 50, 50)       0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 50, 42)       0           permute_10[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 50, 42)       0           lambda_22[0][0]                  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 50, 235)      0           dropout_22[0][0]                 \n",
      "                                                                 dot_30[0][0]                     \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 50, 235)      0           dropout_23[0][0]                 \n",
      "                                                                 dot_29[0][0]                     \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_11 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 50, 50)       0           dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 50, 50)       0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 50, 42)       0           permute_11[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 50, 42)       0           lambda_24[0][0]                  \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 50, 319)      0           dropout_24[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 50, 319)      0           dropout_25[0][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_12 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_44[0][0]             \n",
      "                                                                 concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 50, 50)       0           dropout_26[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 50, 50)       0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 50, 42)       0           permute_12[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 50, 42)       0           lambda_26[0][0]                  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 50, 252)      0           dot_30[0][0]                     \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dot_36[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 50, 252)      0           dot_29[0][0]                     \n",
      "                                                                 dropout_23[0][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 dropout_25[0][0]                 \n",
      "                                                                 dot_35[0][0]                     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 252)          0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 252)          0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 252)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 252)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 504)          0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 504)          0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 504)          0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 504)          0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 2016)         0           concatenate_50[0][0]             \n",
      "                                                                 concatenate_51[0][0]             \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 2016)         0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          516352      dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            771         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2676 - acc: 0.8938 - weighted_accuracy: 0.7138 - val_loss: 0.3077 - val_acc: 0.8593 - val_weighted_accuracy: 0.8483\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2655 - acc: 0.8949 - weighted_accuracy: 0.7134 - val_loss: 0.3069 - val_acc: 0.8600 - val_weighted_accuracy: 0.8477\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2654 - acc: 0.8956 - weighted_accuracy: 0.7129 - val_loss: 0.3033 - val_acc: 0.8631 - val_weighted_accuracy: 0.8490\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2649 - acc: 0.8962 - weighted_accuracy: 0.7133 - val_loss: 0.2975 - val_acc: 0.8679 - val_weighted_accuracy: 0.8549\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2640 - acc: 0.8966 - weighted_accuracy: 0.7133 - val_loss: 0.3087 - val_acc: 0.8628 - val_weighted_accuracy: 0.8539\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2631 - acc: 0.8968 - weighted_accuracy: 0.7139 - val_loss: 0.3130 - val_acc: 0.8569 - val_weighted_accuracy: 0.8481\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2627 - acc: 0.8973 - weighted_accuracy: 0.7142 - val_loss: 0.3008 - val_acc: 0.8630 - val_weighted_accuracy: 0.8489\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2621 - acc: 0.8969 - weighted_accuracy: 0.7139 - val_loss: 0.3040 - val_acc: 0.8652 - val_weighted_accuracy: 0.8509\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2617 - acc: 0.8977 - weighted_accuracy: 0.7140 - val_loss: 0.2967 - val_acc: 0.8680 - val_weighted_accuracy: 0.8546\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2605 - acc: 0.8986 - weighted_accuracy: 0.7145 - val_loss: 0.2996 - val_acc: 0.8644 - val_weighted_accuracy: 0.8523\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2608 - acc: 0.8981 - weighted_accuracy: 0.7139 - val_loss: 0.3000 - val_acc: 0.8638 - val_weighted_accuracy: 0.8521\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2608 - acc: 0.8979 - weighted_accuracy: 0.7139 - val_loss: 0.3123 - val_acc: 0.8575 - val_weighted_accuracy: 0.8472\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2598 - acc: 0.8984 - weighted_accuracy: 0.7141 - val_loss: 0.3028 - val_acc: 0.8628 - val_weighted_accuracy: 0.8517\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2591 - acc: 0.8992 - weighted_accuracy: 0.7152 - val_loss: 0.2996 - val_acc: 0.8640 - val_weighted_accuracy: 0.8513\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2594 - acc: 0.8985 - weighted_accuracy: 0.7147 - val_loss: 0.3037 - val_acc: 0.8654 - val_weighted_accuracy: 0.8562\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2587 - acc: 0.9000 - weighted_accuracy: 0.7160 - val_loss: 0.3056 - val_acc: 0.8617 - val_weighted_accuracy: 0.8505\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 129s 356us/step - loss: 0.2584 - acc: 0.8997 - weighted_accuracy: 0.7156 - val_loss: 0.3071 - val_acc: 0.8645 - val_weighted_accuracy: 0.8488\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2580 - acc: 0.8994 - weighted_accuracy: 0.7151 - val_loss: 0.2971 - val_acc: 0.8672 - val_weighted_accuracy: 0.8539\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2578 - acc: 0.8997 - weighted_accuracy: 0.7156 - val_loss: 0.3064 - val_acc: 0.8627 - val_weighted_accuracy: 0.8496\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 50, 151)      0           embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 50, 151)      0           embedding_9[1][0]                \n",
      "                                                                 embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 50, 151)      0           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 50, 151)      0           concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_13 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 50, 50)       0           dropout_29[0][0]                 \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 50, 50)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 50, 42)       0           permute_13[0][0]                 \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 50, 42)       0           lambda_29[0][0]                  \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 50, 235)      0           dropout_29[0][0]                 \n",
      "                                                                 dot_39[0][0]                     \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 50, 235)      0           dropout_30[0][0]                 \n",
      "                                                                 dot_38[0][0]                     \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_14 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_55[0][0]             \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 50, 50)       0           dropout_31[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 50, 50)       0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 50, 42)       0           permute_14[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 50, 42)       0           lambda_31[0][0]                  \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 50, 319)      0           dropout_31[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 50, 319)      0           dropout_32[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_15 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_57[0][0]             \n",
      "                                                                 concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 50, 50)       0           dropout_33[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 50, 50)       0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 50, 42)       0           permute_15[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 50, 42)       0           lambda_33[0][0]                  \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 50, 252)      0           dot_39[0][0]                     \n",
      "                                                                 dropout_29[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 dropout_31[0][0]                 \n",
      "                                                                 dot_45[0][0]                     \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 50, 252)      0           dot_38[0][0]                     \n",
      "                                                                 dropout_30[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "                                                                 dot_44[0][0]                     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 252)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 252)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 252)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 252)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 504)          0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 504)          0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 504)          0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 504)          0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 2016)         0           concatenate_63[0][0]             \n",
      "                                                                 concatenate_64[0][0]             \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 2016)         0           concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          516352      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            771         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2642 - acc: 0.8955 - weighted_accuracy: 0.7168 - val_loss: 0.2966 - val_acc: 0.8678 - val_weighted_accuracy: 0.8553\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2629 - acc: 0.8963 - weighted_accuracy: 0.7165 - val_loss: 0.3014 - val_acc: 0.8673 - val_weighted_accuracy: 0.8504\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2621 - acc: 0.8969 - weighted_accuracy: 0.7164 - val_loss: 0.2983 - val_acc: 0.8663 - val_weighted_accuracy: 0.8466\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2628 - acc: 0.8971 - weighted_accuracy: 0.7163 - val_loss: 0.2980 - val_acc: 0.8653 - val_weighted_accuracy: 0.8532\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2620 - acc: 0.8971 - weighted_accuracy: 0.7157 - val_loss: 0.2975 - val_acc: 0.8664 - val_weighted_accuracy: 0.8543\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2617 - acc: 0.8973 - weighted_accuracy: 0.7161 - val_loss: 0.2987 - val_acc: 0.8650 - val_weighted_accuracy: 0.8524\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2616 - acc: 0.8975 - weighted_accuracy: 0.7157 - val_loss: 0.2916 - val_acc: 0.8706 - val_weighted_accuracy: 0.8537\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2611 - acc: 0.8974 - weighted_accuracy: 0.7156 - val_loss: 0.2902 - val_acc: 0.8701 - val_weighted_accuracy: 0.8559\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2601 - acc: 0.8979 - weighted_accuracy: 0.7160 - val_loss: 0.3006 - val_acc: 0.8658 - val_weighted_accuracy: 0.8542\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2606 - acc: 0.8982 - weighted_accuracy: 0.7156 - val_loss: 0.2926 - val_acc: 0.8691 - val_weighted_accuracy: 0.8532\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2607 - acc: 0.8983 - weighted_accuracy: 0.7163 - val_loss: 0.3045 - val_acc: 0.8629 - val_weighted_accuracy: 0.8469\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2601 - acc: 0.8984 - weighted_accuracy: 0.7156 - val_loss: 0.2948 - val_acc: 0.8689 - val_weighted_accuracy: 0.8499\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2591 - acc: 0.8986 - weighted_accuracy: 0.7163 - val_loss: 0.2949 - val_acc: 0.8658 - val_weighted_accuracy: 0.8484\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2595 - acc: 0.8990 - weighted_accuracy: 0.7165 - val_loss: 0.2920 - val_acc: 0.8696 - val_weighted_accuracy: 0.8512\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2594 - acc: 0.8985 - weighted_accuracy: 0.7152 - val_loss: 0.2977 - val_acc: 0.8692 - val_weighted_accuracy: 0.8531\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2592 - acc: 0.8987 - weighted_accuracy: 0.7155 - val_loss: 0.3004 - val_acc: 0.8653 - val_weighted_accuracy: 0.8504\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2588 - acc: 0.8991 - weighted_accuracy: 0.7158 - val_loss: 0.2915 - val_acc: 0.8691 - val_weighted_accuracy: 0.8552\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2588 - acc: 0.8996 - weighted_accuracy: 0.7163 - val_loss: 0.2966 - val_acc: 0.8674 - val_weighted_accuracy: 0.8499\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 50, 151)      0           embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 50, 151)      0           embedding_11[1][0]               \n",
      "                                                                 embedding_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 50, 151)      0           concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 50, 151)      0           concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_16 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 50, 50)       0           dropout_36[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 50, 50)       0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 50, 42)       0           permute_16[0][0]                 \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 50, 42)       0           lambda_36[0][0]                  \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 50, 235)      0           dropout_36[0][0]                 \n",
      "                                                                 dot_48[0][0]                     \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 50, 235)      0           dropout_37[0][0]                 \n",
      "                                                                 dot_47[0][0]                     \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_17 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_68[0][0]             \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 50, 50)       0           dropout_38[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 50, 50)       0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 50, 42)       0           permute_17[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 50, 42)       0           lambda_38[0][0]                  \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 50, 319)      0           dropout_38[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 50, 319)      0           dropout_39[0][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_18 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_70[0][0]             \n",
      "                                                                 concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 50, 50)       0           dropout_40[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 50, 50)       0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 50, 42)       0           permute_18[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 50, 42)       0           lambda_40[0][0]                  \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 50, 252)      0           dot_48[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "                                                                 dot_54[0][0]                     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 50, 252)      0           dot_47[0][0]                     \n",
      "                                                                 dropout_37[0][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 dropout_39[0][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 252)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 252)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 252)          0           concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 252)          0           concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 504)          0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 504)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 504)          0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 504)          0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 2016)         0           concatenate_76[0][0]             \n",
      "                                                                 concatenate_77[0][0]             \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 2016)         0           concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          516352      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            771         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2590 - acc: 0.8984 - weighted_accuracy: 0.7199 - val_loss: 0.3205 - val_acc: 0.8565 - val_weighted_accuracy: 0.8427\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2585 - acc: 0.8990 - weighted_accuracy: 0.7189 - val_loss: 0.3109 - val_acc: 0.8589 - val_weighted_accuracy: 0.8446\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2574 - acc: 0.8993 - weighted_accuracy: 0.7190 - val_loss: 0.3098 - val_acc: 0.8594 - val_weighted_accuracy: 0.8416\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2574 - acc: 0.9000 - weighted_accuracy: 0.7187 - val_loss: 0.3091 - val_acc: 0.8596 - val_weighted_accuracy: 0.8412\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2572 - acc: 0.8997 - weighted_accuracy: 0.7182 - val_loss: 0.3130 - val_acc: 0.8546 - val_weighted_accuracy: 0.8423\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2570 - acc: 0.9001 - weighted_accuracy: 0.7186 - val_loss: 0.3107 - val_acc: 0.8568 - val_weighted_accuracy: 0.8433\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2568 - acc: 0.8995 - weighted_accuracy: 0.7175 - val_loss: 0.3116 - val_acc: 0.8582 - val_weighted_accuracy: 0.8436\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2565 - acc: 0.9004 - weighted_accuracy: 0.7184 - val_loss: 0.3105 - val_acc: 0.8587 - val_weighted_accuracy: 0.8432\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2564 - acc: 0.9002 - weighted_accuracy: 0.7183 - val_loss: 0.3061 - val_acc: 0.8615 - val_weighted_accuracy: 0.8464\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2560 - acc: 0.9004 - weighted_accuracy: 0.7187 - val_loss: 0.3147 - val_acc: 0.8587 - val_weighted_accuracy: 0.8450\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2557 - acc: 0.9009 - weighted_accuracy: 0.7184 - val_loss: 0.3071 - val_acc: 0.8625 - val_weighted_accuracy: 0.8439\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2557 - acc: 0.9013 - weighted_accuracy: 0.7181 - val_loss: 0.3092 - val_acc: 0.8591 - val_weighted_accuracy: 0.8414\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2556 - acc: 0.9008 - weighted_accuracy: 0.7186 - val_loss: 0.3138 - val_acc: 0.8555 - val_weighted_accuracy: 0.8401\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2560 - acc: 0.9004 - weighted_accuracy: 0.7176 - val_loss: 0.3060 - val_acc: 0.8618 - val_weighted_accuracy: 0.8433\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2554 - acc: 0.9009 - weighted_accuracy: 0.7183 - val_loss: 0.3176 - val_acc: 0.8573 - val_weighted_accuracy: 0.8405\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2548 - acc: 0.9014 - weighted_accuracy: 0.7184 - val_loss: 0.3129 - val_acc: 0.8553 - val_weighted_accuracy: 0.8435\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2548 - acc: 0.9015 - weighted_accuracy: 0.7192 - val_loss: 0.3139 - val_acc: 0.8572 - val_weighted_accuracy: 0.8441\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2550 - acc: 0.9013 - weighted_accuracy: 0.7184 - val_loss: 0.3117 - val_acc: 0.8590 - val_weighted_accuracy: 0.8416\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2543 - acc: 0.9018 - weighted_accuracy: 0.7187 - val_loss: 0.3122 - val_acc: 0.8578 - val_weighted_accuracy: 0.8433\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2543 - acc: 0.9015 - weighted_accuracy: 0.7184 - val_loss: 0.3149 - val_acc: 0.8558 - val_weighted_accuracy: 0.8431\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2548 - acc: 0.9011 - weighted_accuracy: 0.7182 - val_loss: 0.3251 - val_acc: 0.8517 - val_weighted_accuracy: 0.8436\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2541 - acc: 0.9018 - weighted_accuracy: 0.7189 - val_loss: 0.3150 - val_acc: 0.8566 - val_weighted_accuracy: 0.8428\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2538 - acc: 0.9017 - weighted_accuracy: 0.7185 - val_loss: 0.3116 - val_acc: 0.8595 - val_weighted_accuracy: 0.8398\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2535 - acc: 0.9020 - weighted_accuracy: 0.7193 - val_loss: 0.3141 - val_acc: 0.8586 - val_weighted_accuracy: 0.8411\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 50, 151)      0           embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 50, 151)      0           embedding_13[1][0]               \n",
      "                                                                 embedding_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 50, 151)      0           concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 50, 151)      0           concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_19 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 50, 50)       0           dropout_43[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 50, 50)       0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 50, 42)       0           permute_19[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 50, 42)       0           lambda_43[0][0]                  \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 50, 235)      0           dropout_43[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 50, 235)      0           dropout_44[0][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_20 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_81[0][0]             \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 50, 50)       0           dropout_45[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 50, 50)       0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 50, 42)       0           permute_20[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 50, 42)       0           lambda_45[0][0]                  \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 50, 319)      0           dropout_45[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 50, 319)      0           dropout_46[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_21 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_83[0][0]             \n",
      "                                                                 concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 50, 50)       0           dropout_47[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 50, 50)       0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 50, 42)       0           permute_21[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 50, 42)       0           lambda_47[0][0]                  \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 50, 252)      0           dot_57[0][0]                     \n",
      "                                                                 dropout_43[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 dropout_45[0][0]                 \n",
      "                                                                 dot_63[0][0]                     \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 50, 252)      0           dot_56[0][0]                     \n",
      "                                                                 dropout_44[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 dropout_46[0][0]                 \n",
      "                                                                 dot_62[0][0]                     \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 252)          0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 252)          0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 252)          0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 252)          0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 504)          0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 504)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 504)          0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 504)          0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 2016)         0           concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 2016)         0           concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          516352      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            771         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 125s 345us/step - loss: 0.2716 - acc: 0.8919 - weighted_accuracy: 0.7106 - val_loss: 0.3285 - val_acc: 0.8480 - val_weighted_accuracy: 0.8290\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2689 - acc: 0.8935 - weighted_accuracy: 0.7104 - val_loss: 0.3266 - val_acc: 0.8483 - val_weighted_accuracy: 0.8276\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2679 - acc: 0.8941 - weighted_accuracy: 0.7109 - val_loss: 0.3271 - val_acc: 0.8481 - val_weighted_accuracy: 0.8275\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2660 - acc: 0.8957 - weighted_accuracy: 0.7116 - val_loss: 0.3301 - val_acc: 0.8444 - val_weighted_accuracy: 0.8253\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2650 - acc: 0.8952 - weighted_accuracy: 0.7114 - val_loss: 0.3378 - val_acc: 0.8464 - val_weighted_accuracy: 0.8259\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2643 - acc: 0.8962 - weighted_accuracy: 0.7122 - val_loss: 0.3226 - val_acc: 0.8523 - val_weighted_accuracy: 0.8285\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2629 - acc: 0.8968 - weighted_accuracy: 0.7126 - val_loss: 0.3342 - val_acc: 0.8489 - val_weighted_accuracy: 0.8305\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2622 - acc: 0.8973 - weighted_accuracy: 0.7127 - val_loss: 0.3255 - val_acc: 0.8512 - val_weighted_accuracy: 0.8285\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.2614 - acc: 0.8981 - weighted_accuracy: 0.7134 - val_loss: 0.3338 - val_acc: 0.8484 - val_weighted_accuracy: 0.8172\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2610 - acc: 0.8979 - weighted_accuracy: 0.7130 - val_loss: 0.3272 - val_acc: 0.8505 - val_weighted_accuracy: 0.8275\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2601 - acc: 0.8985 - weighted_accuracy: 0.7141 - val_loss: 0.3272 - val_acc: 0.8486 - val_weighted_accuracy: 0.8286\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2599 - acc: 0.8989 - weighted_accuracy: 0.7140 - val_loss: 0.3314 - val_acc: 0.8474 - val_weighted_accuracy: 0.8284\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2589 - acc: 0.8988 - weighted_accuracy: 0.7138 - val_loss: 0.3297 - val_acc: 0.8506 - val_weighted_accuracy: 0.8273\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2589 - acc: 0.8993 - weighted_accuracy: 0.7144 - val_loss: 0.3334 - val_acc: 0.8486 - val_weighted_accuracy: 0.8265\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2584 - acc: 0.8991 - weighted_accuracy: 0.7141 - val_loss: 0.3279 - val_acc: 0.8507 - val_weighted_accuracy: 0.8266\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2575 - acc: 0.8996 - weighted_accuracy: 0.7147 - val_loss: 0.3300 - val_acc: 0.8514 - val_weighted_accuracy: 0.8282\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 50, 151)      0           embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 50, 151)      0           embedding_15[1][0]               \n",
      "                                                                 embedding_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 50, 151)      0           concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 50, 151)      0           concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_22 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 50, 50)       0           dropout_50[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 50, 50)       0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 50, 42)       0           permute_22[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 50, 42)       0           lambda_50[0][0]                  \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 50, 235)      0           dropout_50[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 50, 235)      0           dropout_51[0][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_23 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_94[0][0]             \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 50, 50)       0           dropout_52[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 50, 50)       0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 50, 42)       0           permute_23[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 50, 42)       0           lambda_52[0][0]                  \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 50, 319)      0           dropout_52[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 50, 319)      0           dropout_53[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_24 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_96[0][0]             \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 50, 50)       0           dropout_54[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 50, 50)       0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 50, 42)       0           permute_24[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 50, 42)       0           lambda_54[0][0]                  \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 50, 252)      0           dot_66[0][0]                     \n",
      "                                                                 dropout_50[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 dropout_52[0][0]                 \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 50, 252)      0           dot_65[0][0]                     \n",
      "                                                                 dropout_51[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 252)          0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 252)          0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 252)          0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 252)          0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 504)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 504)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 504)          0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 504)          0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 2016)         0           concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 2016)         0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          516352      dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            771         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 127s 352us/step - loss: 0.2751 - acc: 0.8897 - weighted_accuracy: 0.7089 - val_loss: 0.2903 - val_acc: 0.8695 - val_weighted_accuracy: 0.8530\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2733 - acc: 0.8912 - weighted_accuracy: 0.7086 - val_loss: 0.3053 - val_acc: 0.8606 - val_weighted_accuracy: 0.8476\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2710 - acc: 0.8922 - weighted_accuracy: 0.7095 - val_loss: 0.3106 - val_acc: 0.8602 - val_weighted_accuracy: 0.8527\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2692 - acc: 0.8934 - weighted_accuracy: 0.7097 - val_loss: 0.2996 - val_acc: 0.8637 - val_weighted_accuracy: 0.8558\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2677 - acc: 0.8944 - weighted_accuracy: 0.7104 - val_loss: 0.2912 - val_acc: 0.8703 - val_weighted_accuracy: 0.8525\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2670 - acc: 0.8948 - weighted_accuracy: 0.7107 - val_loss: 0.2921 - val_acc: 0.8695 - val_weighted_accuracy: 0.8540\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2657 - acc: 0.8960 - weighted_accuracy: 0.7114 - val_loss: 0.2910 - val_acc: 0.8708 - val_weighted_accuracy: 0.8569\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2649 - acc: 0.8960 - weighted_accuracy: 0.7118 - val_loss: 0.3029 - val_acc: 0.8612 - val_weighted_accuracy: 0.8553\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2645 - acc: 0.8956 - weighted_accuracy: 0.7118 - val_loss: 0.2948 - val_acc: 0.8660 - val_weighted_accuracy: 0.8546\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2632 - acc: 0.8969 - weighted_accuracy: 0.7123 - val_loss: 0.2969 - val_acc: 0.8674 - val_weighted_accuracy: 0.8597\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2622 - acc: 0.8974 - weighted_accuracy: 0.7131 - val_loss: 0.2959 - val_acc: 0.8671 - val_weighted_accuracy: 0.8606\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 50, 151)      0           embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 50, 151)      0           embedding_17[1][0]               \n",
      "                                                                 embedding_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 50, 151)      0           concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 50, 151)      0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_25 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 50, 50)       0           dropout_57[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 50, 50)       0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 50, 42)       0           permute_25[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 50, 42)       0           lambda_57[0][0]                  \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 50, 235)      0           dropout_57[0][0]                 \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 spatial_dropout1d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 50, 235)      0           dropout_58[0][0]                 \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_26 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_107[0][0]            \n",
      "                                                                 concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 50, 50)       0           dropout_59[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 50, 50)       0           lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 50, 42)       0           permute_26[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 50, 42)       0           lambda_59[0][0]                  \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 50, 319)      0           dropout_59[0][0]                 \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 50, 319)      0           dropout_60[0][0]                 \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_27 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_109[0][0]            \n",
      "                                                                 concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 50, 50)       0           dropout_61[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 50, 50)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 50, 42)       0           permute_27[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 50, 42)       0           lambda_61[0][0]                  \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 50, 252)      0           dot_75[0][0]                     \n",
      "                                                                 dropout_57[0][0]                 \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 dropout_59[0][0]                 \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 50, 252)      0           dot_74[0][0]                     \n",
      "                                                                 dropout_58[0][0]                 \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 dropout_60[0][0]                 \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 252)          0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 252)          0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 252)          0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 252)          0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 504)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 504)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 504)          0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 504)          0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 2016)         0           concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 2016)         0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          516352      dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 3)            771         dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 128s 355us/step - loss: 0.2643 - acc: 0.8950 - weighted_accuracy: 0.7176 - val_loss: 0.2814 - val_acc: 0.8732 - val_weighted_accuracy: 0.8562\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2636 - acc: 0.8958 - weighted_accuracy: 0.7161 - val_loss: 0.2851 - val_acc: 0.8742 - val_weighted_accuracy: 0.8561\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2629 - acc: 0.8963 - weighted_accuracy: 0.7151 - val_loss: 0.2806 - val_acc: 0.8748 - val_weighted_accuracy: 0.8540\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2624 - acc: 0.8963 - weighted_accuracy: 0.7157 - val_loss: 0.2799 - val_acc: 0.8768 - val_weighted_accuracy: 0.8584\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2619 - acc: 0.8970 - weighted_accuracy: 0.7154 - val_loss: 0.2884 - val_acc: 0.8712 - val_weighted_accuracy: 0.8575\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2615 - acc: 0.8970 - weighted_accuracy: 0.7157 - val_loss: 0.2796 - val_acc: 0.8750 - val_weighted_accuracy: 0.8496\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2615 - acc: 0.8972 - weighted_accuracy: 0.7154 - val_loss: 0.2843 - val_acc: 0.8748 - val_weighted_accuracy: 0.8566\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2611 - acc: 0.8977 - weighted_accuracy: 0.7157 - val_loss: 0.2748 - val_acc: 0.8773 - val_weighted_accuracy: 0.8529\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2603 - acc: 0.8978 - weighted_accuracy: 0.7158 - val_loss: 0.2959 - val_acc: 0.8711 - val_weighted_accuracy: 0.8578\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2604 - acc: 0.8987 - weighted_accuracy: 0.7164 - val_loss: 0.2875 - val_acc: 0.8746 - val_weighted_accuracy: 0.8555\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2597 - acc: 0.8983 - weighted_accuracy: 0.7168 - val_loss: 0.2808 - val_acc: 0.8771 - val_weighted_accuracy: 0.8616\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2596 - acc: 0.8992 - weighted_accuracy: 0.7167 - val_loss: 0.2848 - val_acc: 0.8730 - val_weighted_accuracy: 0.8567\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2594 - acc: 0.8983 - weighted_accuracy: 0.7157 - val_loss: 0.2832 - val_acc: 0.8756 - val_weighted_accuracy: 0.8604\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2592 - acc: 0.8982 - weighted_accuracy: 0.7163 - val_loss: 0.2800 - val_acc: 0.8782 - val_weighted_accuracy: 0.8594\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2585 - acc: 0.8995 - weighted_accuracy: 0.7167 - val_loss: 0.2801 - val_acc: 0.8788 - val_weighted_accuracy: 0.8580\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2583 - acc: 0.8995 - weighted_accuracy: 0.7170 - val_loss: 0.2760 - val_acc: 0.8784 - val_weighted_accuracy: 0.8539\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2575 - acc: 0.8997 - weighted_accuracy: 0.7170 - val_loss: 0.2774 - val_acc: 0.8776 - val_weighted_accuracy: 0.8569\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2577 - acc: 0.8998 - weighted_accuracy: 0.7170 - val_loss: 0.2796 - val_acc: 0.8780 - val_weighted_accuracy: 0.8604\n",
      "score 0.29223456792337\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "80126/80126 [==============================] - 9s 112us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_darnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2][:, -1]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2][:, -1]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"P3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    meta_features_input = Input(shape=(36,), name='mata-features')\n",
    "    \n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    flex_embedding = Embedding(nb_words, 20,\n",
    "                      input_length=max_sequence_length,\n",
    "                      trainable=True)\n",
    "    \n",
    "    em_embeddings = Reshape((max_sequence_length, 1))\n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match),])\n",
    "    q1_encoded = SpatialDropout1D(0.2)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match),])\n",
    "    q2_encoded = SpatialDropout1D(0.2)(q2_embed)\n",
    "\n",
    "\n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    nb_filters = 64\n",
    "    \n",
    "    cnns = [Conv1D(64, 1, strides=1, padding='same', activation='relu') for i in range(3)]\n",
    "    gates_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='tanh') for i in range(3)]\n",
    "    sigm_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='sigmoid') for i in range(3)]\n",
    "    \n",
    "    for i in range(len(cnns)):\n",
    "        drop = Dropout(0.1)\n",
    "        q1_t = gates_cnns[i](q1_encoded)\n",
    "        q2_t = gates_cnns[i](q2_encoded)    \n",
    "        \n",
    "        q1_s = sigm_cnns[i](q1_encoded)\n",
    "        q2_s = sigm_cnns[i](q2_encoded)        \n",
    "        \n",
    "        q1_x = Multiply()([q1_t, q1_s])\n",
    "        q1_x = cnns[i](q1_x)\n",
    "        q1_x = drop(q1_x)\n",
    "        \n",
    "        q2_x = Multiply()([q2_t, q2_s])\n",
    "        q2_x = cnns[i](q2_x)\n",
    "        q2_x = drop(q2_x)\n",
    "\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_x, q2_x)\n",
    "        q1_encoded = Concatenate()([q1_x, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_x, q1_aligned, q2_encoded]) \n",
    "    \n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    attn = AttentionWeightedAverage()\n",
    "    \n",
    "    \n",
    "    q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])\n",
    "    q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])    \n",
    "    \n",
    "    \n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    #drops = Dropout(0.3)\n",
    "    #q1_rep = shrink(drops(q1_rep))\n",
    "    #q2_rep = shrink(drops(q2_rep))\n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    #h_all = Dropout(0.35)(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)    \n",
    "    h_all = Dense(64, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-6))(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, meta_features_input, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 50, 151)      0           embedding_37[0][0]               \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 50, 151)      0           embedding_37[1][0]               \n",
      "                                                                 reshape_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 50, 151)      0           concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 50, 151)      0           concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 50, 64)       0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 50, 64)       0           conv1d_13[1][0]                  \n",
      "                                                                 conv1d_16[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 50, 64)       4160        multiply_33[0][0]                \n",
      "                                                                 multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 50, 64)       0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_10[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_115 (Dot)                   (None, 50, 50)       0           dropout_92[0][0]                 \n",
      "                                                                 dropout_92[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_39 (Permute)            (None, 50, 50)       0           lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_117 (Dot)                   (None, 50, 64)       0           permute_39[0][0]                 \n",
      "                                                                 dropout_92[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_116 (Dot)                   (None, 50, 64)       0           lambda_103[0][0]                 \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 50, 279)      0           dropout_92[0][0]                 \n",
      "                                                                 dot_117[0][0]                    \n",
      "                                                                 spatial_dropout1d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 50, 279)      0           dropout_92[1][0]                 \n",
      "                                                                 dot_116[0][0]                    \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 50, 64)       53632       concatenate_171[0][0]            \n",
      "                                                                 concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 50, 64)       53632       concatenate_171[0][0]            \n",
      "                                                                 concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 50, 64)       0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 50, 64)       0           conv1d_14[1][0]                  \n",
      "                                                                 conv1d_17[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 50, 64)       4160        multiply_35[0][0]                \n",
      "                                                                 multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 50, 64)       0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_11[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_118 (Dot)                   (None, 50, 50)       0           dropout_93[0][0]                 \n",
      "                                                                 dropout_93[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_40 (Permute)            (None, 50, 50)       0           lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_120 (Dot)                   (None, 50, 64)       0           permute_40[0][0]                 \n",
      "                                                                 dropout_93[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_119 (Dot)                   (None, 50, 64)       0           lambda_105[0][0]                 \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 50, 407)      0           dropout_93[0][0]                 \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 50, 407)      0           dropout_93[1][0]                 \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 50, 64)       78208       concatenate_173[0][0]            \n",
      "                                                                 concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 50, 64)       78208       concatenate_173[0][0]            \n",
      "                                                                 concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 50, 64)       0           conv1d_15[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 50, 64)       0           conv1d_15[1][0]                  \n",
      "                                                                 conv1d_18[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 64)       4160        multiply_37[0][0]                \n",
      "                                                                 multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 50, 64)       0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_12[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_121 (Dot)                   (None, 50, 50)       0           dropout_94[0][0]                 \n",
      "                                                                 dropout_94[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_41 (Permute)            (None, 50, 50)       0           lambda_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_123 (Dot)                   (None, 50, 64)       0           permute_41[0][0]                 \n",
      "                                                                 dropout_94[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_122 (Dot)                   (None, 50, 64)       0           lambda_107[0][0]                 \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 50, 535)      0           dropout_94[0][0]                 \n",
      "                                                                 dot_123[0][0]                    \n",
      "                                                                 concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 50, 535)      0           dropout_94[1][0]                 \n",
      "                                                                 dot_122[0][0]                    \n",
      "                                                                 concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_37 (Gl (None, 535)          0           concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_37 (Global (None, 535)          0           concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 535)          535         concatenate_175[0][0]            \n",
      "                                                                 concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_38 (Gl (None, 535)          0           concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_38 (Global (None, 535)          0           concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 1605)         0           global_average_pooling1d_37[0][0]\n",
      "                                                                 global_max_pooling1d_37[0][0]    \n",
      "                                                                 attention_weighted_average_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 1605)         0           global_average_pooling1d_38[0][0]\n",
      "                                                                 global_max_pooling1d_38[0][0]    \n",
      "                                                                 attention_weighted_average_2[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 1605)         0           concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 1605)         0           concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 6420)         0           concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "                                                                 lambda_109[0][0]                 \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 6420)         0           concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 6420)         25680       dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 64)           410944      batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 3)            195         dense_53[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 130s 361us/step - loss: 0.3060 - acc: 0.8733 - weighted_accuracy: 0.6966 - val_loss: 0.3029 - val_acc: 0.8655 - val_weighted_accuracy: 0.8432\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.3010 - acc: 0.8767 - weighted_accuracy: 0.6981 - val_loss: 0.3093 - val_acc: 0.8622 - val_weighted_accuracy: 0.8420\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2977 - acc: 0.8794 - weighted_accuracy: 0.6992 - val_loss: 0.3014 - val_acc: 0.8646 - val_weighted_accuracy: 0.8425\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2945 - acc: 0.8822 - weighted_accuracy: 0.7010 - val_loss: 0.2990 - val_acc: 0.8657 - val_weighted_accuracy: 0.8421\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2917 - acc: 0.8833 - weighted_accuracy: 0.7024 - val_loss: 0.2980 - val_acc: 0.8673 - val_weighted_accuracy: 0.8446\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2909 - acc: 0.8848 - weighted_accuracy: 0.7035 - val_loss: 0.3031 - val_acc: 0.8675 - val_weighted_accuracy: 0.8431\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2884 - acc: 0.8856 - weighted_accuracy: 0.7044 - val_loss: 0.3013 - val_acc: 0.8656 - val_weighted_accuracy: 0.8418\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2875 - acc: 0.8863 - weighted_accuracy: 0.7056 - val_loss: 0.2984 - val_acc: 0.8676 - val_weighted_accuracy: 0.8439\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2861 - acc: 0.8878 - weighted_accuracy: 0.7062 - val_loss: 0.2979 - val_acc: 0.8689 - val_weighted_accuracy: 0.8432\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2841 - acc: 0.8890 - weighted_accuracy: 0.7075 - val_loss: 0.2978 - val_acc: 0.8698 - val_weighted_accuracy: 0.8507\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2838 - acc: 0.8894 - weighted_accuracy: 0.7082 - val_loss: 0.2985 - val_acc: 0.8690 - val_weighted_accuracy: 0.8415\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.2829 - acc: 0.8900 - weighted_accuracy: 0.7078 - val_loss: 0.2943 - val_acc: 0.8709 - val_weighted_accuracy: 0.8489\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2818 - acc: 0.8900 - weighted_accuracy: 0.7091 - val_loss: 0.2952 - val_acc: 0.8712 - val_weighted_accuracy: 0.8477\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2807 - acc: 0.8920 - weighted_accuracy: 0.7096 - val_loss: 0.2959 - val_acc: 0.8709 - val_weighted_accuracy: 0.8497\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2799 - acc: 0.8918 - weighted_accuracy: 0.7098 - val_loss: 0.3003 - val_acc: 0.8698 - val_weighted_accuracy: 0.8480\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2792 - acc: 0.8922 - weighted_accuracy: 0.7108 - val_loss: 0.2929 - val_acc: 0.8716 - val_weighted_accuracy: 0.8477\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2786 - acc: 0.8925 - weighted_accuracy: 0.7106 - val_loss: 0.2928 - val_acc: 0.8724 - val_weighted_accuracy: 0.8459\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2784 - acc: 0.8926 - weighted_accuracy: 0.7106 - val_loss: 0.2956 - val_acc: 0.8715 - val_weighted_accuracy: 0.8496\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2775 - acc: 0.8937 - weighted_accuracy: 0.7119 - val_loss: 0.2924 - val_acc: 0.8733 - val_weighted_accuracy: 0.8514\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2757 - acc: 0.8941 - weighted_accuracy: 0.7126 - val_loss: 0.2964 - val_acc: 0.8723 - val_weighted_accuracy: 0.8471\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 122s 338us/step - loss: 0.2756 - acc: 0.8946 - weighted_accuracy: 0.7127 - val_loss: 0.2946 - val_acc: 0.8726 - val_weighted_accuracy: 0.8484\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2752 - acc: 0.8951 - weighted_accuracy: 0.7131 - val_loss: 0.3089 - val_acc: 0.8638 - val_weighted_accuracy: 0.8356\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2747 - acc: 0.8951 - weighted_accuracy: 0.7133 - val_loss: 0.2952 - val_acc: 0.8737 - val_weighted_accuracy: 0.8525\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 121s 337us/step - loss: 0.2748 - acc: 0.8949 - weighted_accuracy: 0.7131 - val_loss: 0.3019 - val_acc: 0.8703 - val_weighted_accuracy: 0.8429\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2748 - acc: 0.8960 - weighted_accuracy: 0.7132 - val_loss: 0.2948 - val_acc: 0.8732 - val_weighted_accuracy: 0.8513\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2733 - acc: 0.8960 - weighted_accuracy: 0.7139 - val_loss: 0.2955 - val_acc: 0.8731 - val_weighted_accuracy: 0.8482\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2735 - acc: 0.8960 - weighted_accuracy: 0.7138 - val_loss: 0.2924 - val_acc: 0.8743 - val_weighted_accuracy: 0.8481\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2724 - acc: 0.8962 - weighted_accuracy: 0.7146 - val_loss: 0.2935 - val_acc: 0.8730 - val_weighted_accuracy: 0.8503\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 121s 337us/step - loss: 0.2725 - acc: 0.8966 - weighted_accuracy: 0.7146 - val_loss: 0.2960 - val_acc: 0.8702 - val_weighted_accuracy: 0.8471\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2714 - acc: 0.8970 - weighted_accuracy: 0.7149 - val_loss: 0.2994 - val_acc: 0.8686 - val_weighted_accuracy: 0.8494\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2713 - acc: 0.8969 - weighted_accuracy: 0.7147 - val_loss: 0.2945 - val_acc: 0.8739 - val_weighted_accuracy: 0.8504\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2706 - acc: 0.8974 - weighted_accuracy: 0.7152 - val_loss: 0.2991 - val_acc: 0.8713 - val_weighted_accuracy: 0.8472\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 121s 337us/step - loss: 0.2704 - acc: 0.8977 - weighted_accuracy: 0.7158 - val_loss: 0.2955 - val_acc: 0.8715 - val_weighted_accuracy: 0.8477\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 122s 337us/step - loss: 0.2699 - acc: 0.8974 - weighted_accuracy: 0.7160 - val_loss: 0.2966 - val_acc: 0.8733 - val_weighted_accuracy: 0.8477\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 121s 337us/step - loss: 0.2693 - acc: 0.8982 - weighted_accuracy: 0.7162 - val_loss: 0.2934 - val_acc: 0.8728 - val_weighted_accuracy: 0.8504\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2690 - acc: 0.8983 - weighted_accuracy: 0.7164 - val_loss: 0.2945 - val_acc: 0.8740 - val_weighted_accuracy: 0.8506\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 126s 348us/step - loss: 0.2689 - acc: 0.8978 - weighted_accuracy: 0.7158 - val_loss: 0.3025 - val_acc: 0.8678 - val_weighted_accuracy: 0.8439\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 50, 151)      0           embedding_39[0][0]               \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 50, 151)      0           embedding_39[1][0]               \n",
      "                                                                 reshape_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 50, 151)      0           concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_40 (SpatialDr (None, 50, 151)      0           concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_39[0][0]       \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_39[0][0]       \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 50, 64)       0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 50, 64)       0           conv1d_22[1][0]                  \n",
      "                                                                 conv1d_25[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 50, 64)       4160        multiply_40[0][0]                \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 50, 64)       0           conv1d_19[0][0]                  \n",
      "                                                                 conv1d_19[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_124 (Dot)                   (None, 50, 50)       0           dropout_96[0][0]                 \n",
      "                                                                 dropout_96[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 50, 50)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_42 (Permute)            (None, 50, 50)       0           lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 50, 50)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_126 (Dot)                   (None, 50, 64)       0           permute_42[0][0]                 \n",
      "                                                                 dropout_96[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_125 (Dot)                   (None, 50, 64)       0           lambda_110[0][0]                 \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 50, 279)      0           dropout_96[0][0]                 \n",
      "                                                                 dot_126[0][0]                    \n",
      "                                                                 spatial_dropout1d_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 50, 279)      0           dropout_96[1][0]                 \n",
      "                                                                 dot_125[0][0]                    \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 50, 64)       53632       concatenate_182[0][0]            \n",
      "                                                                 concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 50, 64)       53632       concatenate_182[0][0]            \n",
      "                                                                 concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 50, 64)       0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 50, 64)       0           conv1d_23[1][0]                  \n",
      "                                                                 conv1d_26[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 50, 64)       4160        multiply_42[0][0]                \n",
      "                                                                 multiply_43[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 50, 64)       0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_20[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_127 (Dot)                   (None, 50, 50)       0           dropout_97[0][0]                 \n",
      "                                                                 dropout_97[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 50, 50)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_43 (Permute)            (None, 50, 50)       0           lambda_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 50, 50)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_129 (Dot)                   (None, 50, 64)       0           permute_43[0][0]                 \n",
      "                                                                 dropout_97[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_128 (Dot)                   (None, 50, 64)       0           lambda_112[0][0]                 \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 50, 407)      0           dropout_97[0][0]                 \n",
      "                                                                 dot_129[0][0]                    \n",
      "                                                                 concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 50, 407)      0           dropout_97[1][0]                 \n",
      "                                                                 dot_128[0][0]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 50, 64)       78208       concatenate_184[0][0]            \n",
      "                                                                 concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 50, 64)       78208       concatenate_184[0][0]            \n",
      "                                                                 concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 50, 64)       0           conv1d_24[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 50, 64)       0           conv1d_24[1][0]                  \n",
      "                                                                 conv1d_27[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 50, 64)       4160        multiply_44[0][0]                \n",
      "                                                                 multiply_45[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 50, 64)       0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_21[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_130 (Dot)                   (None, 50, 50)       0           dropout_98[0][0]                 \n",
      "                                                                 dropout_98[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 50, 50)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_44 (Permute)            (None, 50, 50)       0           lambda_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 50, 50)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_132 (Dot)                   (None, 50, 64)       0           permute_44[0][0]                 \n",
      "                                                                 dropout_98[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_131 (Dot)                   (None, 50, 64)       0           lambda_114[0][0]                 \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 50, 535)      0           dropout_98[0][0]                 \n",
      "                                                                 dot_132[0][0]                    \n",
      "                                                                 concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 50, 535)      0           dropout_98[1][0]                 \n",
      "                                                                 dot_131[0][0]                    \n",
      "                                                                 concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_39 (Gl (None, 535)          0           concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_39 (Global (None, 535)          0           concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 535)          535         concatenate_186[0][0]            \n",
      "                                                                 concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_40 (Gl (None, 535)          0           concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_40 (Global (None, 535)          0           concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 1605)         0           global_average_pooling1d_39[0][0]\n",
      "                                                                 global_max_pooling1d_39[0][0]    \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 1605)         0           global_average_pooling1d_40[0][0]\n",
      "                                                                 global_max_pooling1d_40[0][0]    \n",
      "                                                                 attention_weighted_average_3[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 1605)         0           concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 1605)         0           concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 6420)         0           concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "                                                                 lambda_116[0][0]                 \n",
      "                                                                 multiply_46[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 6420)         0           concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 6420)         25680       dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 64)           410944      batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 3)            195         dense_55[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 128s 356us/step - loss: 0.2888 - acc: 0.8829 - weighted_accuracy: 0.7069 - val_loss: 0.2833 - val_acc: 0.8751 - val_weighted_accuracy: 0.8543\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2916 - acc: 0.8830 - weighted_accuracy: 0.7045 - val_loss: 0.2826 - val_acc: 0.8772 - val_weighted_accuracy: 0.8584\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 127s 352us/step - loss: 0.2901 - acc: 0.8845 - weighted_accuracy: 0.7045 - val_loss: 0.2821 - val_acc: 0.8748 - val_weighted_accuracy: 0.8541\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2890 - acc: 0.8855 - weighted_accuracy: 0.7051 - val_loss: 0.2906 - val_acc: 0.8752 - val_weighted_accuracy: 0.8561\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2877 - acc: 0.8865 - weighted_accuracy: 0.7054 - val_loss: 0.2839 - val_acc: 0.8791 - val_weighted_accuracy: 0.8611\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2866 - acc: 0.8873 - weighted_accuracy: 0.7062 - val_loss: 0.2846 - val_acc: 0.8766 - val_weighted_accuracy: 0.8531\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2849 - acc: 0.8883 - weighted_accuracy: 0.7067 - val_loss: 0.2814 - val_acc: 0.8786 - val_weighted_accuracy: 0.8595\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2849 - acc: 0.8885 - weighted_accuracy: 0.7071 - val_loss: 0.2843 - val_acc: 0.8774 - val_weighted_accuracy: 0.8526\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2834 - acc: 0.8892 - weighted_accuracy: 0.7085 - val_loss: 0.2825 - val_acc: 0.8805 - val_weighted_accuracy: 0.8602\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2827 - acc: 0.8902 - weighted_accuracy: 0.7087 - val_loss: 0.2842 - val_acc: 0.8783 - val_weighted_accuracy: 0.8552\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2820 - acc: 0.8908 - weighted_accuracy: 0.7099 - val_loss: 0.2806 - val_acc: 0.8795 - val_weighted_accuracy: 0.8554\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2815 - acc: 0.8914 - weighted_accuracy: 0.7097 - val_loss: 0.2816 - val_acc: 0.8790 - val_weighted_accuracy: 0.8578\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2809 - acc: 0.8915 - weighted_accuracy: 0.7100 - val_loss: 0.2856 - val_acc: 0.8792 - val_weighted_accuracy: 0.8609\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2798 - acc: 0.8922 - weighted_accuracy: 0.7109 - val_loss: 0.2887 - val_acc: 0.8747 - val_weighted_accuracy: 0.8513\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2798 - acc: 0.8927 - weighted_accuracy: 0.7116 - val_loss: 0.2838 - val_acc: 0.8773 - val_weighted_accuracy: 0.8577\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2791 - acc: 0.8925 - weighted_accuracy: 0.7116 - val_loss: 0.2799 - val_acc: 0.8800 - val_weighted_accuracy: 0.8600\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2784 - acc: 0.8931 - weighted_accuracy: 0.7113 - val_loss: 0.2794 - val_acc: 0.8810 - val_weighted_accuracy: 0.8590\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2772 - acc: 0.8940 - weighted_accuracy: 0.7128 - val_loss: 0.2840 - val_acc: 0.8776 - val_weighted_accuracy: 0.8579\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2765 - acc: 0.8943 - weighted_accuracy: 0.7130 - val_loss: 0.2838 - val_acc: 0.8795 - val_weighted_accuracy: 0.8573\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2759 - acc: 0.8949 - weighted_accuracy: 0.7132 - val_loss: 0.2842 - val_acc: 0.8802 - val_weighted_accuracy: 0.8570\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2758 - acc: 0.8953 - weighted_accuracy: 0.7136 - val_loss: 0.2919 - val_acc: 0.8717 - val_weighted_accuracy: 0.8500\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2753 - acc: 0.8953 - weighted_accuracy: 0.7139 - val_loss: 0.2816 - val_acc: 0.8791 - val_weighted_accuracy: 0.8566\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2746 - acc: 0.8955 - weighted_accuracy: 0.7137 - val_loss: 0.2822 - val_acc: 0.8782 - val_weighted_accuracy: 0.8555\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2738 - acc: 0.8956 - weighted_accuracy: 0.7141 - val_loss: 0.2782 - val_acc: 0.8830 - val_weighted_accuracy: 0.8615\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2735 - acc: 0.8963 - weighted_accuracy: 0.7150 - val_loss: 0.2813 - val_acc: 0.8810 - val_weighted_accuracy: 0.8611\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2735 - acc: 0.8959 - weighted_accuracy: 0.7150 - val_loss: 0.2888 - val_acc: 0.8774 - val_weighted_accuracy: 0.8575\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2732 - acc: 0.8965 - weighted_accuracy: 0.7146 - val_loss: 0.2831 - val_acc: 0.8782 - val_weighted_accuracy: 0.8604\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2721 - acc: 0.8968 - weighted_accuracy: 0.7155 - val_loss: 0.2911 - val_acc: 0.8744 - val_weighted_accuracy: 0.8508\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2727 - acc: 0.8969 - weighted_accuracy: 0.7155 - val_loss: 0.2816 - val_acc: 0.8829 - val_weighted_accuracy: 0.8628\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2715 - acc: 0.8975 - weighted_accuracy: 0.7161 - val_loss: 0.2788 - val_acc: 0.8828 - val_weighted_accuracy: 0.8650\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2706 - acc: 0.8978 - weighted_accuracy: 0.7166 - val_loss: 0.2785 - val_acc: 0.8830 - val_weighted_accuracy: 0.8628\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2714 - acc: 0.8973 - weighted_accuracy: 0.7163 - val_loss: 0.2846 - val_acc: 0.8798 - val_weighted_accuracy: 0.8640\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2702 - acc: 0.8983 - weighted_accuracy: 0.7170 - val_loss: 0.2799 - val_acc: 0.8798 - val_weighted_accuracy: 0.8619\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2702 - acc: 0.8984 - weighted_accuracy: 0.7165 - val_loss: 0.2838 - val_acc: 0.8774 - val_weighted_accuracy: 0.8552\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 50, 151)      0           embedding_41[0][0]               \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 50, 151)      0           embedding_41[1][0]               \n",
      "                                                                 reshape_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_41 (SpatialDr (None, 50, 151)      0           concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_42 (SpatialDr (None, 50, 151)      0           concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 50, 64)       0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 50, 64)       0           conv1d_31[1][0]                  \n",
      "                                                                 conv1d_34[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 50, 64)       4160        multiply_47[0][0]                \n",
      "                                                                 multiply_48[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 50, 64)       0           conv1d_28[0][0]                  \n",
      "                                                                 conv1d_28[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_133 (Dot)                   (None, 50, 50)       0           dropout_100[0][0]                \n",
      "                                                                 dropout_100[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 50, 50)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_45 (Permute)            (None, 50, 50)       0           lambda_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 50, 50)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_135 (Dot)                   (None, 50, 64)       0           permute_45[0][0]                 \n",
      "                                                                 dropout_100[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_134 (Dot)                   (None, 50, 64)       0           lambda_117[0][0]                 \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 50, 279)      0           dropout_100[0][0]                \n",
      "                                                                 dot_135[0][0]                    \n",
      "                                                                 spatial_dropout1d_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 50, 279)      0           dropout_100[1][0]                \n",
      "                                                                 dot_134[0][0]                    \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 50, 64)       53632       concatenate_193[0][0]            \n",
      "                                                                 concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 50, 64)       53632       concatenate_193[0][0]            \n",
      "                                                                 concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 50, 64)       0           conv1d_32[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 50, 64)       0           conv1d_32[1][0]                  \n",
      "                                                                 conv1d_35[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 50, 64)       4160        multiply_49[0][0]                \n",
      "                                                                 multiply_50[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 50, 64)       0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_29[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_136 (Dot)                   (None, 50, 50)       0           dropout_101[0][0]                \n",
      "                                                                 dropout_101[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 50, 50)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_46 (Permute)            (None, 50, 50)       0           lambda_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 50, 50)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_138 (Dot)                   (None, 50, 64)       0           permute_46[0][0]                 \n",
      "                                                                 dropout_101[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_137 (Dot)                   (None, 50, 64)       0           lambda_119[0][0]                 \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_195 (Concatenate)   (None, 50, 407)      0           dropout_101[0][0]                \n",
      "                                                                 dot_138[0][0]                    \n",
      "                                                                 concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_196 (Concatenate)   (None, 50, 407)      0           dropout_101[1][0]                \n",
      "                                                                 dot_137[0][0]                    \n",
      "                                                                 concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 50, 64)       78208       concatenate_195[0][0]            \n",
      "                                                                 concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 50, 64)       78208       concatenate_195[0][0]            \n",
      "                                                                 concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 50, 64)       0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 50, 64)       0           conv1d_33[1][0]                  \n",
      "                                                                 conv1d_36[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 50, 64)       4160        multiply_51[0][0]                \n",
      "                                                                 multiply_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 50, 64)       0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_30[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_139 (Dot)                   (None, 50, 50)       0           dropout_102[0][0]                \n",
      "                                                                 dropout_102[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 50, 50)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_47 (Permute)            (None, 50, 50)       0           lambda_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 50, 50)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_141 (Dot)                   (None, 50, 64)       0           permute_47[0][0]                 \n",
      "                                                                 dropout_102[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_140 (Dot)                   (None, 50, 64)       0           lambda_121[0][0]                 \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_197 (Concatenate)   (None, 50, 535)      0           dropout_102[0][0]                \n",
      "                                                                 dot_141[0][0]                    \n",
      "                                                                 concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 50, 535)      0           dropout_102[1][0]                \n",
      "                                                                 dot_140[0][0]                    \n",
      "                                                                 concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_41 (Gl (None, 535)          0           concatenate_197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_41 (Global (None, 535)          0           concatenate_197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_4 (A (None, 535)          535         concatenate_197[0][0]            \n",
      "                                                                 concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_42 (Gl (None, 535)          0           concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_42 (Global (None, 535)          0           concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 1605)         0           global_average_pooling1d_41[0][0]\n",
      "                                                                 global_max_pooling1d_41[0][0]    \n",
      "                                                                 attention_weighted_average_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 1605)         0           global_average_pooling1d_42[0][0]\n",
      "                                                                 global_max_pooling1d_42[0][0]    \n",
      "                                                                 attention_weighted_average_4[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 1605)         0           concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 1605)         0           concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_201 (Concatenate)   (None, 6420)         0           concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "                                                                 lambda_123[0][0]                 \n",
      "                                                                 multiply_53[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 6420)         0           concatenate_201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 6420)         25680       dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 64)           410944      batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 3)            195         dense_57[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 130s 360us/step - loss: 0.3003 - acc: 0.8765 - weighted_accuracy: 0.6999 - val_loss: 0.3138 - val_acc: 0.8581 - val_weighted_accuracy: 0.8354\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2975 - acc: 0.8795 - weighted_accuracy: 0.6997 - val_loss: 0.3103 - val_acc: 0.8578 - val_weighted_accuracy: 0.8381\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2948 - acc: 0.8814 - weighted_accuracy: 0.7011 - val_loss: 0.3101 - val_acc: 0.8590 - val_weighted_accuracy: 0.8416\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2915 - acc: 0.8832 - weighted_accuracy: 0.7018 - val_loss: 0.3090 - val_acc: 0.8617 - val_weighted_accuracy: 0.8449\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2907 - acc: 0.8842 - weighted_accuracy: 0.7027 - val_loss: 0.3086 - val_acc: 0.8615 - val_weighted_accuracy: 0.8413\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2894 - acc: 0.8851 - weighted_accuracy: 0.7034 - val_loss: 0.3088 - val_acc: 0.8633 - val_weighted_accuracy: 0.8487\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2868 - acc: 0.8873 - weighted_accuracy: 0.7055 - val_loss: 0.3048 - val_acc: 0.8647 - val_weighted_accuracy: 0.8478\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2857 - acc: 0.8870 - weighted_accuracy: 0.7055 - val_loss: 0.3132 - val_acc: 0.8593 - val_weighted_accuracy: 0.8370\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 125s 348us/step - loss: 0.2843 - acc: 0.8888 - weighted_accuracy: 0.7064 - val_loss: 0.3123 - val_acc: 0.8597 - val_weighted_accuracy: 0.8402\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2828 - acc: 0.8898 - weighted_accuracy: 0.7074 - val_loss: 0.3047 - val_acc: 0.8657 - val_weighted_accuracy: 0.8481\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2816 - acc: 0.8897 - weighted_accuracy: 0.7080 - val_loss: 0.3048 - val_acc: 0.8664 - val_weighted_accuracy: 0.8483\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2808 - acc: 0.8911 - weighted_accuracy: 0.7084 - val_loss: 0.3106 - val_acc: 0.8642 - val_weighted_accuracy: 0.8524\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2808 - acc: 0.8909 - weighted_accuracy: 0.7092 - val_loss: 0.3138 - val_acc: 0.8613 - val_weighted_accuracy: 0.8467\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 125s 345us/step - loss: 0.2800 - acc: 0.8915 - weighted_accuracy: 0.7094 - val_loss: 0.3163 - val_acc: 0.8551 - val_weighted_accuracy: 0.8319\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2786 - acc: 0.8932 - weighted_accuracy: 0.7107 - val_loss: 0.3054 - val_acc: 0.8645 - val_weighted_accuracy: 0.8458\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2777 - acc: 0.8929 - weighted_accuracy: 0.7106 - val_loss: 0.3037 - val_acc: 0.8671 - val_weighted_accuracy: 0.8476\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2773 - acc: 0.8929 - weighted_accuracy: 0.7108 - val_loss: 0.3030 - val_acc: 0.8674 - val_weighted_accuracy: 0.8484\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2761 - acc: 0.8942 - weighted_accuracy: 0.7127 - val_loss: 0.3012 - val_acc: 0.8682 - val_weighted_accuracy: 0.8503\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 151s 418us/step - loss: 0.2760 - acc: 0.8949 - weighted_accuracy: 0.7126 - val_loss: 0.3068 - val_acc: 0.8662 - val_weighted_accuracy: 0.8471\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2754 - acc: 0.8940 - weighted_accuracy: 0.7121 - val_loss: 0.3082 - val_acc: 0.8640 - val_weighted_accuracy: 0.8499\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2754 - acc: 0.8946 - weighted_accuracy: 0.7126 - val_loss: 0.3035 - val_acc: 0.8664 - val_weighted_accuracy: 0.8486\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 126s 348us/step - loss: 0.2738 - acc: 0.8958 - weighted_accuracy: 0.7133 - val_loss: 0.3068 - val_acc: 0.8658 - val_weighted_accuracy: 0.8460\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2737 - acc: 0.8957 - weighted_accuracy: 0.7130 - val_loss: 0.3049 - val_acc: 0.8663 - val_weighted_accuracy: 0.8465\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2738 - acc: 0.8959 - weighted_accuracy: 0.7132 - val_loss: 0.3019 - val_acc: 0.8685 - val_weighted_accuracy: 0.8523\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2720 - acc: 0.8967 - weighted_accuracy: 0.7146 - val_loss: 0.3059 - val_acc: 0.8672 - val_weighted_accuracy: 0.8491\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2726 - acc: 0.8964 - weighted_accuracy: 0.7142 - val_loss: 0.3043 - val_acc: 0.8664 - val_weighted_accuracy: 0.8497\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2718 - acc: 0.8965 - weighted_accuracy: 0.7140 - val_loss: 0.3042 - val_acc: 0.8671 - val_weighted_accuracy: 0.8523\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2709 - acc: 0.8977 - weighted_accuracy: 0.7151 - val_loss: 0.3043 - val_acc: 0.8662 - val_weighted_accuracy: 0.8464\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_202 (Concatenate)   (None, 50, 151)      0           embedding_43[0][0]               \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_203 (Concatenate)   (None, 50, 151)      0           embedding_43[1][0]               \n",
      "                                                                 reshape_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_43 (SpatialDr (None, 50, 151)      0           concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_44 (SpatialDr (None, 50, 151)      0           concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_43[0][0]       \n",
      "                                                                 spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_43[0][0]       \n",
      "                                                                 spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 50, 64)       0           conv1d_40[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 50, 64)       0           conv1d_40[1][0]                  \n",
      "                                                                 conv1d_43[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 50, 64)       4160        multiply_54[0][0]                \n",
      "                                                                 multiply_55[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 50, 64)       0           conv1d_37[0][0]                  \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_142 (Dot)                   (None, 50, 50)       0           dropout_104[0][0]                \n",
      "                                                                 dropout_104[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 50, 50)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_48 (Permute)            (None, 50, 50)       0           lambda_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 50, 50)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_144 (Dot)                   (None, 50, 64)       0           permute_48[0][0]                 \n",
      "                                                                 dropout_104[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_143 (Dot)                   (None, 50, 64)       0           lambda_124[0][0]                 \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_204 (Concatenate)   (None, 50, 279)      0           dropout_104[0][0]                \n",
      "                                                                 dot_144[0][0]                    \n",
      "                                                                 spatial_dropout1d_43[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_205 (Concatenate)   (None, 50, 279)      0           dropout_104[1][0]                \n",
      "                                                                 dot_143[0][0]                    \n",
      "                                                                 spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 50, 64)       53632       concatenate_204[0][0]            \n",
      "                                                                 concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 50, 64)       53632       concatenate_204[0][0]            \n",
      "                                                                 concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 50, 64)       0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 50, 64)       0           conv1d_41[1][0]                  \n",
      "                                                                 conv1d_44[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 50, 64)       4160        multiply_56[0][0]                \n",
      "                                                                 multiply_57[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 50, 64)       0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_145 (Dot)                   (None, 50, 50)       0           dropout_105[0][0]                \n",
      "                                                                 dropout_105[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)             (None, 50, 50)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_49 (Permute)            (None, 50, 50)       0           lambda_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 50, 50)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_147 (Dot)                   (None, 50, 64)       0           permute_49[0][0]                 \n",
      "                                                                 dropout_105[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_146 (Dot)                   (None, 50, 64)       0           lambda_126[0][0]                 \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_206 (Concatenate)   (None, 50, 407)      0           dropout_105[0][0]                \n",
      "                                                                 dot_147[0][0]                    \n",
      "                                                                 concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_207 (Concatenate)   (None, 50, 407)      0           dropout_105[1][0]                \n",
      "                                                                 dot_146[0][0]                    \n",
      "                                                                 concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 50, 64)       78208       concatenate_206[0][0]            \n",
      "                                                                 concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 50, 64)       78208       concatenate_206[0][0]            \n",
      "                                                                 concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 50, 64)       0           conv1d_42[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 50, 64)       0           conv1d_42[1][0]                  \n",
      "                                                                 conv1d_45[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 50, 64)       4160        multiply_58[0][0]                \n",
      "                                                                 multiply_59[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 50, 64)       0           conv1d_39[0][0]                  \n",
      "                                                                 conv1d_39[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_148 (Dot)                   (None, 50, 50)       0           dropout_106[0][0]                \n",
      "                                                                 dropout_106[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 50, 50)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_50 (Permute)            (None, 50, 50)       0           lambda_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             (None, 50, 50)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_150 (Dot)                   (None, 50, 64)       0           permute_50[0][0]                 \n",
      "                                                                 dropout_106[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_149 (Dot)                   (None, 50, 64)       0           lambda_128[0][0]                 \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_208 (Concatenate)   (None, 50, 535)      0           dropout_106[0][0]                \n",
      "                                                                 dot_150[0][0]                    \n",
      "                                                                 concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_209 (Concatenate)   (None, 50, 535)      0           dropout_106[1][0]                \n",
      "                                                                 dot_149[0][0]                    \n",
      "                                                                 concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_43 (Gl (None, 535)          0           concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_43 (Global (None, 535)          0           concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_5 (A (None, 535)          535         concatenate_208[0][0]            \n",
      "                                                                 concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_44 (Gl (None, 535)          0           concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_44 (Global (None, 535)          0           concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_210 (Concatenate)   (None, 1605)         0           global_average_pooling1d_43[0][0]\n",
      "                                                                 global_max_pooling1d_43[0][0]    \n",
      "                                                                 attention_weighted_average_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_211 (Concatenate)   (None, 1605)         0           global_average_pooling1d_44[0][0]\n",
      "                                                                 global_max_pooling1d_44[0][0]    \n",
      "                                                                 attention_weighted_average_5[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             (None, 1605)         0           concatenate_210[0][0]            \n",
      "                                                                 concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 1605)         0           concatenate_210[0][0]            \n",
      "                                                                 concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_212 (Concatenate)   (None, 6420)         0           concatenate_210[0][0]            \n",
      "                                                                 concatenate_211[0][0]            \n",
      "                                                                 lambda_130[0][0]                 \n",
      "                                                                 multiply_60[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 6420)         0           concatenate_212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6420)         25680       dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 64)           410944      batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 3)            195         dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 129s 358us/step - loss: 0.2928 - acc: 0.8805 - weighted_accuracy: 0.7039 - val_loss: 0.3047 - val_acc: 0.8629 - val_weighted_accuracy: 0.8422\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2937 - acc: 0.8815 - weighted_accuracy: 0.7025 - val_loss: 0.3036 - val_acc: 0.8628 - val_weighted_accuracy: 0.8450\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2924 - acc: 0.8827 - weighted_accuracy: 0.7028 - val_loss: 0.3166 - val_acc: 0.8570 - val_weighted_accuracy: 0.8361\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2914 - acc: 0.8835 - weighted_accuracy: 0.7022 - val_loss: 0.3019 - val_acc: 0.8666 - val_weighted_accuracy: 0.8462\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2903 - acc: 0.8845 - weighted_accuracy: 0.7040 - val_loss: 0.3041 - val_acc: 0.8645 - val_weighted_accuracy: 0.8403\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2887 - acc: 0.8851 - weighted_accuracy: 0.7039 - val_loss: 0.3079 - val_acc: 0.8618 - val_weighted_accuracy: 0.8369\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2872 - acc: 0.8866 - weighted_accuracy: 0.7049 - val_loss: 0.3095 - val_acc: 0.8601 - val_weighted_accuracy: 0.8370\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2861 - acc: 0.8875 - weighted_accuracy: 0.7058 - val_loss: 0.3032 - val_acc: 0.8659 - val_weighted_accuracy: 0.8487\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2849 - acc: 0.8881 - weighted_accuracy: 0.7066 - val_loss: 0.3002 - val_acc: 0.8701 - val_weighted_accuracy: 0.8415\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2844 - acc: 0.8892 - weighted_accuracy: 0.7070 - val_loss: 0.3091 - val_acc: 0.8622 - val_weighted_accuracy: 0.8352\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2823 - acc: 0.8902 - weighted_accuracy: 0.7083 - val_loss: 0.3006 - val_acc: 0.8698 - val_weighted_accuracy: 0.8476\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 122s 339us/step - loss: 0.2823 - acc: 0.8902 - weighted_accuracy: 0.7079 - val_loss: 0.3033 - val_acc: 0.8682 - val_weighted_accuracy: 0.8497\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2824 - acc: 0.8904 - weighted_accuracy: 0.7089 - val_loss: 0.3009 - val_acc: 0.8695 - val_weighted_accuracy: 0.8486\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2807 - acc: 0.8914 - weighted_accuracy: 0.7092 - val_loss: 0.3071 - val_acc: 0.8662 - val_weighted_accuracy: 0.8429\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2791 - acc: 0.8922 - weighted_accuracy: 0.7098 - val_loss: 0.3029 - val_acc: 0.8684 - val_weighted_accuracy: 0.8447\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2795 - acc: 0.8927 - weighted_accuracy: 0.7102 - val_loss: 0.3002 - val_acc: 0.8695 - val_weighted_accuracy: 0.8486\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2781 - acc: 0.8933 - weighted_accuracy: 0.7110 - val_loss: 0.3014 - val_acc: 0.8681 - val_weighted_accuracy: 0.8505\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2777 - acc: 0.8933 - weighted_accuracy: 0.7114 - val_loss: 0.3054 - val_acc: 0.8653 - val_weighted_accuracy: 0.8404\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2770 - acc: 0.8940 - weighted_accuracy: 0.7121 - val_loss: 0.3080 - val_acc: 0.8661 - val_weighted_accuracy: 0.8471\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2761 - acc: 0.8942 - weighted_accuracy: 0.7123 - val_loss: 0.3023 - val_acc: 0.8700 - val_weighted_accuracy: 0.8534\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2757 - acc: 0.8945 - weighted_accuracy: 0.7125 - val_loss: 0.2986 - val_acc: 0.8705 - val_weighted_accuracy: 0.8521\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2752 - acc: 0.8951 - weighted_accuracy: 0.7126 - val_loss: 0.2966 - val_acc: 0.8734 - val_weighted_accuracy: 0.8508\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2749 - acc: 0.8949 - weighted_accuracy: 0.7124 - val_loss: 0.2991 - val_acc: 0.8716 - val_weighted_accuracy: 0.8516\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2741 - acc: 0.8953 - weighted_accuracy: 0.7133 - val_loss: 0.3059 - val_acc: 0.8645 - val_weighted_accuracy: 0.8412\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2739 - acc: 0.8955 - weighted_accuracy: 0.7135 - val_loss: 0.2977 - val_acc: 0.8709 - val_weighted_accuracy: 0.8496\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2725 - acc: 0.8960 - weighted_accuracy: 0.7140 - val_loss: 0.2978 - val_acc: 0.8732 - val_weighted_accuracy: 0.8575\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2727 - acc: 0.8963 - weighted_accuracy: 0.7139 - val_loss: 0.2969 - val_acc: 0.8750 - val_weighted_accuracy: 0.8565\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2715 - acc: 0.8976 - weighted_accuracy: 0.7150 - val_loss: 0.2967 - val_acc: 0.8727 - val_weighted_accuracy: 0.8524\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2721 - acc: 0.8964 - weighted_accuracy: 0.7142 - val_loss: 0.2944 - val_acc: 0.8746 - val_weighted_accuracy: 0.8575\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2711 - acc: 0.8975 - weighted_accuracy: 0.7153 - val_loss: 0.3020 - val_acc: 0.8697 - val_weighted_accuracy: 0.8405\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2710 - acc: 0.8975 - weighted_accuracy: 0.7153 - val_loss: 0.3094 - val_acc: 0.8638 - val_weighted_accuracy: 0.8350\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2707 - acc: 0.8974 - weighted_accuracy: 0.7150 - val_loss: 0.2987 - val_acc: 0.8719 - val_weighted_accuracy: 0.8482\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2688 - acc: 0.8989 - weighted_accuracy: 0.7159 - val_loss: 0.2987 - val_acc: 0.8694 - val_weighted_accuracy: 0.8483\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2695 - acc: 0.8977 - weighted_accuracy: 0.7153 - val_loss: 0.3008 - val_acc: 0.8693 - val_weighted_accuracy: 0.8511\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2692 - acc: 0.8984 - weighted_accuracy: 0.7154 - val_loss: 0.2950 - val_acc: 0.8747 - val_weighted_accuracy: 0.8557\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2686 - acc: 0.8992 - weighted_accuracy: 0.7162 - val_loss: 0.3101 - val_acc: 0.8618 - val_weighted_accuracy: 0.8357\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2682 - acc: 0.8988 - weighted_accuracy: 0.7161 - val_loss: 0.2969 - val_acc: 0.8712 - val_weighted_accuracy: 0.8458\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.2684 - acc: 0.8990 - weighted_accuracy: 0.7164 - val_loss: 0.2958 - val_acc: 0.8713 - val_weighted_accuracy: 0.8477\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2681 - acc: 0.8988 - weighted_accuracy: 0.7160 - val_loss: 0.2963 - val_acc: 0.8712 - val_weighted_accuracy: 0.8517\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_213 (Concatenate)   (None, 50, 151)      0           embedding_45[0][0]               \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)   (None, 50, 151)      0           embedding_45[1][0]               \n",
      "                                                                 reshape_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_45 (SpatialDr (None, 50, 151)      0           concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_46 (SpatialDr (None, 50, 151)      0           concatenate_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_45[0][0]       \n",
      "                                                                 spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_45[0][0]       \n",
      "                                                                 spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 50, 64)       0           conv1d_49[0][0]                  \n",
      "                                                                 conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 50, 64)       0           conv1d_49[1][0]                  \n",
      "                                                                 conv1d_52[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 50, 64)       4160        multiply_61[0][0]                \n",
      "                                                                 multiply_62[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 50, 64)       0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_46[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_151 (Dot)                   (None, 50, 50)       0           dropout_108[0][0]                \n",
      "                                                                 dropout_108[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             (None, 50, 50)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_51 (Permute)            (None, 50, 50)       0           lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 50, 50)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_153 (Dot)                   (None, 50, 64)       0           permute_51[0][0]                 \n",
      "                                                                 dropout_108[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_152 (Dot)                   (None, 50, 64)       0           lambda_131[0][0]                 \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_215 (Concatenate)   (None, 50, 279)      0           dropout_108[0][0]                \n",
      "                                                                 dot_153[0][0]                    \n",
      "                                                                 spatial_dropout1d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_216 (Concatenate)   (None, 50, 279)      0           dropout_108[1][0]                \n",
      "                                                                 dot_152[0][0]                    \n",
      "                                                                 spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 50, 64)       53632       concatenate_215[0][0]            \n",
      "                                                                 concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 50, 64)       53632       concatenate_215[0][0]            \n",
      "                                                                 concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 50, 64)       0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 50, 64)       0           conv1d_50[1][0]                  \n",
      "                                                                 conv1d_53[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 50, 64)       4160        multiply_63[0][0]                \n",
      "                                                                 multiply_64[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 50, 64)       0           conv1d_47[0][0]                  \n",
      "                                                                 conv1d_47[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_154 (Dot)                   (None, 50, 50)       0           dropout_109[0][0]                \n",
      "                                                                 dropout_109[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             (None, 50, 50)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_52 (Permute)            (None, 50, 50)       0           lambda_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 50, 50)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_156 (Dot)                   (None, 50, 64)       0           permute_52[0][0]                 \n",
      "                                                                 dropout_109[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_155 (Dot)                   (None, 50, 64)       0           lambda_133[0][0]                 \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_217 (Concatenate)   (None, 50, 407)      0           dropout_109[0][0]                \n",
      "                                                                 dot_156[0][0]                    \n",
      "                                                                 concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_218 (Concatenate)   (None, 50, 407)      0           dropout_109[1][0]                \n",
      "                                                                 dot_155[0][0]                    \n",
      "                                                                 concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 50, 64)       78208       concatenate_217[0][0]            \n",
      "                                                                 concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 50, 64)       78208       concatenate_217[0][0]            \n",
      "                                                                 concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_65 (Multiply)          (None, 50, 64)       0           conv1d_51[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_66 (Multiply)          (None, 50, 64)       0           conv1d_51[1][0]                  \n",
      "                                                                 conv1d_54[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 50, 64)       4160        multiply_65[0][0]                \n",
      "                                                                 multiply_66[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 50, 64)       0           conv1d_48[0][0]                  \n",
      "                                                                 conv1d_48[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_157 (Dot)                   (None, 50, 50)       0           dropout_110[0][0]                \n",
      "                                                                 dropout_110[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 50, 50)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_53 (Permute)            (None, 50, 50)       0           lambda_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 50, 50)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_159 (Dot)                   (None, 50, 64)       0           permute_53[0][0]                 \n",
      "                                                                 dropout_110[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_158 (Dot)                   (None, 50, 64)       0           lambda_135[0][0]                 \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_219 (Concatenate)   (None, 50, 535)      0           dropout_110[0][0]                \n",
      "                                                                 dot_159[0][0]                    \n",
      "                                                                 concatenate_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_220 (Concatenate)   (None, 50, 535)      0           dropout_110[1][0]                \n",
      "                                                                 dot_158[0][0]                    \n",
      "                                                                 concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_45 (Gl (None, 535)          0           concatenate_219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_45 (Global (None, 535)          0           concatenate_219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_6 (A (None, 535)          535         concatenate_219[0][0]            \n",
      "                                                                 concatenate_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_46 (Gl (None, 535)          0           concatenate_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_46 (Global (None, 535)          0           concatenate_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_221 (Concatenate)   (None, 1605)         0           global_average_pooling1d_45[0][0]\n",
      "                                                                 global_max_pooling1d_45[0][0]    \n",
      "                                                                 attention_weighted_average_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_222 (Concatenate)   (None, 1605)         0           global_average_pooling1d_46[0][0]\n",
      "                                                                 global_max_pooling1d_46[0][0]    \n",
      "                                                                 attention_weighted_average_6[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 1605)         0           concatenate_221[0][0]            \n",
      "                                                                 concatenate_222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_67 (Multiply)          (None, 1605)         0           concatenate_221[0][0]            \n",
      "                                                                 concatenate_222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_223 (Concatenate)   (None, 6420)         0           concatenate_221[0][0]            \n",
      "                                                                 concatenate_222[0][0]            \n",
      "                                                                 lambda_137[0][0]                 \n",
      "                                                                 multiply_67[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 6420)         0           concatenate_223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 6420)         25680       dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 64)           410944      batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 3)            195         dense_61[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 129s 358us/step - loss: 0.2857 - acc: 0.8853 - weighted_accuracy: 0.7087 - val_loss: 0.3185 - val_acc: 0.8527 - val_weighted_accuracy: 0.8355\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2880 - acc: 0.8845 - weighted_accuracy: 0.7053 - val_loss: 0.3201 - val_acc: 0.8502 - val_weighted_accuracy: 0.8270\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2880 - acc: 0.8853 - weighted_accuracy: 0.7059 - val_loss: 0.3226 - val_acc: 0.8515 - val_weighted_accuracy: 0.8262\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2878 - acc: 0.8858 - weighted_accuracy: 0.7057 - val_loss: 0.3196 - val_acc: 0.8528 - val_weighted_accuracy: 0.8321\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2861 - acc: 0.8877 - weighted_accuracy: 0.7062 - val_loss: 0.3178 - val_acc: 0.8576 - val_weighted_accuracy: 0.8336\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2847 - acc: 0.8882 - weighted_accuracy: 0.7069 - val_loss: 0.3178 - val_acc: 0.8555 - val_weighted_accuracy: 0.8367\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2843 - acc: 0.8890 - weighted_accuracy: 0.7076 - val_loss: 0.3148 - val_acc: 0.8582 - val_weighted_accuracy: 0.8379\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2832 - acc: 0.8900 - weighted_accuracy: 0.7082 - val_loss: 0.3191 - val_acc: 0.8540 - val_weighted_accuracy: 0.8327\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2823 - acc: 0.8905 - weighted_accuracy: 0.7086 - val_loss: 0.3210 - val_acc: 0.8551 - val_weighted_accuracy: 0.8327\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2826 - acc: 0.8902 - weighted_accuracy: 0.7090 - val_loss: 0.3140 - val_acc: 0.8572 - val_weighted_accuracy: 0.8329\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2808 - acc: 0.8909 - weighted_accuracy: 0.7084 - val_loss: 0.3188 - val_acc: 0.8560 - val_weighted_accuracy: 0.8355\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2805 - acc: 0.8920 - weighted_accuracy: 0.7099 - val_loss: 0.3302 - val_acc: 0.8503 - val_weighted_accuracy: 0.8303\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2793 - acc: 0.8926 - weighted_accuracy: 0.7102 - val_loss: 0.3216 - val_acc: 0.8506 - val_weighted_accuracy: 0.8268\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 122s 340us/step - loss: 0.2794 - acc: 0.8921 - weighted_accuracy: 0.7102 - val_loss: 0.3290 - val_acc: 0.8492 - val_weighted_accuracy: 0.8291\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2787 - acc: 0.8927 - weighted_accuracy: 0.7103 - val_loss: 0.3199 - val_acc: 0.8584 - val_weighted_accuracy: 0.8386\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2775 - acc: 0.8933 - weighted_accuracy: 0.7112 - val_loss: 0.3273 - val_acc: 0.8498 - val_weighted_accuracy: 0.8267\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2773 - acc: 0.8940 - weighted_accuracy: 0.7114 - val_loss: 0.3176 - val_acc: 0.8576 - val_weighted_accuracy: 0.8335\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2758 - acc: 0.8944 - weighted_accuracy: 0.7121 - val_loss: 0.3280 - val_acc: 0.8482 - val_weighted_accuracy: 0.8225\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2760 - acc: 0.8949 - weighted_accuracy: 0.7123 - val_loss: 0.3182 - val_acc: 0.8567 - val_weighted_accuracy: 0.8330\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 340us/step - loss: 0.2749 - acc: 0.8948 - weighted_accuracy: 0.7119 - val_loss: 0.3138 - val_acc: 0.8614 - val_weighted_accuracy: 0.8429\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2744 - acc: 0.8955 - weighted_accuracy: 0.7129 - val_loss: 0.3206 - val_acc: 0.8540 - val_weighted_accuracy: 0.8269\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2740 - acc: 0.8953 - weighted_accuracy: 0.7128 - val_loss: 0.3197 - val_acc: 0.8554 - val_weighted_accuracy: 0.8305\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2738 - acc: 0.8959 - weighted_accuracy: 0.7139 - val_loss: 0.3261 - val_acc: 0.8503 - val_weighted_accuracy: 0.8221\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2728 - acc: 0.8970 - weighted_accuracy: 0.7145 - val_loss: 0.3231 - val_acc: 0.8561 - val_weighted_accuracy: 0.8341\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2728 - acc: 0.8967 - weighted_accuracy: 0.7142 - val_loss: 0.3136 - val_acc: 0.8606 - val_weighted_accuracy: 0.8366\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2723 - acc: 0.8971 - weighted_accuracy: 0.7145 - val_loss: 0.3173 - val_acc: 0.8571 - val_weighted_accuracy: 0.8337\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2718 - acc: 0.8969 - weighted_accuracy: 0.7145 - val_loss: 0.3159 - val_acc: 0.8607 - val_weighted_accuracy: 0.8384\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2717 - acc: 0.8973 - weighted_accuracy: 0.7148 - val_loss: 0.3153 - val_acc: 0.8591 - val_weighted_accuracy: 0.8391\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2707 - acc: 0.8982 - weighted_accuracy: 0.7154 - val_loss: 0.3171 - val_acc: 0.8565 - val_weighted_accuracy: 0.8337\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2700 - acc: 0.8981 - weighted_accuracy: 0.7157 - val_loss: 0.3213 - val_acc: 0.8548 - val_weighted_accuracy: 0.8340\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2691 - acc: 0.8984 - weighted_accuracy: 0.7159 - val_loss: 0.3181 - val_acc: 0.8583 - val_weighted_accuracy: 0.8361\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2699 - acc: 0.8983 - weighted_accuracy: 0.7151 - val_loss: 0.3188 - val_acc: 0.8570 - val_weighted_accuracy: 0.8325\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2686 - acc: 0.8988 - weighted_accuracy: 0.7162 - val_loss: 0.3297 - val_acc: 0.8511 - val_weighted_accuracy: 0.8225\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2680 - acc: 0.8994 - weighted_accuracy: 0.7163 - val_loss: 0.3205 - val_acc: 0.8583 - val_weighted_accuracy: 0.8361\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2683 - acc: 0.8990 - weighted_accuracy: 0.7162 - val_loss: 0.3266 - val_acc: 0.8543 - val_weighted_accuracy: 0.8320\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_224 (Concatenate)   (None, 50, 151)      0           embedding_47[0][0]               \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_225 (Concatenate)   (None, 50, 151)      0           embedding_47[1][0]               \n",
      "                                                                 reshape_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_47 (SpatialDr (None, 50, 151)      0           concatenate_224[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 50, 151)      0           concatenate_225[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_47[0][0]       \n",
      "                                                                 spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_47[0][0]       \n",
      "                                                                 spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_68 (Multiply)          (None, 50, 64)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_69 (Multiply)          (None, 50, 64)       0           conv1d_58[1][0]                  \n",
      "                                                                 conv1d_61[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 50, 64)       4160        multiply_68[0][0]                \n",
      "                                                                 multiply_69[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 50, 64)       0           conv1d_55[0][0]                  \n",
      "                                                                 conv1d_55[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_160 (Dot)                   (None, 50, 50)       0           dropout_112[0][0]                \n",
      "                                                                 dropout_112[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 50, 50)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_54 (Permute)            (None, 50, 50)       0           lambda_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 50, 50)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_162 (Dot)                   (None, 50, 64)       0           permute_54[0][0]                 \n",
      "                                                                 dropout_112[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_161 (Dot)                   (None, 50, 64)       0           lambda_138[0][0]                 \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_226 (Concatenate)   (None, 50, 279)      0           dropout_112[0][0]                \n",
      "                                                                 dot_162[0][0]                    \n",
      "                                                                 spatial_dropout1d_47[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_227 (Concatenate)   (None, 50, 279)      0           dropout_112[1][0]                \n",
      "                                                                 dot_161[0][0]                    \n",
      "                                                                 spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 50, 64)       53632       concatenate_226[0][0]            \n",
      "                                                                 concatenate_227[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 50, 64)       53632       concatenate_226[0][0]            \n",
      "                                                                 concatenate_227[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_70 (Multiply)          (None, 50, 64)       0           conv1d_59[0][0]                  \n",
      "                                                                 conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_71 (Multiply)          (None, 50, 64)       0           conv1d_59[1][0]                  \n",
      "                                                                 conv1d_62[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 50, 64)       4160        multiply_70[0][0]                \n",
      "                                                                 multiply_71[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 50, 64)       0           conv1d_56[0][0]                  \n",
      "                                                                 conv1d_56[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_163 (Dot)                   (None, 50, 50)       0           dropout_113[0][0]                \n",
      "                                                                 dropout_113[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 50, 50)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_55 (Permute)            (None, 50, 50)       0           lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 50, 50)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_165 (Dot)                   (None, 50, 64)       0           permute_55[0][0]                 \n",
      "                                                                 dropout_113[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_164 (Dot)                   (None, 50, 64)       0           lambda_140[0][0]                 \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_228 (Concatenate)   (None, 50, 407)      0           dropout_113[0][0]                \n",
      "                                                                 dot_165[0][0]                    \n",
      "                                                                 concatenate_226[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_229 (Concatenate)   (None, 50, 407)      0           dropout_113[1][0]                \n",
      "                                                                 dot_164[0][0]                    \n",
      "                                                                 concatenate_227[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 50, 64)       78208       concatenate_228[0][0]            \n",
      "                                                                 concatenate_229[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 50, 64)       78208       concatenate_228[0][0]            \n",
      "                                                                 concatenate_229[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_72 (Multiply)          (None, 50, 64)       0           conv1d_60[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_73 (Multiply)          (None, 50, 64)       0           conv1d_60[1][0]                  \n",
      "                                                                 conv1d_63[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 50, 64)       4160        multiply_72[0][0]                \n",
      "                                                                 multiply_73[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 50, 64)       0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_166 (Dot)                   (None, 50, 50)       0           dropout_114[0][0]                \n",
      "                                                                 dropout_114[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 50, 50)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_56 (Permute)            (None, 50, 50)       0           lambda_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 50, 50)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_168 (Dot)                   (None, 50, 64)       0           permute_56[0][0]                 \n",
      "                                                                 dropout_114[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_167 (Dot)                   (None, 50, 64)       0           lambda_142[0][0]                 \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_230 (Concatenate)   (None, 50, 535)      0           dropout_114[0][0]                \n",
      "                                                                 dot_168[0][0]                    \n",
      "                                                                 concatenate_228[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_231 (Concatenate)   (None, 50, 535)      0           dropout_114[1][0]                \n",
      "                                                                 dot_167[0][0]                    \n",
      "                                                                 concatenate_229[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_47 (Gl (None, 535)          0           concatenate_230[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_47 (Global (None, 535)          0           concatenate_230[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_7 (A (None, 535)          535         concatenate_230[0][0]            \n",
      "                                                                 concatenate_231[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_48 (Gl (None, 535)          0           concatenate_231[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_48 (Global (None, 535)          0           concatenate_231[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_232 (Concatenate)   (None, 1605)         0           global_average_pooling1d_47[0][0]\n",
      "                                                                 global_max_pooling1d_47[0][0]    \n",
      "                                                                 attention_weighted_average_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_233 (Concatenate)   (None, 1605)         0           global_average_pooling1d_48[0][0]\n",
      "                                                                 global_max_pooling1d_48[0][0]    \n",
      "                                                                 attention_weighted_average_7[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 1605)         0           concatenate_232[0][0]            \n",
      "                                                                 concatenate_233[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_74 (Multiply)          (None, 1605)         0           concatenate_232[0][0]            \n",
      "                                                                 concatenate_233[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_234 (Concatenate)   (None, 6420)         0           concatenate_232[0][0]            \n",
      "                                                                 concatenate_233[0][0]            \n",
      "                                                                 lambda_144[0][0]                 \n",
      "                                                                 multiply_74[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 6420)         0           concatenate_234[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 6420)         25680       dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 64)           410944      batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 3)            195         dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 130s 361us/step - loss: 0.2948 - acc: 0.8799 - weighted_accuracy: 0.7031 - val_loss: 0.3432 - val_acc: 0.8447 - val_weighted_accuracy: 0.8165\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2945 - acc: 0.8806 - weighted_accuracy: 0.7013 - val_loss: 0.3368 - val_acc: 0.8439 - val_weighted_accuracy: 0.8210\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2921 - acc: 0.8824 - weighted_accuracy: 0.7022 - val_loss: 0.3353 - val_acc: 0.8455 - val_weighted_accuracy: 0.8201\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2895 - acc: 0.8850 - weighted_accuracy: 0.7038 - val_loss: 0.3452 - val_acc: 0.8431 - val_weighted_accuracy: 0.8111\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2885 - acc: 0.8853 - weighted_accuracy: 0.7044 - val_loss: 0.3271 - val_acc: 0.8526 - val_weighted_accuracy: 0.8241\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2864 - acc: 0.8866 - weighted_accuracy: 0.7054 - val_loss: 0.3331 - val_acc: 0.8478 - val_weighted_accuracy: 0.8141\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2856 - acc: 0.8880 - weighted_accuracy: 0.7063 - val_loss: 0.3314 - val_acc: 0.8472 - val_weighted_accuracy: 0.8185\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2835 - acc: 0.8887 - weighted_accuracy: 0.7072 - val_loss: 0.3317 - val_acc: 0.8455 - val_weighted_accuracy: 0.8124\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2824 - acc: 0.8896 - weighted_accuracy: 0.7080 - val_loss: 0.3344 - val_acc: 0.8479 - val_weighted_accuracy: 0.8233\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2818 - acc: 0.8901 - weighted_accuracy: 0.7082 - val_loss: 0.3288 - val_acc: 0.8505 - val_weighted_accuracy: 0.8236\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 123s 341us/step - loss: 0.2804 - acc: 0.8915 - weighted_accuracy: 0.7094 - val_loss: 0.3269 - val_acc: 0.8506 - val_weighted_accuracy: 0.8192\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2790 - acc: 0.8919 - weighted_accuracy: 0.7101 - val_loss: 0.3294 - val_acc: 0.8503 - val_weighted_accuracy: 0.8162\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2783 - acc: 0.8927 - weighted_accuracy: 0.7107 - val_loss: 0.3407 - val_acc: 0.8482 - val_weighted_accuracy: 0.8165\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2777 - acc: 0.8935 - weighted_accuracy: 0.7106 - val_loss: 0.3333 - val_acc: 0.8526 - val_weighted_accuracy: 0.8234\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2771 - acc: 0.8929 - weighted_accuracy: 0.7104 - val_loss: 0.3395 - val_acc: 0.8446 - val_weighted_accuracy: 0.8179\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2760 - acc: 0.8935 - weighted_accuracy: 0.7118 - val_loss: 0.3291 - val_acc: 0.8479 - val_weighted_accuracy: 0.8185\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2770 - acc: 0.8937 - weighted_accuracy: 0.7116 - val_loss: 0.3307 - val_acc: 0.8477 - val_weighted_accuracy: 0.8173\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2740 - acc: 0.8947 - weighted_accuracy: 0.7122 - val_loss: 0.3246 - val_acc: 0.8521 - val_weighted_accuracy: 0.8265\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2752 - acc: 0.8951 - weighted_accuracy: 0.7128 - val_loss: 0.3377 - val_acc: 0.8489 - val_weighted_accuracy: 0.8213\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2738 - acc: 0.8953 - weighted_accuracy: 0.7131 - val_loss: 0.3266 - val_acc: 0.8510 - val_weighted_accuracy: 0.8255\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2727 - acc: 0.8960 - weighted_accuracy: 0.7138 - val_loss: 0.3360 - val_acc: 0.8509 - val_weighted_accuracy: 0.8196\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2723 - acc: 0.8956 - weighted_accuracy: 0.7138 - val_loss: 0.3315 - val_acc: 0.8514 - val_weighted_accuracy: 0.8217\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2716 - acc: 0.8968 - weighted_accuracy: 0.7148 - val_loss: 0.3319 - val_acc: 0.8494 - val_weighted_accuracy: 0.8184\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2713 - acc: 0.8970 - weighted_accuracy: 0.7149 - val_loss: 0.3332 - val_acc: 0.8499 - val_weighted_accuracy: 0.8246\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2709 - acc: 0.8970 - weighted_accuracy: 0.7141 - val_loss: 0.3326 - val_acc: 0.8480 - val_weighted_accuracy: 0.8184\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2710 - acc: 0.8968 - weighted_accuracy: 0.7150 - val_loss: 0.3443 - val_acc: 0.8467 - val_weighted_accuracy: 0.8149\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2707 - acc: 0.8970 - weighted_accuracy: 0.7144 - val_loss: 0.3360 - val_acc: 0.8507 - val_weighted_accuracy: 0.8209\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2692 - acc: 0.8975 - weighted_accuracy: 0.7154 - val_loss: 0.3368 - val_acc: 0.8523 - val_weighted_accuracy: 0.8272\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_235 (Concatenate)   (None, 50, 151)      0           embedding_49[0][0]               \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_236 (Concatenate)   (None, 50, 151)      0           embedding_49[1][0]               \n",
      "                                                                 reshape_8[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 50, 151)      0           concatenate_235[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, 50, 151)      0           concatenate_236[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_75 (Multiply)          (None, 50, 64)       0           conv1d_67[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_76 (Multiply)          (None, 50, 64)       0           conv1d_67[1][0]                  \n",
      "                                                                 conv1d_70[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 50, 64)       4160        multiply_75[0][0]                \n",
      "                                                                 multiply_76[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 50, 64)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_169 (Dot)                   (None, 50, 50)       0           dropout_116[0][0]                \n",
      "                                                                 dropout_116[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 50, 50)       0           dot_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_57 (Permute)            (None, 50, 50)       0           lambda_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 50, 50)       0           dot_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_171 (Dot)                   (None, 50, 64)       0           permute_57[0][0]                 \n",
      "                                                                 dropout_116[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_170 (Dot)                   (None, 50, 64)       0           lambda_145[0][0]                 \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_237 (Concatenate)   (None, 50, 279)      0           dropout_116[0][0]                \n",
      "                                                                 dot_171[0][0]                    \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_238 (Concatenate)   (None, 50, 279)      0           dropout_116[1][0]                \n",
      "                                                                 dot_170[0][0]                    \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 50, 64)       53632       concatenate_237[0][0]            \n",
      "                                                                 concatenate_238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 50, 64)       53632       concatenate_237[0][0]            \n",
      "                                                                 concatenate_238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_77 (Multiply)          (None, 50, 64)       0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_78 (Multiply)          (None, 50, 64)       0           conv1d_68[1][0]                  \n",
      "                                                                 conv1d_71[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 50, 64)       4160        multiply_77[0][0]                \n",
      "                                                                 multiply_78[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 50, 64)       0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_172 (Dot)                   (None, 50, 50)       0           dropout_117[0][0]                \n",
      "                                                                 dropout_117[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 50, 50)       0           dot_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_58 (Permute)            (None, 50, 50)       0           lambda_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 50, 50)       0           dot_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_174 (Dot)                   (None, 50, 64)       0           permute_58[0][0]                 \n",
      "                                                                 dropout_117[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_173 (Dot)                   (None, 50, 64)       0           lambda_147[0][0]                 \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_239 (Concatenate)   (None, 50, 407)      0           dropout_117[0][0]                \n",
      "                                                                 dot_174[0][0]                    \n",
      "                                                                 concatenate_237[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_240 (Concatenate)   (None, 50, 407)      0           dropout_117[1][0]                \n",
      "                                                                 dot_173[0][0]                    \n",
      "                                                                 concatenate_238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 50, 64)       78208       concatenate_239[0][0]            \n",
      "                                                                 concatenate_240[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 50, 64)       78208       concatenate_239[0][0]            \n",
      "                                                                 concatenate_240[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_79 (Multiply)          (None, 50, 64)       0           conv1d_69[0][0]                  \n",
      "                                                                 conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_80 (Multiply)          (None, 50, 64)       0           conv1d_69[1][0]                  \n",
      "                                                                 conv1d_72[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 50, 64)       4160        multiply_79[0][0]                \n",
      "                                                                 multiply_80[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 50, 64)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_175 (Dot)                   (None, 50, 50)       0           dropout_118[0][0]                \n",
      "                                                                 dropout_118[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 50, 50)       0           dot_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_59 (Permute)            (None, 50, 50)       0           lambda_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 50, 50)       0           dot_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_177 (Dot)                   (None, 50, 64)       0           permute_59[0][0]                 \n",
      "                                                                 dropout_118[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_176 (Dot)                   (None, 50, 64)       0           lambda_149[0][0]                 \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_241 (Concatenate)   (None, 50, 535)      0           dropout_118[0][0]                \n",
      "                                                                 dot_177[0][0]                    \n",
      "                                                                 concatenate_239[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_242 (Concatenate)   (None, 50, 535)      0           dropout_118[1][0]                \n",
      "                                                                 dot_176[0][0]                    \n",
      "                                                                 concatenate_240[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_49 (Gl (None, 535)          0           concatenate_241[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_49 (Global (None, 535)          0           concatenate_241[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_8 (A (None, 535)          535         concatenate_241[0][0]            \n",
      "                                                                 concatenate_242[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_50 (Gl (None, 535)          0           concatenate_242[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_50 (Global (None, 535)          0           concatenate_242[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_243 (Concatenate)   (None, 1605)         0           global_average_pooling1d_49[0][0]\n",
      "                                                                 global_max_pooling1d_49[0][0]    \n",
      "                                                                 attention_weighted_average_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_244 (Concatenate)   (None, 1605)         0           global_average_pooling1d_50[0][0]\n",
      "                                                                 global_max_pooling1d_50[0][0]    \n",
      "                                                                 attention_weighted_average_8[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 1605)         0           concatenate_243[0][0]            \n",
      "                                                                 concatenate_244[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_81 (Multiply)          (None, 1605)         0           concatenate_243[0][0]            \n",
      "                                                                 concatenate_244[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_245 (Concatenate)   (None, 6420)         0           concatenate_243[0][0]            \n",
      "                                                                 concatenate_244[0][0]            \n",
      "                                                                 lambda_151[0][0]                 \n",
      "                                                                 multiply_81[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 6420)         0           concatenate_245[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 6420)         25680       dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 64)           410944      batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 3)            195         dense_65[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 130s 361us/step - loss: 0.2815 - acc: 0.8877 - weighted_accuracy: 0.7123 - val_loss: 0.2971 - val_acc: 0.8661 - val_weighted_accuracy: 0.8445\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2871 - acc: 0.8855 - weighted_accuracy: 0.7073 - val_loss: 0.3019 - val_acc: 0.8648 - val_weighted_accuracy: 0.8463\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2861 - acc: 0.8860 - weighted_accuracy: 0.7064 - val_loss: 0.2975 - val_acc: 0.8691 - val_weighted_accuracy: 0.8522\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2866 - acc: 0.8869 - weighted_accuracy: 0.7066 - val_loss: 0.3018 - val_acc: 0.8663 - val_weighted_accuracy: 0.8355\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2854 - acc: 0.8877 - weighted_accuracy: 0.7069 - val_loss: 0.2954 - val_acc: 0.8709 - val_weighted_accuracy: 0.8520\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2844 - acc: 0.8886 - weighted_accuracy: 0.7078 - val_loss: 0.2977 - val_acc: 0.8677 - val_weighted_accuracy: 0.8478\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2831 - acc: 0.8890 - weighted_accuracy: 0.7082 - val_loss: 0.2980 - val_acc: 0.8705 - val_weighted_accuracy: 0.8522\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2832 - acc: 0.8892 - weighted_accuracy: 0.7082 - val_loss: 0.2929 - val_acc: 0.8741 - val_weighted_accuracy: 0.8562\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2816 - acc: 0.8904 - weighted_accuracy: 0.7084 - val_loss: 0.3001 - val_acc: 0.8693 - val_weighted_accuracy: 0.8507\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2806 - acc: 0.8912 - weighted_accuracy: 0.7097 - val_loss: 0.3004 - val_acc: 0.8675 - val_weighted_accuracy: 0.8443\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2797 - acc: 0.8917 - weighted_accuracy: 0.7105 - val_loss: 0.3017 - val_acc: 0.8679 - val_weighted_accuracy: 0.8466\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 123s 342us/step - loss: 0.2794 - acc: 0.8923 - weighted_accuracy: 0.7106 - val_loss: 0.2969 - val_acc: 0.8718 - val_weighted_accuracy: 0.8540\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2787 - acc: 0.8929 - weighted_accuracy: 0.7112 - val_loss: 0.2987 - val_acc: 0.8714 - val_weighted_accuracy: 0.8510\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2785 - acc: 0.8930 - weighted_accuracy: 0.7113 - val_loss: 0.2991 - val_acc: 0.8707 - val_weighted_accuracy: 0.8503\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2773 - acc: 0.8934 - weighted_accuracy: 0.7124 - val_loss: 0.2976 - val_acc: 0.8721 - val_weighted_accuracy: 0.8509\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2771 - acc: 0.8942 - weighted_accuracy: 0.7125 - val_loss: 0.3053 - val_acc: 0.8656 - val_weighted_accuracy: 0.8445\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2771 - acc: 0.8944 - weighted_accuracy: 0.7126 - val_loss: 0.2977 - val_acc: 0.8726 - val_weighted_accuracy: 0.8494\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2763 - acc: 0.8944 - weighted_accuracy: 0.7131 - val_loss: 0.2966 - val_acc: 0.8724 - val_weighted_accuracy: 0.8528\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_51 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_246 (Concatenate)   (None, 50, 151)      0           embedding_51[0][0]               \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_247 (Concatenate)   (None, 50, 151)      0           embedding_51[1][0]               \n",
      "                                                                 reshape_9[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, 50, 151)      0           concatenate_246[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_52 (SpatialDr (None, 50, 151)      0           concatenate_247[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_51[0][0]       \n",
      "                                                                 spatial_dropout1d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_51[0][0]       \n",
      "                                                                 spatial_dropout1d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)          (None, 50, 64)       0           conv1d_76[0][0]                  \n",
      "                                                                 conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)          (None, 50, 64)       0           conv1d_76[1][0]                  \n",
      "                                                                 conv1d_79[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 50, 64)       4160        multiply_82[0][0]                \n",
      "                                                                 multiply_83[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 50, 64)       0           conv1d_73[0][0]                  \n",
      "                                                                 conv1d_73[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_178 (Dot)                   (None, 50, 50)       0           dropout_120[0][0]                \n",
      "                                                                 dropout_120[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 50, 50)       0           dot_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_60 (Permute)            (None, 50, 50)       0           lambda_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 50, 50)       0           dot_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_180 (Dot)                   (None, 50, 64)       0           permute_60[0][0]                 \n",
      "                                                                 dropout_120[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_179 (Dot)                   (None, 50, 64)       0           lambda_152[0][0]                 \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_248 (Concatenate)   (None, 50, 279)      0           dropout_120[0][0]                \n",
      "                                                                 dot_180[0][0]                    \n",
      "                                                                 spatial_dropout1d_51[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_249 (Concatenate)   (None, 50, 279)      0           dropout_120[1][0]                \n",
      "                                                                 dot_179[0][0]                    \n",
      "                                                                 spatial_dropout1d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 50, 64)       53632       concatenate_248[0][0]            \n",
      "                                                                 concatenate_249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 50, 64)       53632       concatenate_248[0][0]            \n",
      "                                                                 concatenate_249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_84 (Multiply)          (None, 50, 64)       0           conv1d_77[0][0]                  \n",
      "                                                                 conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_85 (Multiply)          (None, 50, 64)       0           conv1d_77[1][0]                  \n",
      "                                                                 conv1d_80[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 50, 64)       4160        multiply_84[0][0]                \n",
      "                                                                 multiply_85[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 50, 64)       0           conv1d_74[0][0]                  \n",
      "                                                                 conv1d_74[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_181 (Dot)                   (None, 50, 50)       0           dropout_121[0][0]                \n",
      "                                                                 dropout_121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 50, 50)       0           dot_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_61 (Permute)            (None, 50, 50)       0           lambda_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 50, 50)       0           dot_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_183 (Dot)                   (None, 50, 64)       0           permute_61[0][0]                 \n",
      "                                                                 dropout_121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_182 (Dot)                   (None, 50, 64)       0           lambda_154[0][0]                 \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_250 (Concatenate)   (None, 50, 407)      0           dropout_121[0][0]                \n",
      "                                                                 dot_183[0][0]                    \n",
      "                                                                 concatenate_248[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_251 (Concatenate)   (None, 50, 407)      0           dropout_121[1][0]                \n",
      "                                                                 dot_182[0][0]                    \n",
      "                                                                 concatenate_249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 50, 64)       78208       concatenate_250[0][0]            \n",
      "                                                                 concatenate_251[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 50, 64)       78208       concatenate_250[0][0]            \n",
      "                                                                 concatenate_251[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_86 (Multiply)          (None, 50, 64)       0           conv1d_78[0][0]                  \n",
      "                                                                 conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_87 (Multiply)          (None, 50, 64)       0           conv1d_78[1][0]                  \n",
      "                                                                 conv1d_81[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 50, 64)       4160        multiply_86[0][0]                \n",
      "                                                                 multiply_87[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 50, 64)       0           conv1d_75[0][0]                  \n",
      "                                                                 conv1d_75[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_184 (Dot)                   (None, 50, 50)       0           dropout_122[0][0]                \n",
      "                                                                 dropout_122[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 50, 50)       0           dot_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_62 (Permute)            (None, 50, 50)       0           lambda_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 50, 50)       0           dot_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_186 (Dot)                   (None, 50, 64)       0           permute_62[0][0]                 \n",
      "                                                                 dropout_122[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_185 (Dot)                   (None, 50, 64)       0           lambda_156[0][0]                 \n",
      "                                                                 dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_252 (Concatenate)   (None, 50, 535)      0           dropout_122[0][0]                \n",
      "                                                                 dot_186[0][0]                    \n",
      "                                                                 concatenate_250[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_253 (Concatenate)   (None, 50, 535)      0           dropout_122[1][0]                \n",
      "                                                                 dot_185[0][0]                    \n",
      "                                                                 concatenate_251[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_51 (Gl (None, 535)          0           concatenate_252[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_51 (Global (None, 535)          0           concatenate_252[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_9 (A (None, 535)          535         concatenate_252[0][0]            \n",
      "                                                                 concatenate_253[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_52 (Gl (None, 535)          0           concatenate_253[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_52 (Global (None, 535)          0           concatenate_253[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_254 (Concatenate)   (None, 1605)         0           global_average_pooling1d_51[0][0]\n",
      "                                                                 global_max_pooling1d_51[0][0]    \n",
      "                                                                 attention_weighted_average_9[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_255 (Concatenate)   (None, 1605)         0           global_average_pooling1d_52[0][0]\n",
      "                                                                 global_max_pooling1d_52[0][0]    \n",
      "                                                                 attention_weighted_average_9[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)             (None, 1605)         0           concatenate_254[0][0]            \n",
      "                                                                 concatenate_255[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_88 (Multiply)          (None, 1605)         0           concatenate_254[0][0]            \n",
      "                                                                 concatenate_255[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_256 (Concatenate)   (None, 6420)         0           concatenate_254[0][0]            \n",
      "                                                                 concatenate_255[0][0]            \n",
      "                                                                 lambda_158[0][0]                 \n",
      "                                                                 multiply_88[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 6420)         0           concatenate_256[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6420)         25680       dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 64)           410944      batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 3)            195         dense_67[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM7.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 131s 363us/step - loss: 0.3009 - acc: 0.8763 - weighted_accuracy: 0.7001 - val_loss: 0.2962 - val_acc: 0.8667 - val_weighted_accuracy: 0.8423\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2991 - acc: 0.8778 - weighted_accuracy: 0.6992 - val_loss: 0.2894 - val_acc: 0.8696 - val_weighted_accuracy: 0.8464\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 121s 336us/step - loss: 0.2966 - acc: 0.8801 - weighted_accuracy: 0.7002 - val_loss: 0.2892 - val_acc: 0.8711 - val_weighted_accuracy: 0.8443\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2943 - acc: 0.8828 - weighted_accuracy: 0.7024 - val_loss: 0.2858 - val_acc: 0.8726 - val_weighted_accuracy: 0.8483\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2929 - acc: 0.8830 - weighted_accuracy: 0.7023 - val_loss: 0.2850 - val_acc: 0.8732 - val_weighted_accuracy: 0.8452\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2915 - acc: 0.8845 - weighted_accuracy: 0.7037 - val_loss: 0.2879 - val_acc: 0.8728 - val_weighted_accuracy: 0.8451\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2899 - acc: 0.8857 - weighted_accuracy: 0.7041 - val_loss: 0.2876 - val_acc: 0.8749 - val_weighted_accuracy: 0.8499\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2886 - acc: 0.8862 - weighted_accuracy: 0.7048 - val_loss: 0.2868 - val_acc: 0.8745 - val_weighted_accuracy: 0.8499\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2874 - acc: 0.8875 - weighted_accuracy: 0.7061 - val_loss: 0.2856 - val_acc: 0.8744 - val_weighted_accuracy: 0.8511\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2860 - acc: 0.8884 - weighted_accuracy: 0.7065 - val_loss: 0.2858 - val_acc: 0.8749 - val_weighted_accuracy: 0.8501\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2855 - acc: 0.8887 - weighted_accuracy: 0.7072 - val_loss: 0.2891 - val_acc: 0.8718 - val_weighted_accuracy: 0.8456\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2839 - acc: 0.8896 - weighted_accuracy: 0.7080 - val_loss: 0.2844 - val_acc: 0.8753 - val_weighted_accuracy: 0.8485\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2845 - acc: 0.8889 - weighted_accuracy: 0.7077 - val_loss: 0.2973 - val_acc: 0.8697 - val_weighted_accuracy: 0.8467\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2828 - acc: 0.8904 - weighted_accuracy: 0.7090 - val_loss: 0.2884 - val_acc: 0.8751 - val_weighted_accuracy: 0.8506\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2822 - acc: 0.8908 - weighted_accuracy: 0.7089 - val_loss: 0.2912 - val_acc: 0.8740 - val_weighted_accuracy: 0.8411\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2828 - acc: 0.8901 - weighted_accuracy: 0.7083 - val_loss: 0.2881 - val_acc: 0.8743 - val_weighted_accuracy: 0.8476\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2801 - acc: 0.8918 - weighted_accuracy: 0.7104 - val_loss: 0.2860 - val_acc: 0.8776 - val_weighted_accuracy: 0.8554\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2801 - acc: 0.8921 - weighted_accuracy: 0.7098 - val_loss: 0.2843 - val_acc: 0.8754 - val_weighted_accuracy: 0.8501\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2792 - acc: 0.8927 - weighted_accuracy: 0.7108 - val_loss: 0.2878 - val_acc: 0.8752 - val_weighted_accuracy: 0.8473\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2785 - acc: 0.8935 - weighted_accuracy: 0.7112 - val_loss: 0.2832 - val_acc: 0.8786 - val_weighted_accuracy: 0.8567\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2779 - acc: 0.8940 - weighted_accuracy: 0.7115 - val_loss: 0.2838 - val_acc: 0.8781 - val_weighted_accuracy: 0.8544\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2775 - acc: 0.8939 - weighted_accuracy: 0.7121 - val_loss: 0.2902 - val_acc: 0.8757 - val_weighted_accuracy: 0.8453\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2775 - acc: 0.8943 - weighted_accuracy: 0.7117 - val_loss: 0.2887 - val_acc: 0.8730 - val_weighted_accuracy: 0.8473\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2763 - acc: 0.8940 - weighted_accuracy: 0.7116 - val_loss: 0.2864 - val_acc: 0.8756 - val_weighted_accuracy: 0.8485\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2759 - acc: 0.8948 - weighted_accuracy: 0.7124 - val_loss: 0.2891 - val_acc: 0.8761 - val_weighted_accuracy: 0.8538\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2746 - acc: 0.8952 - weighted_accuracy: 0.7137 - val_loss: 0.2831 - val_acc: 0.8767 - val_weighted_accuracy: 0.8483\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 124s 343us/step - loss: 0.2742 - acc: 0.8959 - weighted_accuracy: 0.7139 - val_loss: 0.2858 - val_acc: 0.8763 - val_weighted_accuracy: 0.8485\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 126s 349us/step - loss: 0.2747 - acc: 0.8957 - weighted_accuracy: 0.7132 - val_loss: 0.2882 - val_acc: 0.8721 - val_weighted_accuracy: 0.8468\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 130s 362us/step - loss: 0.2741 - acc: 0.8959 - weighted_accuracy: 0.7136 - val_loss: 0.2817 - val_acc: 0.8790 - val_weighted_accuracy: 0.8534\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2741 - acc: 0.8958 - weighted_accuracy: 0.7135 - val_loss: 0.2874 - val_acc: 0.8746 - val_weighted_accuracy: 0.8466\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2734 - acc: 0.8958 - weighted_accuracy: 0.7136 - val_loss: 0.2846 - val_acc: 0.8774 - val_weighted_accuracy: 0.8555\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 126s 351us/step - loss: 0.2725 - acc: 0.8964 - weighted_accuracy: 0.7140 - val_loss: 0.2885 - val_acc: 0.8742 - val_weighted_accuracy: 0.8487\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 125s 347us/step - loss: 0.2722 - acc: 0.8970 - weighted_accuracy: 0.7144 - val_loss: 0.2858 - val_acc: 0.8772 - val_weighted_accuracy: 0.8515\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 125s 346us/step - loss: 0.2715 - acc: 0.8972 - weighted_accuracy: 0.7150 - val_loss: 0.2897 - val_acc: 0.8725 - val_weighted_accuracy: 0.8472\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2715 - acc: 0.8973 - weighted_accuracy: 0.7160 - val_loss: 0.2896 - val_acc: 0.8737 - val_weighted_accuracy: 0.8444\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 124s 344us/step - loss: 0.2708 - acc: 0.8975 - weighted_accuracy: 0.7156 - val_loss: 0.2858 - val_acc: 0.8766 - val_weighted_accuracy: 0.8582\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2702 - acc: 0.8975 - weighted_accuracy: 0.7156 - val_loss: 0.2932 - val_acc: 0.8718 - val_weighted_accuracy: 0.8470\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 125s 345us/step - loss: 0.2704 - acc: 0.8980 - weighted_accuracy: 0.7159 - val_loss: 0.2844 - val_acc: 0.8780 - val_weighted_accuracy: 0.8518\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 124s 345us/step - loss: 0.2694 - acc: 0.8981 - weighted_accuracy: 0.7158 - val_loss: 0.2925 - val_acc: 0.8736 - val_weighted_accuracy: 0.8511\n",
      "score 0.2973616680235025\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 8s 95us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 86us/step\n",
      "80126/80126 [==============================] - 7s 86us/step\n",
      "80126/80126 [==============================] - 7s 86us/step\n",
      "80126/80126 [==============================] - 7s 86us/step\n",
      "80126/80126 [==============================] - 7s 86us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2][:, -1]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2][:, -1]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"P3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_ESIM(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    #input_encoded = BatchNormalization()(input_layer_3)\n",
    "    input_encoded = Dense(2016, activation='elu')(input_layer_3)\n",
    "    input_encoded = Dropout(0.25)(input_encoded)\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    #q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    #q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    batch_norm = BatchNormalization(axis=-1)\n",
    "    q1_embed = batch_norm(q1_embed)\n",
    "    q2_embed = batch_norm(q2_embed)\n",
    "    \n",
    "    aggreation_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    " \n",
    "    q1_seq = aggreation_gru(q1_embed)\n",
    "    q2_seq = aggreation_gru(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "    q1_vec = Concatenate()([q1_seq, q2_aligned, substract(q1_seq, q2_aligned), Multiply()([q1_seq, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_seq, q1_aligned, substract(q2_seq, q1_aligned), Multiply()([q2_seq, q1_aligned])])\n",
    "    \n",
    "    compare_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    "    \n",
    "    q1_rep = compare_gru(q1_vec)\n",
    "    q2_rep = compare_gru(q2_vec)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5, amsgrad=True), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 50, 150)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 50, 150)      0           embedding_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 150)      600         spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 144)      129024      batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 50, 50)       0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 50, 50)       0           lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 50, 144)      0           permute_28[0][0]                 \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 50, 144)      0           lambda_64[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50, 144)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 50, 144)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 50, 144)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 50, 144)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 50, 576)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 lambda_66[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 50, 576)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 144)      374400      concatenate_118[0][0]            \n",
      "                                                                 concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 144)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 144)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 144)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 144)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 288)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 288)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 576)          0           concatenate_120[0][0]            \n",
      "                                                                 concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 576)          2304        concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 256)          147712      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          65792       dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            771         dropout_66[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.2689 - acc: 0.8951 - weighted_accuracy: 0.7119 - val_loss: 0.2916 - val_acc: 0.8718 - val_weighted_accuracy: 0.8549\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.2530 - acc: 0.9044 - weighted_accuracy: 0.7188 - val_loss: 0.2943 - val_acc: 0.8715 - val_weighted_accuracy: 0.8561\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2409 - acc: 0.9103 - weighted_accuracy: 0.7240 - val_loss: 0.2845 - val_acc: 0.8753 - val_weighted_accuracy: 0.8621\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2313 - acc: 0.9156 - weighted_accuracy: 0.7290 - val_loss: 0.2888 - val_acc: 0.8750 - val_weighted_accuracy: 0.8559\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2228 - acc: 0.9197 - weighted_accuracy: 0.7335 - val_loss: 0.2831 - val_acc: 0.8770 - val_weighted_accuracy: 0.8583\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2163 - acc: 0.9234 - weighted_accuracy: 0.7365 - val_loss: 0.2829 - val_acc: 0.8782 - val_weighted_accuracy: 0.8614\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2104 - acc: 0.9250 - weighted_accuracy: 0.7396 - val_loss: 0.2955 - val_acc: 0.8730 - val_weighted_accuracy: 0.8603\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.2051 - acc: 0.9281 - weighted_accuracy: 0.7426 - val_loss: 0.2927 - val_acc: 0.8754 - val_weighted_accuracy: 0.8604\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1994 - acc: 0.9306 - weighted_accuracy: 0.7454 - val_loss: 0.2933 - val_acc: 0.8773 - val_weighted_accuracy: 0.8596\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.1951 - acc: 0.9323 - weighted_accuracy: 0.7474 - val_loss: 0.2951 - val_acc: 0.8786 - val_weighted_accuracy: 0.8611\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 435us/step - loss: 0.1902 - acc: 0.9349 - weighted_accuracy: 0.7501 - val_loss: 0.2934 - val_acc: 0.8749 - val_weighted_accuracy: 0.8602\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1859 - acc: 0.9363 - weighted_accuracy: 0.7518 - val_loss: 0.3081 - val_acc: 0.8749 - val_weighted_accuracy: 0.8600\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1815 - acc: 0.9386 - weighted_accuracy: 0.7543 - val_loss: 0.3263 - val_acc: 0.8715 - val_weighted_accuracy: 0.8573\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1779 - acc: 0.9403 - weighted_accuracy: 0.7565 - val_loss: 0.3187 - val_acc: 0.8741 - val_weighted_accuracy: 0.8596\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1745 - acc: 0.9417 - weighted_accuracy: 0.7575 - val_loss: 0.3205 - val_acc: 0.8741 - val_weighted_accuracy: 0.8607\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1709 - acc: 0.9434 - weighted_accuracy: 0.7594 - val_loss: 0.3166 - val_acc: 0.8744 - val_weighted_accuracy: 0.8606\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 50, 150)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 50, 150)      0           embedding_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50, 150)      600         spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 50, 144)      129024      batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_5[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_85 (Dot)                    (None, 50, 50)       0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 50, 50)       0           lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_87 (Dot)                    (None, 50, 144)      0           permute_29[0][0]                 \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_86 (Dot)                    (None, 50, 144)      0           lambda_68[0][0]                  \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 50, 144)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 50, 144)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 50, 144)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 50, 144)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 50, 576)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_87[0][0]                     \n",
      "                                                                 lambda_70[0][0]                  \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 50, 576)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_86[0][0]                     \n",
      "                                                                 lambda_71[0][0]                  \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 50, 144)      374400      concatenate_123[0][0]            \n",
      "                                                                 concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 144)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 144)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 144)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 144)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 288)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 288)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 576)          0           concatenate_125[0][0]            \n",
      "                                                                 concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 576)          2304        concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          147712      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          65792       dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 3)            771         dropout_69[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 161s 448us/step - loss: 0.2502 - acc: 0.9041 - weighted_accuracy: 0.7220 - val_loss: 0.2681 - val_acc: 0.8840 - val_weighted_accuracy: 0.8708\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2393 - acc: 0.9112 - weighted_accuracy: 0.7265 - val_loss: 0.2655 - val_acc: 0.8849 - val_weighted_accuracy: 0.8675\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2299 - acc: 0.9151 - weighted_accuracy: 0.7305 - val_loss: 0.2665 - val_acc: 0.8851 - val_weighted_accuracy: 0.8691\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2221 - acc: 0.9201 - weighted_accuracy: 0.7345 - val_loss: 0.2666 - val_acc: 0.8849 - val_weighted_accuracy: 0.8685\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2155 - acc: 0.9229 - weighted_accuracy: 0.7380 - val_loss: 0.2649 - val_acc: 0.8867 - val_weighted_accuracy: 0.8722\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2092 - acc: 0.9265 - weighted_accuracy: 0.7414 - val_loss: 0.2687 - val_acc: 0.8861 - val_weighted_accuracy: 0.8702\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2045 - acc: 0.9280 - weighted_accuracy: 0.7429 - val_loss: 0.2707 - val_acc: 0.8863 - val_weighted_accuracy: 0.8711\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1983 - acc: 0.9304 - weighted_accuracy: 0.7461 - val_loss: 0.2712 - val_acc: 0.8853 - val_weighted_accuracy: 0.8712\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1942 - acc: 0.9332 - weighted_accuracy: 0.7490 - val_loss: 0.2761 - val_acc: 0.8824 - val_weighted_accuracy: 0.8695\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.1884 - acc: 0.9361 - weighted_accuracy: 0.7519 - val_loss: 0.2756 - val_acc: 0.8841 - val_weighted_accuracy: 0.8694\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.1849 - acc: 0.9371 - weighted_accuracy: 0.7531 - val_loss: 0.2963 - val_acc: 0.8812 - val_weighted_accuracy: 0.8704\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.1802 - acc: 0.9390 - weighted_accuracy: 0.7552 - val_loss: 0.2974 - val_acc: 0.8832 - val_weighted_accuracy: 0.8679\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.1769 - acc: 0.9405 - weighted_accuracy: 0.7567 - val_loss: 0.2875 - val_acc: 0.8824 - val_weighted_accuracy: 0.8695\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.1735 - acc: 0.9421 - weighted_accuracy: 0.7581 - val_loss: 0.3037 - val_acc: 0.8839 - val_weighted_accuracy: 0.8699\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 156s 433us/step - loss: 0.1698 - acc: 0.9440 - weighted_accuracy: 0.7604 - val_loss: 0.2921 - val_acc: 0.8854 - val_weighted_accuracy: 0.8712\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 50, 150)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 50, 150)      0           embedding_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 150)      600         spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 50, 144)      129024      batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_9[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_88 (Dot)                    (None, 50, 50)       0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 50, 50)       0           lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_90 (Dot)                    (None, 50, 144)      0           permute_30[0][0]                 \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_89 (Dot)                    (None, 50, 144)      0           lambda_72[0][0]                  \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 50, 576)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_90[0][0]                     \n",
      "                                                                 lambda_74[0][0]                  \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 50, 576)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_89[0][0]                     \n",
      "                                                                 lambda_75[0][0]                  \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 50, 144)      374400      concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 288)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 288)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 576)          0           concatenate_130[0][0]            \n",
      "                                                                 concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 576)          2304        concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          147712      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          65792       dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 256)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 3)            771         dropout_72[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 160s 445us/step - loss: 0.2582 - acc: 0.9003 - weighted_accuracy: 0.7176 - val_loss: 0.3012 - val_acc: 0.8680 - val_weighted_accuracy: 0.8523\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2453 - acc: 0.9080 - weighted_accuracy: 0.7223 - val_loss: 0.2925 - val_acc: 0.8730 - val_weighted_accuracy: 0.8593\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.2345 - acc: 0.9138 - weighted_accuracy: 0.7283 - val_loss: 0.2925 - val_acc: 0.8700 - val_weighted_accuracy: 0.8519\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2266 - acc: 0.9177 - weighted_accuracy: 0.7316 - val_loss: 0.2904 - val_acc: 0.8719 - val_weighted_accuracy: 0.8603\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2197 - acc: 0.9210 - weighted_accuracy: 0.7348 - val_loss: 0.2931 - val_acc: 0.8720 - val_weighted_accuracy: 0.8587\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2128 - acc: 0.9245 - weighted_accuracy: 0.7386 - val_loss: 0.2873 - val_acc: 0.8746 - val_weighted_accuracy: 0.8607\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.2073 - acc: 0.9270 - weighted_accuracy: 0.7415 - val_loss: 0.2904 - val_acc: 0.8754 - val_weighted_accuracy: 0.8619\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.2020 - acc: 0.9293 - weighted_accuracy: 0.7439 - val_loss: 0.2966 - val_acc: 0.8699 - val_weighted_accuracy: 0.8551\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.1973 - acc: 0.9317 - weighted_accuracy: 0.7470 - val_loss: 0.2985 - val_acc: 0.8715 - val_weighted_accuracy: 0.8596\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.1933 - acc: 0.9334 - weighted_accuracy: 0.7489 - val_loss: 0.3064 - val_acc: 0.8724 - val_weighted_accuracy: 0.8564\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.1881 - acc: 0.9356 - weighted_accuracy: 0.7509 - val_loss: 0.2965 - val_acc: 0.8724 - val_weighted_accuracy: 0.8575\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.1840 - acc: 0.9371 - weighted_accuracy: 0.7527 - val_loss: 0.3140 - val_acc: 0.8689 - val_weighted_accuracy: 0.8564\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.1798 - acc: 0.9394 - weighted_accuracy: 0.7554 - val_loss: 0.3231 - val_acc: 0.8691 - val_weighted_accuracy: 0.8579\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.1760 - acc: 0.9410 - weighted_accuracy: 0.7571 - val_loss: 0.3184 - val_acc: 0.8696 - val_weighted_accuracy: 0.8570\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 156s 434us/step - loss: 0.1725 - acc: 0.9423 - weighted_accuracy: 0.7584 - val_loss: 0.3167 - val_acc: 0.8691 - val_weighted_accuracy: 0.8575\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 157s 434us/step - loss: 0.1697 - acc: 0.9439 - weighted_accuracy: 0.7605 - val_loss: 0.3226 - val_acc: 0.8687 - val_weighted_accuracy: 0.8587\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 50, 150)      0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 50, 150)      0           embedding_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 50, 150)      600         spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 50, 144)      129024      batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_13[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_91 (Dot)                    (None, 50, 50)       0           bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_31 (Permute)            (None, 50, 50)       0           lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_93 (Dot)                    (None, 50, 144)      0           permute_31[0][0]                 \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_92 (Dot)                    (None, 50, 144)      0           lambda_76[0][0]                  \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 50, 576)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 lambda_78[0][0]                  \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 50, 576)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 lambda_79[0][0]                  \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 50, 144)      374400      concatenate_133[0][0]            \n",
      "                                                                 concatenate_134[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 288)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 288)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 576)          0           concatenate_135[0][0]            \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 576)          2304        concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 256)          147712      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          65792       dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 3)            771         dropout_75[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n",
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 161s 447us/step - loss: 0.2363 - acc: 0.9118 - weighted_accuracy: 0.7306 - val_loss: 0.2873 - val_acc: 0.8736 - val_weighted_accuracy: 0.8568\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2272 - acc: 0.9170 - weighted_accuracy: 0.7336 - val_loss: 0.2882 - val_acc: 0.8737 - val_weighted_accuracy: 0.8631\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2202 - acc: 0.9204 - weighted_accuracy: 0.7362 - val_loss: 0.2914 - val_acc: 0.8728 - val_weighted_accuracy: 0.8633\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2132 - acc: 0.9239 - weighted_accuracy: 0.7403 - val_loss: 0.2902 - val_acc: 0.8762 - val_weighted_accuracy: 0.8614\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2081 - acc: 0.9268 - weighted_accuracy: 0.7425 - val_loss: 0.2810 - val_acc: 0.8765 - val_weighted_accuracy: 0.8637\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2023 - acc: 0.9295 - weighted_accuracy: 0.7451 - val_loss: 0.2906 - val_acc: 0.8753 - val_weighted_accuracy: 0.8599\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1969 - acc: 0.9316 - weighted_accuracy: 0.7472 - val_loss: 0.2849 - val_acc: 0.8773 - val_weighted_accuracy: 0.8638\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1924 - acc: 0.9338 - weighted_accuracy: 0.7496 - val_loss: 0.2977 - val_acc: 0.8745 - val_weighted_accuracy: 0.8631\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1877 - acc: 0.9356 - weighted_accuracy: 0.7516 - val_loss: 0.3014 - val_acc: 0.8758 - val_weighted_accuracy: 0.8614\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1829 - acc: 0.9373 - weighted_accuracy: 0.7536 - val_loss: 0.3013 - val_acc: 0.8747 - val_weighted_accuracy: 0.8603\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1792 - acc: 0.9399 - weighted_accuracy: 0.7565 - val_loss: 0.3164 - val_acc: 0.8734 - val_weighted_accuracy: 0.8571\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1750 - acc: 0.9411 - weighted_accuracy: 0.7577 - val_loss: 0.3219 - val_acc: 0.8708 - val_weighted_accuracy: 0.8556\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1713 - acc: 0.9427 - weighted_accuracy: 0.7596 - val_loss: 0.3085 - val_acc: 0.8748 - val_weighted_accuracy: 0.8576\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1681 - acc: 0.9440 - weighted_accuracy: 0.7608 - val_loss: 0.3036 - val_acc: 0.8741 - val_weighted_accuracy: 0.8612\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1654 - acc: 0.9452 - weighted_accuracy: 0.7625 - val_loss: 0.3302 - val_acc: 0.8727 - val_weighted_accuracy: 0.8601\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 50, 150)      0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 50, 150)      0           embedding_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50, 150)      600         spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 50, 144)      129024      batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_17[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_94 (Dot)                    (None, 50, 50)       0           bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_32 (Permute)            (None, 50, 50)       0           lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_96 (Dot)                    (None, 50, 144)      0           permute_32[0][0]                 \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_95 (Dot)                    (None, 50, 144)      0           lambda_80[0][0]                  \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 50, 576)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_96[0][0]                     \n",
      "                                                                 lambda_82[0][0]                  \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 50, 576)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_95[0][0]                     \n",
      "                                                                 lambda_83[0][0]                  \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 50, 144)      374400      concatenate_138[0][0]            \n",
      "                                                                 concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 288)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 288)          0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 576)          0           concatenate_140[0][0]            \n",
      "                                                                 concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 576)          2304        concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 256)          147712      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 256)          65792       dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 3)            771         dropout_78[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 162s 449us/step - loss: 0.2481 - acc: 0.9062 - weighted_accuracy: 0.7239 - val_loss: 0.3086 - val_acc: 0.8607 - val_weighted_accuracy: 0.8447\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2372 - acc: 0.9123 - weighted_accuracy: 0.7275 - val_loss: 0.3044 - val_acc: 0.8636 - val_weighted_accuracy: 0.8523\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2278 - acc: 0.9174 - weighted_accuracy: 0.7316 - val_loss: 0.3034 - val_acc: 0.8678 - val_weighted_accuracy: 0.8529\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2205 - acc: 0.9212 - weighted_accuracy: 0.7355 - val_loss: 0.2972 - val_acc: 0.8684 - val_weighted_accuracy: 0.8508\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2136 - acc: 0.9246 - weighted_accuracy: 0.7394 - val_loss: 0.2938 - val_acc: 0.8729 - val_weighted_accuracy: 0.8558\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2071 - acc: 0.9273 - weighted_accuracy: 0.7420 - val_loss: 0.3061 - val_acc: 0.8673 - val_weighted_accuracy: 0.8500\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2016 - acc: 0.9300 - weighted_accuracy: 0.7447 - val_loss: 0.3005 - val_acc: 0.8682 - val_weighted_accuracy: 0.8494\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1974 - acc: 0.9317 - weighted_accuracy: 0.7468 - val_loss: 0.3134 - val_acc: 0.8688 - val_weighted_accuracy: 0.8530\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.1920 - acc: 0.9343 - weighted_accuracy: 0.7498 - val_loss: 0.3129 - val_acc: 0.8694 - val_weighted_accuracy: 0.8546\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1882 - acc: 0.9363 - weighted_accuracy: 0.7515 - val_loss: 0.3099 - val_acc: 0.8672 - val_weighted_accuracy: 0.8522\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1832 - acc: 0.9380 - weighted_accuracy: 0.7537 - val_loss: 0.3206 - val_acc: 0.8641 - val_weighted_accuracy: 0.8515\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1796 - acc: 0.9394 - weighted_accuracy: 0.7555 - val_loss: 0.3279 - val_acc: 0.8647 - val_weighted_accuracy: 0.8532\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1761 - acc: 0.9414 - weighted_accuracy: 0.7579 - val_loss: 0.3314 - val_acc: 0.8648 - val_weighted_accuracy: 0.8540\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1717 - acc: 0.9432 - weighted_accuracy: 0.7596 - val_loss: 0.3323 - val_acc: 0.8646 - val_weighted_accuracy: 0.8508\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1688 - acc: 0.9443 - weighted_accuracy: 0.7613 - val_loss: 0.3228 - val_acc: 0.8676 - val_weighted_accuracy: 0.8496\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 50, 150)      0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 50, 150)      0           embedding_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 150)      600         spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 50, 144)      129024      batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_21[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_97 (Dot)                    (None, 50, 50)       0           bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_33 (Permute)            (None, 50, 50)       0           lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_99 (Dot)                    (None, 50, 144)      0           permute_33[0][0]                 \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_98 (Dot)                    (None, 50, 144)      0           lambda_84[0][0]                  \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 50, 576)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_99[0][0]                     \n",
      "                                                                 lambda_86[0][0]                  \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 50, 576)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_98[0][0]                     \n",
      "                                                                 lambda_87[0][0]                  \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 50, 144)      374400      concatenate_143[0][0]            \n",
      "                                                                 concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 288)          0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 288)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 576)          0           concatenate_145[0][0]            \n",
      "                                                                 concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 576)          2304        concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 256)          147712      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          65792       dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 256)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 3)            771         dropout_81[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 162s 450us/step - loss: 0.2475 - acc: 0.9062 - weighted_accuracy: 0.7239 - val_loss: 0.3188 - val_acc: 0.8569 - val_weighted_accuracy: 0.8254\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.2366 - acc: 0.9119 - weighted_accuracy: 0.7273 - val_loss: 0.3164 - val_acc: 0.8586 - val_weighted_accuracy: 0.8393\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.2282 - acc: 0.9171 - weighted_accuracy: 0.7318 - val_loss: 0.3139 - val_acc: 0.8596 - val_weighted_accuracy: 0.8366\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.2194 - acc: 0.9209 - weighted_accuracy: 0.7361 - val_loss: 0.3164 - val_acc: 0.8577 - val_weighted_accuracy: 0.8418\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2127 - acc: 0.9244 - weighted_accuracy: 0.7389 - val_loss: 0.3227 - val_acc: 0.8606 - val_weighted_accuracy: 0.8396\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.2072 - acc: 0.9267 - weighted_accuracy: 0.7416 - val_loss: 0.3113 - val_acc: 0.8629 - val_weighted_accuracy: 0.8385\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 157s 437us/step - loss: 0.2004 - acc: 0.9297 - weighted_accuracy: 0.7449 - val_loss: 0.3124 - val_acc: 0.8659 - val_weighted_accuracy: 0.8465\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1955 - acc: 0.9319 - weighted_accuracy: 0.7471 - val_loss: 0.3229 - val_acc: 0.8622 - val_weighted_accuracy: 0.8386\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1910 - acc: 0.9339 - weighted_accuracy: 0.7492 - val_loss: 0.3181 - val_acc: 0.8610 - val_weighted_accuracy: 0.8389\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1855 - acc: 0.9360 - weighted_accuracy: 0.7519 - val_loss: 0.3335 - val_acc: 0.8609 - val_weighted_accuracy: 0.8377\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 157s 436us/step - loss: 0.1818 - acc: 0.9380 - weighted_accuracy: 0.7539 - val_loss: 0.3301 - val_acc: 0.8603 - val_weighted_accuracy: 0.8356\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1777 - acc: 0.9398 - weighted_accuracy: 0.7558 - val_loss: 0.3359 - val_acc: 0.8580 - val_weighted_accuracy: 0.8351\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1738 - acc: 0.9415 - weighted_accuracy: 0.7578 - val_loss: 0.3464 - val_acc: 0.8621 - val_weighted_accuracy: 0.8374\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1694 - acc: 0.9437 - weighted_accuracy: 0.7598 - val_loss: 0.3577 - val_acc: 0.8570 - val_weighted_accuracy: 0.8415\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1665 - acc: 0.9454 - weighted_accuracy: 0.7616 - val_loss: 0.3615 - val_acc: 0.8579 - val_weighted_accuracy: 0.8370\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.1627 - acc: 0.9466 - weighted_accuracy: 0.7633 - val_loss: 0.3630 - val_acc: 0.8574 - val_weighted_accuracy: 0.8392\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 50, 150)      0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 50, 150)      0           embedding_31[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 50, 150)      600         spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 50, 144)      129024      batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_25[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_100 (Dot)                   (None, 50, 50)       0           bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_34 (Permute)            (None, 50, 50)       0           lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_102 (Dot)                   (None, 50, 144)      0           permute_34[0][0]                 \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 50, 144)      0           lambda_88[0][0]                  \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 50, 576)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 lambda_90[0][0]                  \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 50, 576)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 lambda_91[0][0]                  \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 50, 144)      374400      concatenate_148[0][0]            \n",
      "                                                                 concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 288)          0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 288)          0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 576)          0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 576)          2304        concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 256)          147712      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          65792       dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 3)            771         dropout_84[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 163s 452us/step - loss: 0.2574 - acc: 0.9009 - weighted_accuracy: 0.7177 - val_loss: 0.2886 - val_acc: 0.8706 - val_weighted_accuracy: 0.8579\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.2445 - acc: 0.9086 - weighted_accuracy: 0.7226 - val_loss: 0.2814 - val_acc: 0.8751 - val_weighted_accuracy: 0.8621\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 158s 437us/step - loss: 0.2349 - acc: 0.9134 - weighted_accuracy: 0.7277 - val_loss: 0.2846 - val_acc: 0.8745 - val_weighted_accuracy: 0.8618\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.2262 - acc: 0.9174 - weighted_accuracy: 0.7313 - val_loss: 0.2764 - val_acc: 0.8791 - val_weighted_accuracy: 0.8607\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.2188 - acc: 0.9216 - weighted_accuracy: 0.7354 - val_loss: 0.2803 - val_acc: 0.8794 - val_weighted_accuracy: 0.8687\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 158s 438us/step - loss: 0.2121 - acc: 0.9247 - weighted_accuracy: 0.7391 - val_loss: 0.2832 - val_acc: 0.8780 - val_weighted_accuracy: 0.8663\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 160s 444us/step - loss: 0.2059 - acc: 0.9278 - weighted_accuracy: 0.7422 - val_loss: 0.2884 - val_acc: 0.8784 - val_weighted_accuracy: 0.8647\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.2014 - acc: 0.9297 - weighted_accuracy: 0.7446 - val_loss: 0.2860 - val_acc: 0.8798 - val_weighted_accuracy: 0.8598\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1961 - acc: 0.9321 - weighted_accuracy: 0.7473 - val_loss: 0.2830 - val_acc: 0.8785 - val_weighted_accuracy: 0.8639\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1913 - acc: 0.9342 - weighted_accuracy: 0.7492 - val_loss: 0.2840 - val_acc: 0.8776 - val_weighted_accuracy: 0.8647\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1874 - acc: 0.9357 - weighted_accuracy: 0.7508 - val_loss: 0.2964 - val_acc: 0.8775 - val_weighted_accuracy: 0.8651\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1833 - acc: 0.9380 - weighted_accuracy: 0.7530 - val_loss: 0.2896 - val_acc: 0.8755 - val_weighted_accuracy: 0.8588\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 158s 440us/step - loss: 0.1796 - acc: 0.9396 - weighted_accuracy: 0.7553 - val_loss: 0.2962 - val_acc: 0.8751 - val_weighted_accuracy: 0.8631\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.1761 - acc: 0.9413 - weighted_accuracy: 0.7571 - val_loss: 0.3018 - val_acc: 0.8757 - val_weighted_accuracy: 0.8653\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, 50, 150)      0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, 50, 150)      0           embedding_33[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 50, 150)      600         spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 50, 144)      129024      batch_normalization_29[0][0]     \n",
      "                                                                 batch_normalization_29[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_103 (Dot)                   (None, 50, 50)       0           bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_35 (Permute)            (None, 50, 50)       0           lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_105 (Dot)                   (None, 50, 144)      0           permute_35[0][0]                 \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_104 (Dot)                   (None, 50, 144)      0           lambda_92[0][0]                  \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 50, 576)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_105[0][0]                    \n",
      "                                                                 lambda_94[0][0]                  \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 50, 576)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_104[0][0]                    \n",
      "                                                                 lambda_95[0][0]                  \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 50, 144)      374400      concatenate_153[0][0]            \n",
      "                                                                 concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 288)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_max_pooling1d_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 288)          0           global_average_pooling1d_34[0][0]\n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 576)          0           concatenate_155[0][0]            \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 576)          2304        concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          147712      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256)          1024        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 256)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 256)          65792       dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256)          1024        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 256)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 3)            771         dropout_87[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from  3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 164s 454us/step - loss: 0.2425 - acc: 0.9088 - weighted_accuracy: 0.7281 - val_loss: 0.2674 - val_acc: 0.8836 - val_weighted_accuracy: 0.8624\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2329 - acc: 0.9142 - weighted_accuracy: 0.7314 - val_loss: 0.2690 - val_acc: 0.8801 - val_weighted_accuracy: 0.8566\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2234 - acc: 0.9188 - weighted_accuracy: 0.7357 - val_loss: 0.2748 - val_acc: 0.8767 - val_weighted_accuracy: 0.8613\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2164 - acc: 0.9223 - weighted_accuracy: 0.7386 - val_loss: 0.2751 - val_acc: 0.8816 - val_weighted_accuracy: 0.8629\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2099 - acc: 0.9258 - weighted_accuracy: 0.7421 - val_loss: 0.2855 - val_acc: 0.8768 - val_weighted_accuracy: 0.8622\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.2041 - acc: 0.9286 - weighted_accuracy: 0.7451 - val_loss: 0.2824 - val_acc: 0.8812 - val_weighted_accuracy: 0.8617\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.1987 - acc: 0.9309 - weighted_accuracy: 0.7473 - val_loss: 0.2790 - val_acc: 0.8841 - val_weighted_accuracy: 0.8640\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 159s 440us/step - loss: 0.1936 - acc: 0.9331 - weighted_accuracy: 0.7500 - val_loss: 0.2925 - val_acc: 0.8802 - val_weighted_accuracy: 0.8653\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.1882 - acc: 0.9357 - weighted_accuracy: 0.7524 - val_loss: 0.2908 - val_acc: 0.8809 - val_weighted_accuracy: 0.8638\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.1854 - acc: 0.9369 - weighted_accuracy: 0.7540 - val_loss: 0.2856 - val_acc: 0.8805 - val_weighted_accuracy: 0.8634\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 158s 439us/step - loss: 0.1807 - acc: 0.9394 - weighted_accuracy: 0.7565 - val_loss: 0.2915 - val_acc: 0.8824 - val_weighted_accuracy: 0.8615\n",
      "score 0.2831312316634446\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "80126/80126 [==============================] - 12s 153us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_ESIM(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "\n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=(trains[0], trains[1], trains[2]), y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        tests=(tests[0], tests[1], tests[2]), em_test_features=em_test_features, pseudo_labels=pseudo_labels,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"P3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
