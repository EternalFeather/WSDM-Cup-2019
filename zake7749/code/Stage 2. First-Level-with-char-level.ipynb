{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import pandas as pd\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from iwillwin.trainer.supervised_trainer import KerasModelTrainer\n",
    "from iwillwin.data_utils.data_helpers import DataTransformer, DataLoader, CharDataTransformer\n",
    "from iwillwin.model.sim_zoos import *\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, MaxPooling1D, CuDNNLSTM, Embedding, Add, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from iwillwin.config import dataset_config, model_config\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.legacy.layers import Highway\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 5000\n",
    "EMBEDDING_DIM = 150\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "OUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataHelper] Apply normalization on value-type columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing preprocessing...\n",
      "Transforming words to indices...\n",
      "Shape of data tensor: (320552, 50) (320552, 50)\n",
      "Shape of label tensor: (320552,)\n",
      "Preprocessed.\n",
      "Number of unique words 5237\n"
     ]
    }
   ],
   "source": [
    "data_transformer = CharDataTransformer(max_num_words=NB_WORDS, max_sequence_length=MAX_SEQUENCE_LENGTH, char_level=False,\n",
    "                                   normalization=True, features_processed=True)\n",
    "trains, tests, labels = data_transformer.prepare_data(dual=False)\n",
    "print(\"Number of unique words\", len(data_transformer.tokenizer.index_docs))\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "['.gitkeep', 'fasttext-50-win3.vec', 'zh-wordvec-50-cbow-windowsize50.vec', 'zh-wordvec-50-skipgram-windowsize7.vec']\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings\")\n",
    "print(os.listdir(\"../data/wordvec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n",
      "Total 4114 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "skip_gram_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-skipgram-windowsize7.vec')\n",
    "cbow_embeddings = data_loader.load_embedding('../data/wordvec/zh-wordvec-50-cbow-windowsize50.vec')\n",
    "fasttext_embeddings = data_loader.load_embedding('../data/wordvec/fasttext-50-win3.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(embeddings_index, nb_words=NB_WORDS, word_index=data_transformer.tokenizer.word_index):\n",
    "    #nb_words = min(nb_words, len(embeddings_index))\n",
    "    #embedding_matrix = np.random.rand(nb_words, 50)\n",
    "    embedding_matrix = np.zeros((nb_words, 50))\n",
    "    \n",
    "    word_index = data_transformer.tokenizer.word_index\n",
    "    null_words = open('null-word.txt', 'w', encoding='utf-8')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words:\n",
    "            null_words.write(word + '\\n')\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            null_words.write(word + '\\n')\n",
    "    print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n",
      "Null word embeddings: 948\n"
     ]
    }
   ],
   "source": [
    "cbow_matrix = build_embedding_matrix(cbow_embeddings)\n",
    "skipgram_matrix = build_embedding_matrix(skip_gram_embeddings)\n",
    "fasttext_matrix = build_embedding_matrix(fasttext_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings = np.concatenate((cbow_matrix, skipgram_matrix, fasttext_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_embeddings[0] = np.array([0] * 150) # zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tricky features\n",
    "\n",
    "## Rumor words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/dataset/train.csv')\n",
    "test_df = pd.read_csv('../data/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "rumor_words = ['辟谣', '谣言', '勿传', '假的']\n",
    "\n",
    "def is_rumor(text):\n",
    "    if type(text) != str:\n",
    "        print(text, type(text))\n",
    "        return 0\n",
    "    for rumor_word in rumor_words:\n",
    "        if rumor_word in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def has_split_symbol(text):\n",
    "    if type(text) != str:\n",
    "        return 0\n",
    "    if '|' in text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['has_|'] = df['title2_zh'].apply(has_split_symbol)\n",
    "    df['has_rumor_words'] = df['title2_zh'].apply(is_rumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_has_rumor = train_df.has_rumor_words.values\n",
    "test_has_rumor = test_df.has_rumor_words.values\n",
    "\n",
    "trick_trains_features = np.concatenate((trains[2], train_has_rumor.reshape((-1, 1))), axis=1)\n",
    "trick_tests_features = np.concatenate((tests[2], test_has_rumor.reshape((-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _build_exact_match_sequences(sent_1, sent_2):\n",
    "    sent_1_char_set = set(sent_1)\n",
    "    sent_2_char_set = set(sent_2)\n",
    "    intersection = sent_1_char_set & sent_2_char_set\n",
    "    \n",
    "    sent_1_em = np.zeros_like(sent_1)\n",
    "    sent_2_em = np.zeros_like(sent_2)\n",
    "\n",
    "    for i in range(len(sent_1)):\n",
    "        if sent_1[i] == 0:\n",
    "            continue\n",
    "        if sent_1[i] in intersection:\n",
    "            sent_1_em[i] = 1\n",
    "    \n",
    "    for i in range(len(sent_2)):\n",
    "        if sent_2[i] == 0:\n",
    "            continue        \n",
    "        if sent_2[i] in intersection:\n",
    "            sent_2_em[i] = 1\n",
    "    \n",
    "    return sent_1_em, sent_2_em\n",
    "\n",
    "def build_exact_match_sequences(sents_1, sents_2):\n",
    "    sents_1_em, sents_2_em = [], []\n",
    "    for sent_1, sent_2 in zip(sents_1, sents_2):\n",
    "        sent_1_em, sent_2_em = _build_exact_match_sequences(sent_1, sent_2)\n",
    "        sents_1_em.append(sent_1_em)\n",
    "        sents_2_em.append(sent_2_em)\n",
    "    return np.array(sents_1_em), np.array(sents_2_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_1_ems, trains_2_ems = build_exact_match_sequences(trains[0], trains[1])\n",
    "tests_1_ems, tests_2_ems = build_exact_match_sequences(tests[0], tests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train em (320552, 50) (320552, 50)\n",
      "Shape of test em (80126, 50) (80126, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train em\", trains_1_ems.shape, trains_2_ems.shape)\n",
    "print(\"Shape of test em\", tests_1_ems.shape, tests_2_ems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_train_features = (trains_1_ems, trains_2_ems)\n",
    "em_test_features = (tests_1_ems, tests_2_ems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class_weight.compute_class_weight('balanced', [0, 1, 2], labels.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trick or Treat!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tricky = True\n",
    "\n",
    "if use_tricky:\n",
    "    trains = (trains[0], trains[1], trick_trains_features)\n",
    "    tests = (tests[0], tests[1], trick_tests_features)\n",
    "else:\n",
    "    trains = (trains[0], trains[1], trains[2])\n",
    "    tests = (tests[0], tests[1], tests[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "        self.class_weight = [0.93, 1.21]\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, batch_size, get_model_func, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        #features = features[:, -1]\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "\n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=None)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        bst_model_path = self.model_stamp + str(fold_id) + '.h5'\n",
    "        val_data = (val_x, val_y, weight_val) if weight_val is not None else (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         callbacks=[early_stopping, model_checkpoint],\n",
    "                         class_weight=class_weight)\n",
    "        bst_val_score = max(hist.history['val_weighted_accuracy']) # note this is the hard version\n",
    "        model.load_weights(bst_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = tf.nn.leaky_relu(K.conv1d(u_vecs, self.W))\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = K.tanh(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "    \n",
    "def get_padding_mask(q, k):\n",
    "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "    return mask\n",
    "\n",
    "def unchanged_shape(input_shape):\n",
    "    \"Function for Lambda layer\"\n",
    "    return input_shape\n",
    "\n",
    "def substract(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: x[0] - x[1])([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def eldistance(input_1, input_2):\n",
    "    \"Substract element-wise\"\n",
    "    out_ = Lambda(lambda x: K.sqrt(K.square(x[0] - x[1])))([input_1, input_2])\n",
    "    return out_\n",
    "\n",
    "def submult(input_1, input_2):\n",
    "    \"Get multiplication and subtraction then concatenate results\"\n",
    "    mult = Multiply()([input_1, input_2])\n",
    "    add = Add()([input_1, input_2])\n",
    "    sub = substract(input_1, input_2)\n",
    "    distance = eldistance(input_1, input_2)\n",
    "    \n",
    "    dual = Concatenate()([input_1, input_2])\n",
    "    dual = Dense(32, activation='relu')(dual)\n",
    "    dual = Dropout(0.5)(dual)\n",
    "    dual = Dense(8, activation='relu')(dual)\n",
    "    \n",
    "    out_= Concatenate()([sub, mult, ])\n",
    "    return out_\n",
    "\n",
    "def apply_multiple(input_, layers):\n",
    "    \"Apply layers to input then concatenate result\"\n",
    "    if not len(layers) > 1:\n",
    "        raise ValueError('Layers list should contain more than 1 layer')\n",
    "    else:\n",
    "        agg_ = []\n",
    "        for layer in layers:\n",
    "            agg_.append(layer(input_))\n",
    "        out_ = Concatenate()(agg_)\n",
    "    return out_\n",
    "\n",
    "def time_distributed(input_, layers):\n",
    "    \"Apply a list of layers in TimeDistributed mode\"\n",
    "    out_ = []\n",
    "    node_ = input_\n",
    "    for layer_ in layers:\n",
    "        node_ = TimeDistributed(layer_)(node_)\n",
    "    out_ = node_\n",
    "    return out_\n",
    "\n",
    "def soft_attention_alignment(input_1, input_2):\n",
    "    \"Align text representation with neural soft attention\"\n",
    "    attention = Dot(axes=-1)([input_1, input_2])\n",
    "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
    "                     output_shape=unchanged_shape)(attention)\n",
    "    w_att_2 = Permute((2, 1))(Lambda(lambda x: softmax(x, axis=2),\n",
    "                             output_shape=unchanged_shape)(attention))\n",
    "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
    "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
    "    return in1_aligned, in2_aligned    \n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q1_c = Input(shape=(max_sequence_length, 11), name='first_sentences_char')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q2_c = Input(shape=(max_sequence_length, 11), name='second_sentences_char')\n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words,\n",
    "                            embedding_dim,\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=True)\n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.5)(q1_embed)\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.5)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    \n",
    "    q1_encoded = th(q1_embed,)    \n",
    "    q2_encoded = th(q2_embed,)\n",
    "    \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
    "    q1_encoded = Concatenate()([q2_aligned, q1_encoded])\n",
    "    q2_encoded = Concatenate()([q1_aligned, q2_encoded])  \n",
    "    \n",
    "    cnn_init = Conv1D(32, 1, strides=1, padding='same', activation='relu')\n",
    "    q1_seq = cnn_init(q1_encoded)\n",
    "    q2_seq = cnn_init(q2_encoded)\n",
    "    \n",
    "    cnns = [Conv1D(1, 3, strides=1, padding='same', activation='relu') for i in range(10)]\n",
    "    \n",
    "    for idx, cnn in enumerate(cnns):\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        q1_encoded = Concatenate()([q1_seq, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_seq, q1_aligned, q2_encoded])            \n",
    "        q1_seq = cnn(q1_encoded)\n",
    "        q2_seq = cnn(q2_encoded)    \n",
    "    \n",
    "    \n",
    "    capsule_pooling = Capsule(num_capsule=8, dim_capsule=100, routings=3, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    \n",
    "    #q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])\n",
    "    #q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(),])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi, ])\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_darnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    #q1_embed = Dropout(0.2)(th(q1_embed,))\n",
    "    #q2_embed = Dropout(0.2)(th(q2_embed,))    \n",
    "    \n",
    "    rnns = [CuDNNGRU(42, return_sequences=True) for i in range(3)]\n",
    "    \n",
    "    q1_res = []\n",
    "    q2_res = []\n",
    "    \n",
    "    \n",
    "    for idx, rnn in enumerate(rnns):\n",
    "        q1_seq = rnn(q1_embed)\n",
    "        q1_seq = Dropout(0.1)(q1_seq)\n",
    "        q2_seq = rnn(q2_embed)\n",
    "        q2_seq = Dropout(0.1)(q2_seq)\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        \n",
    "        q1_res.append(q2_aligned)\n",
    "        q1_res.append(q1_seq)\n",
    "        \n",
    "        q2_res.append(q1_aligned)\n",
    "        q2_res.append(q2_seq)\n",
    "        \n",
    "        q1_embed = Concatenate()([q1_seq, q2_aligned, q1_embed])\n",
    "        q2_embed = Concatenate()([q2_seq, q1_aligned, q2_embed])            \n",
    "        \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    q1_res = Concatenate()(q1_res)\n",
    "    q2_res = Concatenate()(q2_res)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_res, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.1)(h_all)\n",
    "    h_all = Dense(256, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    \n",
    "    y_pred = K.cast(y_pred > 0.5, 'int32') # hard version\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    \n",
    "    res = K.cast(K.equal(y_pred, y_true), 'float32') * weight_mask / K.sum(weight_mask)\n",
    "    res = K.sum(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_manager = ModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:659: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 50, 151)      0           embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 50, 151)      0           embedding_9[1][0]                \n",
      "                                                                 embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 50, 151)      0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 50, 151)      0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 42)       0           cu_dnngru_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 50, 50)       0           dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 50, 50)       0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 50, 42)       0           permute_18[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 50, 42)       0           lambda_40[0][0]                  \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 50, 235)      0           dropout_24[0][0]                 \n",
      "                                                                 dot_54[0][0]                     \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 50, 235)      0           dropout_25[0][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_11 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 50, 42)       0           cu_dnngru_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 50, 50)       0           dropout_26[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 50, 50)       0           lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 50, 42)       0           permute_19[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 50, 42)       0           lambda_42[0][0]                  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 50, 319)      0           dropout_26[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 50, 319)      0           dropout_27[0][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_12 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_66[0][0]             \n",
      "                                                                 concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 50, 42)       0           cu_dnngru_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 50, 50)       0           dropout_28[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 50, 50)       0           lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 50, 42)       0           permute_20[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 50, 42)       0           lambda_44[0][0]                  \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 50, 252)      0           dot_54[0][0]                     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 50, 252)      0           dot_53[0][0]                     \n",
      "                                                                 dropout_25[0][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 252)          0           concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 252)          0           concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 252)          0           concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 252)          0           concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 504)          0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 504)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 504)          0           concatenate_72[0][0]             \n",
      "                                                                 concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 504)          0           concatenate_72[0][0]             \n",
      "                                                                 concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 2016)         0           concatenate_72[0][0]             \n",
      "                                                                 concatenate_73[0][0]             \n",
      "                                                                 lambda_46[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 2016)         0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          516352      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            771         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 112s 401us/step - loss: 0.3552 - acc: 0.8346 - weighted_accuracy: 0.8042 - val_loss: 0.3393 - val_acc: 0.8371 - val_weighted_accuracy: 0.8209\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 109s 390us/step - loss: 0.3097 - acc: 0.8586 - weighted_accuracy: 0.8335 - val_loss: 0.3648 - val_acc: 0.8267 - val_weighted_accuracy: 0.8124\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 113s 401us/step - loss: 0.2950 - acc: 0.8669 - weighted_accuracy: 0.8434 - val_loss: 0.3413 - val_acc: 0.8340 - val_weighted_accuracy: 0.8221\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2862 - acc: 0.8719 - weighted_accuracy: 0.8488 - val_loss: 0.3227 - val_acc: 0.8504 - val_weighted_accuracy: 0.8402\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 110s 391us/step - loss: 0.2800 - acc: 0.8751 - weighted_accuracy: 0.8523 - val_loss: 0.3140 - val_acc: 0.8567 - val_weighted_accuracy: 0.8388\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 110s 392us/step - loss: 0.2735 - acc: 0.8787 - weighted_accuracy: 0.8572 - val_loss: 0.3227 - val_acc: 0.8497 - val_weighted_accuracy: 0.8331\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 109s 390us/step - loss: 0.2698 - acc: 0.8804 - weighted_accuracy: 0.8587 - val_loss: 0.3008 - val_acc: 0.8621 - val_weighted_accuracy: 0.8449\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2662 - acc: 0.8826 - weighted_accuracy: 0.8615 - val_loss: 0.2942 - val_acc: 0.8669 - val_weighted_accuracy: 0.8432\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 110s 391us/step - loss: 0.2634 - acc: 0.8835 - weighted_accuracy: 0.8623 - val_loss: 0.2961 - val_acc: 0.8674 - val_weighted_accuracy: 0.8476\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 110s 391us/step - loss: 0.2607 - acc: 0.8853 - weighted_accuracy: 0.8645 - val_loss: 0.2984 - val_acc: 0.8663 - val_weighted_accuracy: 0.8391\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2589 - acc: 0.8860 - weighted_accuracy: 0.8653 - val_loss: 0.3179 - val_acc: 0.8567 - val_weighted_accuracy: 0.8436\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 110s 392us/step - loss: 0.2577 - acc: 0.8869 - weighted_accuracy: 0.8661 - val_loss: 0.2996 - val_acc: 0.8645 - val_weighted_accuracy: 0.8472\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2548 - acc: 0.8886 - weighted_accuracy: 0.8684 - val_loss: 0.3093 - val_acc: 0.8596 - val_weighted_accuracy: 0.8414\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2534 - acc: 0.8891 - weighted_accuracy: 0.8685 - val_loss: 0.3213 - val_acc: 0.8569 - val_weighted_accuracy: 0.8413\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2531 - acc: 0.8897 - weighted_accuracy: 0.8696 - val_loss: 0.3230 - val_acc: 0.8569 - val_weighted_accuracy: 0.8443\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 110s 392us/step - loss: 0.2523 - acc: 0.8899 - weighted_accuracy: 0.8699 - val_loss: 0.3117 - val_acc: 0.8643 - val_weighted_accuracy: 0.8492\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 116s 413us/step - loss: 0.2511 - acc: 0.8901 - weighted_accuracy: 0.8700 - val_loss: 0.3190 - val_acc: 0.8584 - val_weighted_accuracy: 0.8438\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2501 - acc: 0.8913 - weighted_accuracy: 0.8713 - val_loss: 0.2974 - val_acc: 0.8665 - val_weighted_accuracy: 0.8439\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2479 - acc: 0.8918 - weighted_accuracy: 0.8720 - val_loss: 0.3020 - val_acc: 0.8646 - val_weighted_accuracy: 0.8464\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2472 - acc: 0.8920 - weighted_accuracy: 0.8724 - val_loss: 0.3086 - val_acc: 0.8620 - val_weighted_accuracy: 0.8417\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2479 - acc: 0.8924 - weighted_accuracy: 0.8727 - val_loss: 0.3009 - val_acc: 0.8637 - val_weighted_accuracy: 0.8509\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2456 - acc: 0.8927 - weighted_accuracy: 0.8733 - val_loss: 0.3176 - val_acc: 0.8626 - val_weighted_accuracy: 0.8457\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2457 - acc: 0.8927 - weighted_accuracy: 0.8727 - val_loss: 0.3036 - val_acc: 0.8681 - val_weighted_accuracy: 0.8501\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2451 - acc: 0.8931 - weighted_accuracy: 0.8738 - val_loss: 0.3032 - val_acc: 0.8688 - val_weighted_accuracy: 0.8500\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2441 - acc: 0.8937 - weighted_accuracy: 0.8742 - val_loss: 0.3164 - val_acc: 0.8629 - val_weighted_accuracy: 0.8485\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2429 - acc: 0.8944 - weighted_accuracy: 0.8752 - val_loss: 0.3100 - val_acc: 0.8651 - val_weighted_accuracy: 0.8506\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2423 - acc: 0.8947 - weighted_accuracy: 0.8754 - val_loss: 0.3004 - val_acc: 0.8677 - val_weighted_accuracy: 0.8508\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2418 - acc: 0.8948 - weighted_accuracy: 0.8755 - val_loss: 0.3198 - val_acc: 0.8626 - val_weighted_accuracy: 0.8483\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2423 - acc: 0.8942 - weighted_accuracy: 0.8751 - val_loss: 0.3111 - val_acc: 0.8624 - val_weighted_accuracy: 0.8495\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2419 - acc: 0.8941 - weighted_accuracy: 0.8750 - val_loss: 0.3236 - val_acc: 0.8568 - val_weighted_accuracy: 0.8420\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2404 - acc: 0.8958 - weighted_accuracy: 0.8771 - val_loss: 0.3029 - val_acc: 0.8652 - val_weighted_accuracy: 0.8450\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2397 - acc: 0.8958 - weighted_accuracy: 0.8765 - val_loss: 0.3145 - val_acc: 0.8627 - val_weighted_accuracy: 0.8449\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2405 - acc: 0.8955 - weighted_accuracy: 0.8766 - val_loss: 0.2961 - val_acc: 0.8681 - val_weighted_accuracy: 0.8493\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 50, 151)      0           embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 50, 151)      0           embedding_11[1][0]               \n",
      "                                                                 embedding_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 50, 151)      0           concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 50, 151)      0           concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_13 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 50, 42)       0           cu_dnngru_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 50, 50)       0           dropout_31[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 50, 50)       0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 50, 42)       0           permute_21[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 50, 42)       0           lambda_47[0][0]                  \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 50, 235)      0           dropout_31[0][0]                 \n",
      "                                                                 dot_63[0][0]                     \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 50, 235)      0           dropout_32[0][0]                 \n",
      "                                                                 dot_62[0][0]                     \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_14 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_77[0][0]             \n",
      "                                                                 concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 50, 42)       0           cu_dnngru_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 50, 50)       0           dropout_33[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 50, 50)       0           lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 50, 42)       0           permute_22[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 50, 42)       0           lambda_49[0][0]                  \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 50, 319)      0           dropout_33[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 50, 319)      0           dropout_34[0][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_15 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_79[0][0]             \n",
      "                                                                 concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 50, 42)       0           cu_dnngru_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 50, 50)       0           dropout_35[0][0]                 \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 50, 50)       0           lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 50, 42)       0           permute_23[0][0]                 \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 50, 42)       0           lambda_51[0][0]                  \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 50, 252)      0           dot_63[0][0]                     \n",
      "                                                                 dropout_31[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 dropout_33[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 50, 252)      0           dot_62[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 dropout_34[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 252)          0           concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 252)          0           concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 252)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 252)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 504)          0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 504)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 504)          0           concatenate_85[0][0]             \n",
      "                                                                 concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 504)          0           concatenate_85[0][0]             \n",
      "                                                                 concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 2016)         0           concatenate_85[0][0]             \n",
      "                                                                 concatenate_86[0][0]             \n",
      "                                                                 lambda_53[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 2016)         0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          516352      dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            771         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 112s 401us/step - loss: 0.3561 - acc: 0.8350 - weighted_accuracy: 0.8040 - val_loss: 0.3175 - val_acc: 0.8557 - val_weighted_accuracy: 0.8267\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.3110 - acc: 0.8577 - weighted_accuracy: 0.8327 - val_loss: 0.3032 - val_acc: 0.8641 - val_weighted_accuracy: 0.8487\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2976 - acc: 0.8652 - weighted_accuracy: 0.8409 - val_loss: 0.3081 - val_acc: 0.8584 - val_weighted_accuracy: 0.8464\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2881 - acc: 0.8705 - weighted_accuracy: 0.8471 - val_loss: 0.3013 - val_acc: 0.8609 - val_weighted_accuracy: 0.8476\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2820 - acc: 0.8739 - weighted_accuracy: 0.8512 - val_loss: 0.2914 - val_acc: 0.8681 - val_weighted_accuracy: 0.8529\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2781 - acc: 0.8762 - weighted_accuracy: 0.8542 - val_loss: 0.3004 - val_acc: 0.8625 - val_weighted_accuracy: 0.8501\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2735 - acc: 0.8785 - weighted_accuracy: 0.8571 - val_loss: 0.2869 - val_acc: 0.8708 - val_weighted_accuracy: 0.8506\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2699 - acc: 0.8809 - weighted_accuracy: 0.8595 - val_loss: 0.2810 - val_acc: 0.8733 - val_weighted_accuracy: 0.8537\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2676 - acc: 0.8818 - weighted_accuracy: 0.8605 - val_loss: 0.2860 - val_acc: 0.8715 - val_weighted_accuracy: 0.8518\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2653 - acc: 0.8830 - weighted_accuracy: 0.8623 - val_loss: 0.3015 - val_acc: 0.8640 - val_weighted_accuracy: 0.8516\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2632 - acc: 0.8845 - weighted_accuracy: 0.8637 - val_loss: 0.2948 - val_acc: 0.8635 - val_weighted_accuracy: 0.8535\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2604 - acc: 0.8857 - weighted_accuracy: 0.8649 - val_loss: 0.2825 - val_acc: 0.8705 - val_weighted_accuracy: 0.8544\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2592 - acc: 0.8868 - weighted_accuracy: 0.8665 - val_loss: 0.2879 - val_acc: 0.8686 - val_weighted_accuracy: 0.8555\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2587 - acc: 0.8863 - weighted_accuracy: 0.8659 - val_loss: 0.2836 - val_acc: 0.8693 - val_weighted_accuracy: 0.8548\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2570 - acc: 0.8872 - weighted_accuracy: 0.8672 - val_loss: 0.2834 - val_acc: 0.8728 - val_weighted_accuracy: 0.8539\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2548 - acc: 0.8880 - weighted_accuracy: 0.8677 - val_loss: 0.2926 - val_acc: 0.8677 - val_weighted_accuracy: 0.8553\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2544 - acc: 0.8883 - weighted_accuracy: 0.8682 - val_loss: 0.2877 - val_acc: 0.8727 - val_weighted_accuracy: 0.8547\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2535 - acc: 0.8888 - weighted_accuracy: 0.8679 - val_loss: 0.2827 - val_acc: 0.8770 - val_weighted_accuracy: 0.8564\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2529 - acc: 0.8897 - weighted_accuracy: 0.8697 - val_loss: 0.2893 - val_acc: 0.8705 - val_weighted_accuracy: 0.8595\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2522 - acc: 0.8902 - weighted_accuracy: 0.8699 - val_loss: 0.2975 - val_acc: 0.8695 - val_weighted_accuracy: 0.8548\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2508 - acc: 0.8900 - weighted_accuracy: 0.8696 - val_loss: 0.2832 - val_acc: 0.8733 - val_weighted_accuracy: 0.8533\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2500 - acc: 0.8909 - weighted_accuracy: 0.8712 - val_loss: 0.2833 - val_acc: 0.8740 - val_weighted_accuracy: 0.8568\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2496 - acc: 0.8909 - weighted_accuracy: 0.8710 - val_loss: 0.2906 - val_acc: 0.8714 - val_weighted_accuracy: 0.8564\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2489 - acc: 0.8916 - weighted_accuracy: 0.8717 - val_loss: 0.2824 - val_acc: 0.8762 - val_weighted_accuracy: 0.8613\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2487 - acc: 0.8919 - weighted_accuracy: 0.8720 - val_loss: 0.2832 - val_acc: 0.8743 - val_weighted_accuracy: 0.8573\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2487 - acc: 0.8913 - weighted_accuracy: 0.8715 - val_loss: 0.2841 - val_acc: 0.8741 - val_weighted_accuracy: 0.8526\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2472 - acc: 0.8918 - weighted_accuracy: 0.8719 - val_loss: 0.2846 - val_acc: 0.8758 - val_weighted_accuracy: 0.8575\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2480 - acc: 0.8916 - weighted_accuracy: 0.8721 - val_loss: 0.2814 - val_acc: 0.8720 - val_weighted_accuracy: 0.8582\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2465 - acc: 0.8923 - weighted_accuracy: 0.8730 - val_loss: 0.2935 - val_acc: 0.8708 - val_weighted_accuracy: 0.8574\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2461 - acc: 0.8923 - weighted_accuracy: 0.8726 - val_loss: 0.2797 - val_acc: 0.8765 - val_weighted_accuracy: 0.8580\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2459 - acc: 0.8927 - weighted_accuracy: 0.8731 - val_loss: 0.2817 - val_acc: 0.8760 - val_weighted_accuracy: 0.8583\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2449 - acc: 0.8932 - weighted_accuracy: 0.8734 - val_loss: 0.2836 - val_acc: 0.8761 - val_weighted_accuracy: 0.8598\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2455 - acc: 0.8929 - weighted_accuracy: 0.8736 - val_loss: 0.2847 - val_acc: 0.8751 - val_weighted_accuracy: 0.8599\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2452 - acc: 0.8926 - weighted_accuracy: 0.8735 - val_loss: 0.2867 - val_acc: 0.8730 - val_weighted_accuracy: 0.8573\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2439 - acc: 0.8937 - weighted_accuracy: 0.8742 - val_loss: 0.2840 - val_acc: 0.8754 - val_weighted_accuracy: 0.8593\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2434 - acc: 0.8936 - weighted_accuracy: 0.8741 - val_loss: 0.2966 - val_acc: 0.8715 - val_weighted_accuracy: 0.8573\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2423 - acc: 0.8938 - weighted_accuracy: 0.8747 - val_loss: 0.2873 - val_acc: 0.8702 - val_weighted_accuracy: 0.8550\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2431 - acc: 0.8941 - weighted_accuracy: 0.8746 - val_loss: 0.2838 - val_acc: 0.8733 - val_weighted_accuracy: 0.8599\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2431 - acc: 0.8938 - weighted_accuracy: 0.8740 - val_loss: 0.2962 - val_acc: 0.8661 - val_weighted_accuracy: 0.8539\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2426 - acc: 0.8940 - weighted_accuracy: 0.8742 - val_loss: 0.2896 - val_acc: 0.8715 - val_weighted_accuracy: 0.8545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2431 - acc: 0.8939 - weighted_accuracy: 0.8744 - val_loss: 0.2952 - val_acc: 0.8690 - val_weighted_accuracy: 0.8575\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2420 - acc: 0.8940 - weighted_accuracy: 0.8747 - val_loss: 0.2847 - val_acc: 0.8718 - val_weighted_accuracy: 0.8566\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2419 - acc: 0.8939 - weighted_accuracy: 0.8744 - val_loss: 0.2815 - val_acc: 0.8748 - val_weighted_accuracy: 0.8582\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2424 - acc: 0.8943 - weighted_accuracy: 0.8741 - val_loss: 0.2900 - val_acc: 0.8706 - val_weighted_accuracy: 0.8584\n",
      "Epoch 45/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2412 - acc: 0.8949 - weighted_accuracy: 0.8757 - val_loss: 0.2835 - val_acc: 0.8757 - val_weighted_accuracy: 0.8551\n",
      "Epoch 46/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2417 - acc: 0.8949 - weighted_accuracy: 0.8754 - val_loss: 0.2847 - val_acc: 0.8745 - val_weighted_accuracy: 0.8558\n",
      "Epoch 47/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2414 - acc: 0.8947 - weighted_accuracy: 0.8753 - val_loss: 0.2972 - val_acc: 0.8680 - val_weighted_accuracy: 0.8563\n",
      "Epoch 48/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2411 - acc: 0.8948 - weighted_accuracy: 0.8758 - val_loss: 0.2890 - val_acc: 0.8716 - val_weighted_accuracy: 0.8567\n",
      "Epoch 49/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2404 - acc: 0.8947 - weighted_accuracy: 0.8752 - val_loss: 0.2831 - val_acc: 0.8733 - val_weighted_accuracy: 0.8580\n",
      "Epoch 50/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2404 - acc: 0.8955 - weighted_accuracy: 0.8761 - val_loss: 0.2830 - val_acc: 0.8738 - val_weighted_accuracy: 0.8576\n",
      "Epoch 51/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2394 - acc: 0.8963 - weighted_accuracy: 0.8769 - val_loss: 0.2796 - val_acc: 0.8762 - val_weighted_accuracy: 0.8560\n",
      "Epoch 52/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2396 - acc: 0.8956 - weighted_accuracy: 0.8761 - val_loss: 0.2858 - val_acc: 0.8731 - val_weighted_accuracy: 0.8573\n",
      "Epoch 53/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2397 - acc: 0.8955 - weighted_accuracy: 0.8765 - val_loss: 0.2843 - val_acc: 0.8748 - val_weighted_accuracy: 0.8589\n",
      "Epoch 54/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2392 - acc: 0.8957 - weighted_accuracy: 0.8766 - val_loss: 0.2841 - val_acc: 0.8755 - val_weighted_accuracy: 0.8585\n",
      "Epoch 55/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2390 - acc: 0.8961 - weighted_accuracy: 0.8769 - val_loss: 0.2860 - val_acc: 0.8746 - val_weighted_accuracy: 0.8561\n",
      "Epoch 56/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2396 - acc: 0.8956 - weighted_accuracy: 0.8763 - val_loss: 0.2861 - val_acc: 0.8737 - val_weighted_accuracy: 0.8559\n",
      "Epoch 57/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2384 - acc: 0.8960 - weighted_accuracy: 0.8770 - val_loss: 0.2875 - val_acc: 0.8757 - val_weighted_accuracy: 0.8580\n",
      "Epoch 58/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2381 - acc: 0.8965 - weighted_accuracy: 0.8772 - val_loss: 0.2850 - val_acc: 0.8743 - val_weighted_accuracy: 0.8571\n",
      "Epoch 59/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2373 - acc: 0.8965 - weighted_accuracy: 0.8775 - val_loss: 0.2880 - val_acc: 0.8712 - val_weighted_accuracy: 0.8571\n",
      "Epoch 60/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2383 - acc: 0.8963 - weighted_accuracy: 0.8774 - val_loss: 0.2981 - val_acc: 0.8709 - val_weighted_accuracy: 0.8528\n",
      "Epoch 61/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2366 - acc: 0.8968 - weighted_accuracy: 0.8781 - val_loss: 0.2894 - val_acc: 0.8725 - val_weighted_accuracy: 0.8555\n",
      "Epoch 62/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2372 - acc: 0.8965 - weighted_accuracy: 0.8772 - val_loss: 0.2889 - val_acc: 0.8743 - val_weighted_accuracy: 0.8581\n",
      "Epoch 63/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2379 - acc: 0.8961 - weighted_accuracy: 0.8768 - val_loss: 0.2922 - val_acc: 0.8721 - val_weighted_accuracy: 0.8540\n",
      "Epoch 64/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2371 - acc: 0.8973 - weighted_accuracy: 0.8782 - val_loss: 0.2863 - val_acc: 0.8750 - val_weighted_accuracy: 0.8571\n",
      "Epoch 65/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2363 - acc: 0.8970 - weighted_accuracy: 0.8780 - val_loss: 0.2870 - val_acc: 0.8727 - val_weighted_accuracy: 0.8570\n",
      "Epoch 66/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2369 - acc: 0.8968 - weighted_accuracy: 0.8779 - val_loss: 0.2885 - val_acc: 0.8718 - val_weighted_accuracy: 0.8579\n",
      "Epoch 67/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2366 - acc: 0.8973 - weighted_accuracy: 0.8782 - val_loss: 0.2888 - val_acc: 0.8724 - val_weighted_accuracy: 0.8545\n",
      "Epoch 68/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2363 - acc: 0.8972 - weighted_accuracy: 0.8779 - val_loss: 0.2931 - val_acc: 0.8726 - val_weighted_accuracy: 0.8571\n",
      "Epoch 69/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2361 - acc: 0.8970 - weighted_accuracy: 0.8782 - val_loss: 0.2913 - val_acc: 0.8708 - val_weighted_accuracy: 0.8542\n",
      "Epoch 70/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2361 - acc: 0.8972 - weighted_accuracy: 0.8779 - val_loss: 0.2928 - val_acc: 0.8696 - val_weighted_accuracy: 0.8549\n",
      "Epoch 71/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2359 - acc: 0.8970 - weighted_accuracy: 0.8783 - val_loss: 0.2918 - val_acc: 0.8730 - val_weighted_accuracy: 0.8559\n",
      "Epoch 72/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2353 - acc: 0.8978 - weighted_accuracy: 0.8790 - val_loss: 0.2974 - val_acc: 0.8668 - val_weighted_accuracy: 0.8543\n",
      "Epoch 73/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2350 - acc: 0.8980 - weighted_accuracy: 0.8791 - val_loss: 0.2930 - val_acc: 0.8697 - val_weighted_accuracy: 0.8559\n",
      "Epoch 74/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2349 - acc: 0.8979 - weighted_accuracy: 0.8792 - val_loss: 0.2935 - val_acc: 0.8715 - val_weighted_accuracy: 0.8559\n",
      "Epoch 75/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2351 - acc: 0.8978 - weighted_accuracy: 0.8788 - val_loss: 0.2938 - val_acc: 0.8711 - val_weighted_accuracy: 0.8528\n",
      "Epoch 76/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2352 - acc: 0.8976 - weighted_accuracy: 0.8786 - val_loss: 0.2973 - val_acc: 0.8690 - val_weighted_accuracy: 0.8539\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 50, 151)      0           embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 50, 151)      0           embedding_13[1][0]               \n",
      "                                                                 embedding_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 50, 151)      0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 50, 151)      0           concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_16 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 50, 42)       0           cu_dnngru_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 50, 50)       0           dropout_38[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 50, 50)       0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 50, 42)       0           permute_24[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 50, 42)       0           lambda_54[0][0]                  \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 50, 235)      0           dropout_38[0][0]                 \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 50, 235)      0           dropout_39[0][0]                 \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_17 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_90[0][0]             \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 50, 42)       0           cu_dnngru_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 50, 50)       0           dropout_40[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 50, 50)       0           lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 50, 42)       0           permute_25[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 50, 42)       0           lambda_56[0][0]                  \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 50, 319)      0           dropout_40[0][0]                 \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 50, 319)      0           dropout_41[0][0]                 \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_18 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_92[0][0]             \n",
      "                                                                 concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 50, 42)       0           cu_dnngru_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 50, 50)       0           dropout_42[0][0]                 \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 50, 50)       0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 50, 42)       0           permute_26[0][0]                 \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 50, 42)       0           lambda_58[0][0]                  \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 50, 252)      0           dot_72[0][0]                     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 50, 252)      0           dot_71[0][0]                     \n",
      "                                                                 dropout_39[0][0]                 \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 dropout_41[0][0]                 \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 252)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 252)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 252)          0           concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 252)          0           concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 504)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 504)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 504)          0           concatenate_98[0][0]             \n",
      "                                                                 concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 504)          0           concatenate_98[0][0]             \n",
      "                                                                 concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 2016)         0           concatenate_98[0][0]             \n",
      "                                                                 concatenate_99[0][0]             \n",
      "                                                                 lambda_60[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 2016)         0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          516352      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            771         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 113s 402us/step - loss: 0.3524 - acc: 0.8361 - weighted_accuracy: 0.8052 - val_loss: 0.3340 - val_acc: 0.8433 - val_weighted_accuracy: 0.8302\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.3075 - acc: 0.8601 - weighted_accuracy: 0.8343 - val_loss: 0.3304 - val_acc: 0.8420 - val_weighted_accuracy: 0.8233\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2927 - acc: 0.8686 - weighted_accuracy: 0.8439 - val_loss: 0.3304 - val_acc: 0.8417 - val_weighted_accuracy: 0.8289\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2840 - acc: 0.8731 - weighted_accuracy: 0.8495 - val_loss: 0.3433 - val_acc: 0.8336 - val_weighted_accuracy: 0.8238\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2769 - acc: 0.8774 - weighted_accuracy: 0.8540 - val_loss: 0.3090 - val_acc: 0.8572 - val_weighted_accuracy: 0.8420\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2732 - acc: 0.8790 - weighted_accuracy: 0.8560 - val_loss: 0.3116 - val_acc: 0.8570 - val_weighted_accuracy: 0.8424\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2688 - acc: 0.8813 - weighted_accuracy: 0.8591 - val_loss: 0.3169 - val_acc: 0.8578 - val_weighted_accuracy: 0.8449\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2658 - acc: 0.8833 - weighted_accuracy: 0.8609 - val_loss: 0.3138 - val_acc: 0.8562 - val_weighted_accuracy: 0.8425\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2637 - acc: 0.8841 - weighted_accuracy: 0.8619 - val_loss: 0.3051 - val_acc: 0.8616 - val_weighted_accuracy: 0.8460\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2605 - acc: 0.8860 - weighted_accuracy: 0.8644 - val_loss: 0.3184 - val_acc: 0.8525 - val_weighted_accuracy: 0.8435\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2583 - acc: 0.8870 - weighted_accuracy: 0.8652 - val_loss: 0.3084 - val_acc: 0.8601 - val_weighted_accuracy: 0.8508\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2569 - acc: 0.8881 - weighted_accuracy: 0.8663 - val_loss: 0.3052 - val_acc: 0.8614 - val_weighted_accuracy: 0.8446\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2549 - acc: 0.8885 - weighted_accuracy: 0.8668 - val_loss: 0.3152 - val_acc: 0.8577 - val_weighted_accuracy: 0.8423\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2539 - acc: 0.8891 - weighted_accuracy: 0.8680 - val_loss: 0.3124 - val_acc: 0.8602 - val_weighted_accuracy: 0.8454\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2538 - acc: 0.8891 - weighted_accuracy: 0.8681 - val_loss: 0.3028 - val_acc: 0.8639 - val_weighted_accuracy: 0.8489\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2529 - acc: 0.8900 - weighted_accuracy: 0.8692 - val_loss: 0.3059 - val_acc: 0.8621 - val_weighted_accuracy: 0.8503\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2509 - acc: 0.8905 - weighted_accuracy: 0.8695 - val_loss: 0.3146 - val_acc: 0.8615 - val_weighted_accuracy: 0.8460\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2512 - acc: 0.8907 - weighted_accuracy: 0.8698 - val_loss: 0.3122 - val_acc: 0.8594 - val_weighted_accuracy: 0.8483\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2500 - acc: 0.8912 - weighted_accuracy: 0.8704 - val_loss: 0.3054 - val_acc: 0.8631 - val_weighted_accuracy: 0.8479\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2495 - acc: 0.8915 - weighted_accuracy: 0.8709 - val_loss: 0.3223 - val_acc: 0.8555 - val_weighted_accuracy: 0.8429\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2488 - acc: 0.8919 - weighted_accuracy: 0.8716 - val_loss: 0.3243 - val_acc: 0.8570 - val_weighted_accuracy: 0.8463\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2477 - acc: 0.8917 - weighted_accuracy: 0.8711 - val_loss: 0.3078 - val_acc: 0.8626 - val_weighted_accuracy: 0.8451\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2472 - acc: 0.8926 - weighted_accuracy: 0.8719 - val_loss: 0.3072 - val_acc: 0.8606 - val_weighted_accuracy: 0.8470\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2459 - acc: 0.8932 - weighted_accuracy: 0.8729 - val_loss: 0.3116 - val_acc: 0.8606 - val_weighted_accuracy: 0.8483\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2455 - acc: 0.8936 - weighted_accuracy: 0.8734 - val_loss: 0.3201 - val_acc: 0.8554 - val_weighted_accuracy: 0.8394\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2447 - acc: 0.8933 - weighted_accuracy: 0.8730 - val_loss: 0.3107 - val_acc: 0.8594 - val_weighted_accuracy: 0.8432\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2447 - acc: 0.8940 - weighted_accuracy: 0.8739 - val_loss: 0.3080 - val_acc: 0.8619 - val_weighted_accuracy: 0.8481\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2442 - acc: 0.8941 - weighted_accuracy: 0.8738 - val_loss: 0.3199 - val_acc: 0.8583 - val_weighted_accuracy: 0.8461\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2441 - acc: 0.8943 - weighted_accuracy: 0.8741 - val_loss: 0.3073 - val_acc: 0.8630 - val_weighted_accuracy: 0.8460\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2430 - acc: 0.8942 - weighted_accuracy: 0.8738 - val_loss: 0.3167 - val_acc: 0.8586 - val_weighted_accuracy: 0.8475\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2430 - acc: 0.8947 - weighted_accuracy: 0.8745 - val_loss: 0.3206 - val_acc: 0.8593 - val_weighted_accuracy: 0.8487\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2431 - acc: 0.8942 - weighted_accuracy: 0.8741 - val_loss: 0.3086 - val_acc: 0.8620 - val_weighted_accuracy: 0.8492\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2422 - acc: 0.8945 - weighted_accuracy: 0.8744 - val_loss: 0.3242 - val_acc: 0.8549 - val_weighted_accuracy: 0.8450\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2430 - acc: 0.8944 - weighted_accuracy: 0.8741 - val_loss: 0.3134 - val_acc: 0.8599 - val_weighted_accuracy: 0.8447\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2420 - acc: 0.8952 - weighted_accuracy: 0.8754 - val_loss: 0.3193 - val_acc: 0.8573 - val_weighted_accuracy: 0.8470\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2410 - acc: 0.8959 - weighted_accuracy: 0.8757 - val_loss: 0.3145 - val_acc: 0.8578 - val_weighted_accuracy: 0.8424\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2410 - acc: 0.8954 - weighted_accuracy: 0.8751 - val_loss: 0.3116 - val_acc: 0.8608 - val_weighted_accuracy: 0.8473\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2403 - acc: 0.8957 - weighted_accuracy: 0.8755 - val_loss: 0.3111 - val_acc: 0.8622 - val_weighted_accuracy: 0.8510\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2406 - acc: 0.8958 - weighted_accuracy: 0.8758 - val_loss: 0.3139 - val_acc: 0.8583 - val_weighted_accuracy: 0.8448\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2398 - acc: 0.8956 - weighted_accuracy: 0.8759 - val_loss: 0.3133 - val_acc: 0.8612 - val_weighted_accuracy: 0.8448\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 50, 151)      0           embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 50, 151)      0           embedding_15[1][0]               \n",
      "                                                                 embedding_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 50, 151)      0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 50, 151)      0           concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_19 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 50, 42)       0           cu_dnngru_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 50, 50)       0           dropout_45[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 50, 50)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 50, 42)       0           permute_27[0][0]                 \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 50, 42)       0           lambda_61[0][0]                  \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 50, 235)      0           dropout_45[0][0]                 \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 spatial_dropout1d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 50, 235)      0           dropout_46[0][0]                 \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_20 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_103[0][0]            \n",
      "                                                                 concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 50, 42)       0           cu_dnngru_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 50, 50)       0           dropout_47[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 50, 50)       0           lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 50, 42)       0           permute_28[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 50, 42)       0           lambda_63[0][0]                  \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 50, 319)      0           dropout_47[0][0]                 \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 50, 319)      0           dropout_48[0][0]                 \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_21 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_105[0][0]            \n",
      "                                                                 concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 50, 42)       0           cu_dnngru_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_85 (Dot)                    (None, 50, 50)       0           dropout_49[0][0]                 \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 50, 50)       0           lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50, 50)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_87 (Dot)                    (None, 50, 42)       0           permute_29[0][0]                 \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_86 (Dot)                    (None, 50, 42)       0           lambda_65[0][0]                  \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 50, 252)      0           dot_81[0][0]                     \n",
      "                                                                 dropout_45[0][0]                 \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 dropout_47[0][0]                 \n",
      "                                                                 dot_87[0][0]                     \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 50, 252)      0           dot_80[0][0]                     \n",
      "                                                                 dropout_46[0][0]                 \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 dropout_48[0][0]                 \n",
      "                                                                 dot_86[0][0]                     \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 252)          0           concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 252)          0           concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 252)          0           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 252)          0           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 504)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 504)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 504)          0           concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 504)          0           concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 2016)         0           concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 2016)         0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          516352      dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 3)            771         dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 113s 403us/step - loss: 0.3547 - acc: 0.8354 - weighted_accuracy: 0.8044 - val_loss: 0.3312 - val_acc: 0.8477 - val_weighted_accuracy: 0.8347\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.3092 - acc: 0.8591 - weighted_accuracy: 0.8337 - val_loss: 0.3175 - val_acc: 0.8533 - val_weighted_accuracy: 0.8363\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2947 - acc: 0.8665 - weighted_accuracy: 0.8424 - val_loss: 0.3069 - val_acc: 0.8600 - val_weighted_accuracy: 0.8410\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2877 - acc: 0.8710 - weighted_accuracy: 0.8476 - val_loss: 0.3248 - val_acc: 0.8488 - val_weighted_accuracy: 0.8401\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2810 - acc: 0.8744 - weighted_accuracy: 0.8519 - val_loss: 0.3030 - val_acc: 0.8608 - val_weighted_accuracy: 0.8422\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2754 - acc: 0.8777 - weighted_accuracy: 0.8554 - val_loss: 0.3048 - val_acc: 0.8591 - val_weighted_accuracy: 0.8465\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2720 - acc: 0.8790 - weighted_accuracy: 0.8564 - val_loss: 0.3096 - val_acc: 0.8590 - val_weighted_accuracy: 0.8421\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2680 - acc: 0.8812 - weighted_accuracy: 0.8592 - val_loss: 0.3177 - val_acc: 0.8533 - val_weighted_accuracy: 0.8430\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2659 - acc: 0.8827 - weighted_accuracy: 0.8608 - val_loss: 0.2977 - val_acc: 0.8631 - val_weighted_accuracy: 0.8460\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2629 - acc: 0.8842 - weighted_accuracy: 0.8625 - val_loss: 0.3003 - val_acc: 0.8640 - val_weighted_accuracy: 0.8501\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2610 - acc: 0.8848 - weighted_accuracy: 0.8636 - val_loss: 0.3003 - val_acc: 0.8638 - val_weighted_accuracy: 0.8423\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2592 - acc: 0.8850 - weighted_accuracy: 0.8636 - val_loss: 0.3006 - val_acc: 0.8642 - val_weighted_accuracy: 0.8478\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2586 - acc: 0.8862 - weighted_accuracy: 0.8648 - val_loss: 0.2972 - val_acc: 0.8670 - val_weighted_accuracy: 0.8505\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2568 - acc: 0.8871 - weighted_accuracy: 0.8660 - val_loss: 0.3012 - val_acc: 0.8650 - val_weighted_accuracy: 0.8491\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2555 - acc: 0.8878 - weighted_accuracy: 0.8670 - val_loss: 0.3061 - val_acc: 0.8633 - val_weighted_accuracy: 0.8447\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2539 - acc: 0.8884 - weighted_accuracy: 0.8678 - val_loss: 0.3003 - val_acc: 0.8647 - val_weighted_accuracy: 0.8473\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2528 - acc: 0.8891 - weighted_accuracy: 0.8685 - val_loss: 0.3006 - val_acc: 0.8667 - val_weighted_accuracy: 0.8496\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2525 - acc: 0.8897 - weighted_accuracy: 0.8692 - val_loss: 0.3091 - val_acc: 0.8604 - val_weighted_accuracy: 0.8486\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2516 - acc: 0.8904 - weighted_accuracy: 0.8705 - val_loss: 0.2966 - val_acc: 0.8652 - val_weighted_accuracy: 0.8499\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2505 - acc: 0.8901 - weighted_accuracy: 0.8698 - val_loss: 0.2991 - val_acc: 0.8653 - val_weighted_accuracy: 0.8511\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2499 - acc: 0.8908 - weighted_accuracy: 0.8702 - val_loss: 0.3069 - val_acc: 0.8623 - val_weighted_accuracy: 0.8480\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2499 - acc: 0.8904 - weighted_accuracy: 0.8702 - val_loss: 0.3045 - val_acc: 0.8641 - val_weighted_accuracy: 0.8471\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2484 - acc: 0.8913 - weighted_accuracy: 0.8712 - val_loss: 0.3015 - val_acc: 0.8632 - val_weighted_accuracy: 0.8488\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2479 - acc: 0.8918 - weighted_accuracy: 0.8715 - val_loss: 0.3003 - val_acc: 0.8644 - val_weighted_accuracy: 0.8484\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2469 - acc: 0.8916 - weighted_accuracy: 0.8716 - val_loss: 0.2996 - val_acc: 0.8657 - val_weighted_accuracy: 0.8498\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2468 - acc: 0.8925 - weighted_accuracy: 0.8727 - val_loss: 0.2966 - val_acc: 0.8685 - val_weighted_accuracy: 0.8486\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2461 - acc: 0.8921 - weighted_accuracy: 0.8725 - val_loss: 0.3033 - val_acc: 0.8641 - val_weighted_accuracy: 0.8510\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2453 - acc: 0.8922 - weighted_accuracy: 0.8721 - val_loss: 0.2999 - val_acc: 0.8658 - val_weighted_accuracy: 0.8494\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2459 - acc: 0.8928 - weighted_accuracy: 0.8731 - val_loss: 0.2956 - val_acc: 0.8691 - val_weighted_accuracy: 0.8483\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2450 - acc: 0.8934 - weighted_accuracy: 0.8738 - val_loss: 0.3096 - val_acc: 0.8594 - val_weighted_accuracy: 0.8462\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2446 - acc: 0.8932 - weighted_accuracy: 0.8739 - val_loss: 0.3038 - val_acc: 0.8617 - val_weighted_accuracy: 0.8463\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2444 - acc: 0.8936 - weighted_accuracy: 0.8741 - val_loss: 0.2998 - val_acc: 0.8668 - val_weighted_accuracy: 0.8455\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2445 - acc: 0.8934 - weighted_accuracy: 0.8736 - val_loss: 0.3083 - val_acc: 0.8631 - val_weighted_accuracy: 0.8518\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2433 - acc: 0.8940 - weighted_accuracy: 0.8748 - val_loss: 0.2960 - val_acc: 0.8687 - val_weighted_accuracy: 0.8500\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2435 - acc: 0.8938 - weighted_accuracy: 0.8743 - val_loss: 0.3013 - val_acc: 0.8667 - val_weighted_accuracy: 0.8499\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2433 - acc: 0.8943 - weighted_accuracy: 0.8748 - val_loss: 0.3034 - val_acc: 0.8643 - val_weighted_accuracy: 0.8475\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2421 - acc: 0.8948 - weighted_accuracy: 0.8758 - val_loss: 0.2984 - val_acc: 0.8673 - val_weighted_accuracy: 0.8459\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2425 - acc: 0.8944 - weighted_accuracy: 0.8750 - val_loss: 0.3084 - val_acc: 0.8603 - val_weighted_accuracy: 0.8497\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2425 - acc: 0.8947 - weighted_accuracy: 0.8752 - val_loss: 0.3018 - val_acc: 0.8669 - val_weighted_accuracy: 0.8496\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2432 - acc: 0.8940 - weighted_accuracy: 0.8747 - val_loss: 0.2964 - val_acc: 0.8674 - val_weighted_accuracy: 0.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2417 - acc: 0.8944 - weighted_accuracy: 0.8753 - val_loss: 0.3036 - val_acc: 0.8668 - val_weighted_accuracy: 0.8469\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2417 - acc: 0.8947 - weighted_accuracy: 0.8754 - val_loss: 0.3071 - val_acc: 0.8646 - val_weighted_accuracy: 0.8485\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2409 - acc: 0.8952 - weighted_accuracy: 0.8754 - val_loss: 0.3115 - val_acc: 0.8620 - val_weighted_accuracy: 0.8467\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2408 - acc: 0.8951 - weighted_accuracy: 0.8759 - val_loss: 0.3072 - val_acc: 0.8647 - val_weighted_accuracy: 0.8522\n",
      "Epoch 45/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2408 - acc: 0.8949 - weighted_accuracy: 0.8753 - val_loss: 0.3028 - val_acc: 0.8676 - val_weighted_accuracy: 0.8488\n",
      "Epoch 46/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2401 - acc: 0.8954 - weighted_accuracy: 0.8763 - val_loss: 0.3116 - val_acc: 0.8654 - val_weighted_accuracy: 0.8475\n",
      "Epoch 47/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2395 - acc: 0.8954 - weighted_accuracy: 0.8762 - val_loss: 0.3084 - val_acc: 0.8659 - val_weighted_accuracy: 0.8500\n",
      "Epoch 48/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2400 - acc: 0.8955 - weighted_accuracy: 0.8761 - val_loss: 0.3051 - val_acc: 0.8648 - val_weighted_accuracy: 0.8528\n",
      "Epoch 49/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2397 - acc: 0.8951 - weighted_accuracy: 0.8756 - val_loss: 0.3052 - val_acc: 0.8634 - val_weighted_accuracy: 0.8476\n",
      "Epoch 50/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2397 - acc: 0.8955 - weighted_accuracy: 0.8760 - val_loss: 0.2964 - val_acc: 0.8675 - val_weighted_accuracy: 0.8526\n",
      "Epoch 51/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2391 - acc: 0.8958 - weighted_accuracy: 0.8765 - val_loss: 0.3001 - val_acc: 0.8679 - val_weighted_accuracy: 0.8495\n",
      "Epoch 52/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2391 - acc: 0.8956 - weighted_accuracy: 0.8761 - val_loss: 0.3097 - val_acc: 0.8622 - val_weighted_accuracy: 0.8501\n",
      "Epoch 53/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2382 - acc: 0.8963 - weighted_accuracy: 0.8775 - val_loss: 0.3026 - val_acc: 0.8663 - val_weighted_accuracy: 0.8481\n",
      "Epoch 54/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2393 - acc: 0.8962 - weighted_accuracy: 0.8772 - val_loss: 0.3061 - val_acc: 0.8665 - val_weighted_accuracy: 0.8521\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 50, 151)      0           embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 50, 151)      0           embedding_17[1][0]               \n",
      "                                                                 embedding_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 50, 151)      0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 50, 151)      0           concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_22 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 50, 42)       0           cu_dnngru_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_88 (Dot)                    (None, 50, 50)       0           dropout_52[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 50, 50)       0           lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50, 50)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_90 (Dot)                    (None, 50, 42)       0           permute_30[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_89 (Dot)                    (None, 50, 42)       0           lambda_68[0][0]                  \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 50, 235)      0           dropout_52[0][0]                 \n",
      "                                                                 dot_90[0][0]                     \n",
      "                                                                 spatial_dropout1d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 50, 235)      0           dropout_53[0][0]                 \n",
      "                                                                 dot_89[0][0]                     \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_23 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_116[0][0]            \n",
      "                                                                 concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 50, 42)       0           cu_dnngru_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_91 (Dot)                    (None, 50, 50)       0           dropout_54[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_31 (Permute)            (None, 50, 50)       0           lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 50, 50)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_93 (Dot)                    (None, 50, 42)       0           permute_31[0][0]                 \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_92 (Dot)                    (None, 50, 42)       0           lambda_70[0][0]                  \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 50, 319)      0           dropout_54[0][0]                 \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 50, 319)      0           dropout_55[0][0]                 \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_24 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_118[0][0]            \n",
      "                                                                 concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 50, 42)       0           cu_dnngru_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_94 (Dot)                    (None, 50, 50)       0           dropout_56[0][0]                 \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_32 (Permute)            (None, 50, 50)       0           lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 50, 50)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_96 (Dot)                    (None, 50, 42)       0           permute_32[0][0]                 \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_95 (Dot)                    (None, 50, 42)       0           lambda_72[0][0]                  \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 50, 252)      0           dot_90[0][0]                     \n",
      "                                                                 dropout_52[0][0]                 \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 dropout_54[0][0]                 \n",
      "                                                                 dot_96[0][0]                     \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 50, 252)      0           dot_89[0][0]                     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 dropout_55[0][0]                 \n",
      "                                                                 dot_95[0][0]                     \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 252)          0           concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 252)          0           concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 252)          0           concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 252)          0           concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 504)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 504)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 504)          0           concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 504)          0           concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 2016)         0           concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "                                                                 lambda_74[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 2016)         0           concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          516352      dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            771         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 113s 403us/step - loss: 0.3555 - acc: 0.8361 - weighted_accuracy: 0.8046 - val_loss: 0.3708 - val_acc: 0.8175 - val_weighted_accuracy: 0.8081\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.3084 - acc: 0.8598 - weighted_accuracy: 0.8341 - val_loss: 0.3341 - val_acc: 0.8409 - val_weighted_accuracy: 0.8239\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2939 - acc: 0.8679 - weighted_accuracy: 0.8437 - val_loss: 0.3306 - val_acc: 0.8430 - val_weighted_accuracy: 0.8258\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2842 - acc: 0.8727 - weighted_accuracy: 0.8493 - val_loss: 0.3753 - val_acc: 0.8265 - val_weighted_accuracy: 0.8176\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2782 - acc: 0.8765 - weighted_accuracy: 0.8536 - val_loss: 0.3328 - val_acc: 0.8370 - val_weighted_accuracy: 0.8223\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2727 - acc: 0.8799 - weighted_accuracy: 0.8577 - val_loss: 0.3344 - val_acc: 0.8442 - val_weighted_accuracy: 0.8342\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2691 - acc: 0.8816 - weighted_accuracy: 0.8596 - val_loss: 0.3298 - val_acc: 0.8464 - val_weighted_accuracy: 0.8355\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2656 - acc: 0.8830 - weighted_accuracy: 0.8617 - val_loss: 0.3162 - val_acc: 0.8536 - val_weighted_accuracy: 0.8352\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2625 - acc: 0.8846 - weighted_accuracy: 0.8635 - val_loss: 0.3179 - val_acc: 0.8531 - val_weighted_accuracy: 0.8409\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2600 - acc: 0.8863 - weighted_accuracy: 0.8652 - val_loss: 0.3189 - val_acc: 0.8545 - val_weighted_accuracy: 0.8392\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2596 - acc: 0.8864 - weighted_accuracy: 0.8653 - val_loss: 0.3226 - val_acc: 0.8495 - val_weighted_accuracy: 0.8358\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2577 - acc: 0.8869 - weighted_accuracy: 0.8662 - val_loss: 0.3221 - val_acc: 0.8544 - val_weighted_accuracy: 0.8359\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2558 - acc: 0.8881 - weighted_accuracy: 0.8675 - val_loss: 0.3157 - val_acc: 0.8545 - val_weighted_accuracy: 0.8353\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2539 - acc: 0.8892 - weighted_accuracy: 0.8687 - val_loss: 0.3187 - val_acc: 0.8522 - val_weighted_accuracy: 0.8341\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2522 - acc: 0.8903 - weighted_accuracy: 0.8697 - val_loss: 0.3181 - val_acc: 0.8522 - val_weighted_accuracy: 0.8404\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2508 - acc: 0.8912 - weighted_accuracy: 0.8714 - val_loss: 0.3177 - val_acc: 0.8549 - val_weighted_accuracy: 0.8355\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 398us/step - loss: 0.2507 - acc: 0.8909 - weighted_accuracy: 0.8707 - val_loss: 0.3198 - val_acc: 0.8533 - val_weighted_accuracy: 0.8374\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2508 - acc: 0.8910 - weighted_accuracy: 0.8707 - val_loss: 0.3235 - val_acc: 0.8526 - val_weighted_accuracy: 0.8350\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2488 - acc: 0.8917 - weighted_accuracy: 0.8716 - val_loss: 0.3162 - val_acc: 0.8561 - val_weighted_accuracy: 0.8378\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2474 - acc: 0.8923 - weighted_accuracy: 0.8722 - val_loss: 0.3224 - val_acc: 0.8528 - val_weighted_accuracy: 0.8390\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2462 - acc: 0.8931 - weighted_accuracy: 0.8729 - val_loss: 0.3191 - val_acc: 0.8540 - val_weighted_accuracy: 0.8398\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2462 - acc: 0.8926 - weighted_accuracy: 0.8728 - val_loss: 0.3239 - val_acc: 0.8504 - val_weighted_accuracy: 0.8355\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2455 - acc: 0.8930 - weighted_accuracy: 0.8733 - val_loss: 0.3182 - val_acc: 0.8568 - val_weighted_accuracy: 0.8400\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2448 - acc: 0.8937 - weighted_accuracy: 0.8743 - val_loss: 0.3152 - val_acc: 0.8550 - val_weighted_accuracy: 0.8400\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2436 - acc: 0.8946 - weighted_accuracy: 0.8750 - val_loss: 0.3377 - val_acc: 0.8468 - val_weighted_accuracy: 0.8365\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2440 - acc: 0.8945 - weighted_accuracy: 0.8748 - val_loss: 0.3170 - val_acc: 0.8539 - val_weighted_accuracy: 0.8401\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2436 - acc: 0.8944 - weighted_accuracy: 0.8747 - val_loss: 0.3317 - val_acc: 0.8479 - val_weighted_accuracy: 0.8378\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2431 - acc: 0.8942 - weighted_accuracy: 0.8745 - val_loss: 0.3221 - val_acc: 0.8523 - val_weighted_accuracy: 0.8394\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2423 - acc: 0.8949 - weighted_accuracy: 0.8756 - val_loss: 0.3176 - val_acc: 0.8560 - val_weighted_accuracy: 0.8430\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2429 - acc: 0.8947 - weighted_accuracy: 0.8750 - val_loss: 0.3193 - val_acc: 0.8547 - val_weighted_accuracy: 0.8407\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2416 - acc: 0.8951 - weighted_accuracy: 0.8756 - val_loss: 0.3172 - val_acc: 0.8567 - val_weighted_accuracy: 0.8408\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2416 - acc: 0.8955 - weighted_accuracy: 0.8759 - val_loss: 0.3238 - val_acc: 0.8544 - val_weighted_accuracy: 0.8411\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2408 - acc: 0.8958 - weighted_accuracy: 0.8764 - val_loss: 0.3172 - val_acc: 0.8561 - val_weighted_accuracy: 0.8410\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2406 - acc: 0.8956 - weighted_accuracy: 0.8760 - val_loss: 0.3246 - val_acc: 0.8514 - val_weighted_accuracy: 0.8393\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2400 - acc: 0.8961 - weighted_accuracy: 0.8764 - val_loss: 0.3235 - val_acc: 0.8537 - val_weighted_accuracy: 0.8362\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2406 - acc: 0.8960 - weighted_accuracy: 0.8765 - val_loss: 0.3184 - val_acc: 0.8539 - val_weighted_accuracy: 0.8355\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2388 - acc: 0.8965 - weighted_accuracy: 0.8766 - val_loss: 0.3227 - val_acc: 0.8530 - val_weighted_accuracy: 0.8396\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2388 - acc: 0.8964 - weighted_accuracy: 0.8769 - val_loss: 0.3210 - val_acc: 0.8557 - val_weighted_accuracy: 0.8378\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2380 - acc: 0.8968 - weighted_accuracy: 0.8776 - val_loss: 0.3256 - val_acc: 0.8521 - val_weighted_accuracy: 0.8373\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2375 - acc: 0.8974 - weighted_accuracy: 0.8779 - val_loss: 0.3213 - val_acc: 0.8546 - val_weighted_accuracy: 0.8424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2376 - acc: 0.8969 - weighted_accuracy: 0.8774 - val_loss: 0.3136 - val_acc: 0.8562 - val_weighted_accuracy: 0.8410\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2379 - acc: 0.8967 - weighted_accuracy: 0.8772 - val_loss: 0.3218 - val_acc: 0.8545 - val_weighted_accuracy: 0.8387\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2367 - acc: 0.8974 - weighted_accuracy: 0.8781 - val_loss: 0.3277 - val_acc: 0.8506 - val_weighted_accuracy: 0.8373\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2364 - acc: 0.8978 - weighted_accuracy: 0.8786 - val_loss: 0.3227 - val_acc: 0.8518 - val_weighted_accuracy: 0.8395\n",
      "Epoch 45/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2368 - acc: 0.8974 - weighted_accuracy: 0.8779 - val_loss: 0.3231 - val_acc: 0.8535 - val_weighted_accuracy: 0.8377\n",
      "Epoch 46/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2365 - acc: 0.8973 - weighted_accuracy: 0.8778 - val_loss: 0.3287 - val_acc: 0.8528 - val_weighted_accuracy: 0.8349\n",
      "Epoch 47/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2360 - acc: 0.8978 - weighted_accuracy: 0.8783 - val_loss: 0.3201 - val_acc: 0.8552 - val_weighted_accuracy: 0.8388\n",
      "Epoch 48/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2355 - acc: 0.8981 - weighted_accuracy: 0.8788 - val_loss: 0.3369 - val_acc: 0.8515 - val_weighted_accuracy: 0.8388\n",
      "Epoch 49/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2359 - acc: 0.8977 - weighted_accuracy: 0.8787 - val_loss: 0.3201 - val_acc: 0.8544 - val_weighted_accuracy: 0.8376\n",
      "Epoch 50/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2353 - acc: 0.8985 - weighted_accuracy: 0.8792 - val_loss: 0.3181 - val_acc: 0.8517 - val_weighted_accuracy: 0.8400\n",
      "Epoch 51/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2340 - acc: 0.8987 - weighted_accuracy: 0.8798 - val_loss: 0.3220 - val_acc: 0.8534 - val_weighted_accuracy: 0.8385\n",
      "Epoch 52/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2337 - acc: 0.8990 - weighted_accuracy: 0.8796 - val_loss: 0.3215 - val_acc: 0.8551 - val_weighted_accuracy: 0.8402\n",
      "Epoch 53/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2338 - acc: 0.8993 - weighted_accuracy: 0.8805 - val_loss: 0.3195 - val_acc: 0.8550 - val_weighted_accuracy: 0.8363\n",
      "Epoch 54/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2344 - acc: 0.8981 - weighted_accuracy: 0.8790 - val_loss: 0.3234 - val_acc: 0.8535 - val_weighted_accuracy: 0.8339\n",
      "Epoch 55/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2330 - acc: 0.8995 - weighted_accuracy: 0.8805 - val_loss: 0.3207 - val_acc: 0.8556 - val_weighted_accuracy: 0.8384\n",
      "Epoch 56/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2329 - acc: 0.8990 - weighted_accuracy: 0.8803 - val_loss: 0.3230 - val_acc: 0.8560 - val_weighted_accuracy: 0.8361\n",
      "Epoch 57/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2330 - acc: 0.8993 - weighted_accuracy: 0.8800 - val_loss: 0.3331 - val_acc: 0.8518 - val_weighted_accuracy: 0.8366\n",
      "Epoch 58/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2331 - acc: 0.8997 - weighted_accuracy: 0.8806 - val_loss: 0.3223 - val_acc: 0.8542 - val_weighted_accuracy: 0.8402\n",
      "Epoch 59/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2328 - acc: 0.8996 - weighted_accuracy: 0.8806 - val_loss: 0.3362 - val_acc: 0.8539 - val_weighted_accuracy: 0.8373\n",
      "Epoch 60/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2321 - acc: 0.9002 - weighted_accuracy: 0.8810 - val_loss: 0.3207 - val_acc: 0.8549 - val_weighted_accuracy: 0.8395\n",
      "Epoch 61/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2318 - acc: 0.8999 - weighted_accuracy: 0.8809 - val_loss: 0.3240 - val_acc: 0.8549 - val_weighted_accuracy: 0.8396\n",
      "Epoch 62/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2330 - acc: 0.8992 - weighted_accuracy: 0.8807 - val_loss: 0.3275 - val_acc: 0.8507 - val_weighted_accuracy: 0.8358\n",
      "Epoch 63/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2316 - acc: 0.8993 - weighted_accuracy: 0.8801 - val_loss: 0.3334 - val_acc: 0.8529 - val_weighted_accuracy: 0.8384\n",
      "Epoch 64/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2320 - acc: 0.8996 - weighted_accuracy: 0.8806 - val_loss: 0.3176 - val_acc: 0.8563 - val_weighted_accuracy: 0.8405\n",
      "Epoch 65/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2312 - acc: 0.9000 - weighted_accuracy: 0.8812 - val_loss: 0.3281 - val_acc: 0.8502 - val_weighted_accuracy: 0.8383\n",
      "Epoch 66/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2311 - acc: 0.9003 - weighted_accuracy: 0.8813 - val_loss: 0.3190 - val_acc: 0.8546 - val_weighted_accuracy: 0.8397\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 50, 151)      0           embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 50, 151)      0           embedding_19[1][0]               \n",
      "                                                                 embedding_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 50, 151)      0           concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 50, 151)      0           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_25 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 50, 42)       0           cu_dnngru_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_97 (Dot)                    (None, 50, 50)       0           dropout_59[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_33 (Permute)            (None, 50, 50)       0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 50, 50)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_99 (Dot)                    (None, 50, 42)       0           permute_33[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_98 (Dot)                    (None, 50, 42)       0           lambda_75[0][0]                  \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 50, 235)      0           dropout_59[0][0]                 \n",
      "                                                                 dot_99[0][0]                     \n",
      "                                                                 spatial_dropout1d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 50, 235)      0           dropout_60[0][0]                 \n",
      "                                                                 dot_98[0][0]                     \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_26 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_129[0][0]            \n",
      "                                                                 concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 50, 42)       0           cu_dnngru_26[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_100 (Dot)                   (None, 50, 50)       0           dropout_61[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_34 (Permute)            (None, 50, 50)       0           lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 50, 50)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_102 (Dot)                   (None, 50, 42)       0           permute_34[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 50, 42)       0           lambda_77[0][0]                  \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 50, 319)      0           dropout_61[0][0]                 \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 50, 319)      0           dropout_62[0][0]                 \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_27 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_131[0][0]            \n",
      "                                                                 concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 50, 42)       0           cu_dnngru_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_103 (Dot)                   (None, 50, 50)       0           dropout_63[0][0]                 \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_35 (Permute)            (None, 50, 50)       0           lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 50, 50)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_105 (Dot)                   (None, 50, 42)       0           permute_35[0][0]                 \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_104 (Dot)                   (None, 50, 42)       0           lambda_79[0][0]                  \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 50, 252)      0           dot_99[0][0]                     \n",
      "                                                                 dropout_59[0][0]                 \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 dropout_61[0][0]                 \n",
      "                                                                 dot_105[0][0]                    \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 50, 252)      0           dot_98[0][0]                     \n",
      "                                                                 dropout_60[0][0]                 \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 dropout_62[0][0]                 \n",
      "                                                                 dot_104[0][0]                    \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 252)          0           concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 252)          0           concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 252)          0           concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 252)          0           concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 504)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 504)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 504)          0           concatenate_137[0][0]            \n",
      "                                                                 concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 504)          0           concatenate_137[0][0]            \n",
      "                                                                 concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 2016)         0           concatenate_137[0][0]            \n",
      "                                                                 concatenate_138[0][0]            \n",
      "                                                                 lambda_81[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 2016)         0           concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          516352      dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            771         dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 113s 404us/step - loss: 0.3510 - acc: 0.8365 - weighted_accuracy: 0.8063 - val_loss: 0.3653 - val_acc: 0.8270 - val_weighted_accuracy: 0.8006\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.3051 - acc: 0.8607 - weighted_accuracy: 0.8353 - val_loss: 0.3511 - val_acc: 0.8334 - val_weighted_accuracy: 0.8116\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2898 - acc: 0.8698 - weighted_accuracy: 0.8461 - val_loss: 0.3359 - val_acc: 0.8430 - val_weighted_accuracy: 0.8193\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2820 - acc: 0.8742 - weighted_accuracy: 0.8506 - val_loss: 0.3371 - val_acc: 0.8429 - val_weighted_accuracy: 0.8124\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2749 - acc: 0.8777 - weighted_accuracy: 0.8547 - val_loss: 0.3392 - val_acc: 0.8430 - val_weighted_accuracy: 0.8238\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2708 - acc: 0.8804 - weighted_accuracy: 0.8582 - val_loss: 0.3401 - val_acc: 0.8404 - val_weighted_accuracy: 0.8199\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2664 - acc: 0.8828 - weighted_accuracy: 0.8606 - val_loss: 0.3346 - val_acc: 0.8453 - val_weighted_accuracy: 0.8178\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2636 - acc: 0.8843 - weighted_accuracy: 0.8625 - val_loss: 0.3420 - val_acc: 0.8406 - val_weighted_accuracy: 0.8178\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2605 - acc: 0.8857 - weighted_accuracy: 0.8644 - val_loss: 0.3325 - val_acc: 0.8485 - val_weighted_accuracy: 0.8207\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2576 - acc: 0.8871 - weighted_accuracy: 0.8661 - val_loss: 0.3459 - val_acc: 0.8474 - val_weighted_accuracy: 0.8193\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2570 - acc: 0.8882 - weighted_accuracy: 0.8672 - val_loss: 0.3377 - val_acc: 0.8461 - val_weighted_accuracy: 0.8184\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2542 - acc: 0.8889 - weighted_accuracy: 0.8679 - val_loss: 0.3337 - val_acc: 0.8471 - val_weighted_accuracy: 0.8212\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2534 - acc: 0.8894 - weighted_accuracy: 0.8689 - val_loss: 0.3478 - val_acc: 0.8382 - val_weighted_accuracy: 0.8167\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2524 - acc: 0.8892 - weighted_accuracy: 0.8687 - val_loss: 0.3442 - val_acc: 0.8421 - val_weighted_accuracy: 0.8198\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2500 - acc: 0.8909 - weighted_accuracy: 0.8705 - val_loss: 0.3487 - val_acc: 0.8439 - val_weighted_accuracy: 0.8211\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2490 - acc: 0.8915 - weighted_accuracy: 0.8717 - val_loss: 0.3481 - val_acc: 0.8450 - val_weighted_accuracy: 0.8154\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2486 - acc: 0.8915 - weighted_accuracy: 0.8715 - val_loss: 0.3537 - val_acc: 0.8439 - val_weighted_accuracy: 0.8162\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2477 - acc: 0.8915 - weighted_accuracy: 0.8720 - val_loss: 0.3477 - val_acc: 0.8401 - val_weighted_accuracy: 0.8194\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2464 - acc: 0.8931 - weighted_accuracy: 0.8734 - val_loss: 0.3411 - val_acc: 0.8443 - val_weighted_accuracy: 0.8220\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2464 - acc: 0.8925 - weighted_accuracy: 0.8729 - val_loss: 0.3403 - val_acc: 0.8434 - val_weighted_accuracy: 0.8261\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2454 - acc: 0.8928 - weighted_accuracy: 0.8733 - val_loss: 0.3439 - val_acc: 0.8429 - val_weighted_accuracy: 0.8205\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2448 - acc: 0.8940 - weighted_accuracy: 0.8743 - val_loss: 0.3463 - val_acc: 0.8453 - val_weighted_accuracy: 0.8199\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2444 - acc: 0.8936 - weighted_accuracy: 0.8740 - val_loss: 0.3482 - val_acc: 0.8460 - val_weighted_accuracy: 0.8197\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2431 - acc: 0.8945 - weighted_accuracy: 0.8751 - val_loss: 0.3467 - val_acc: 0.8452 - val_weighted_accuracy: 0.8242\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2429 - acc: 0.8941 - weighted_accuracy: 0.8747 - val_loss: 0.3423 - val_acc: 0.8450 - val_weighted_accuracy: 0.8206\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2425 - acc: 0.8949 - weighted_accuracy: 0.8755 - val_loss: 0.3499 - val_acc: 0.8424 - val_weighted_accuracy: 0.8197\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2429 - acc: 0.8946 - weighted_accuracy: 0.8755 - val_loss: 0.3509 - val_acc: 0.8371 - val_weighted_accuracy: 0.8190\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2411 - acc: 0.8951 - weighted_accuracy: 0.8757 - val_loss: 0.3536 - val_acc: 0.8443 - val_weighted_accuracy: 0.8190\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2410 - acc: 0.8952 - weighted_accuracy: 0.8758 - val_loss: 0.3458 - val_acc: 0.8461 - val_weighted_accuracy: 0.8204\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2402 - acc: 0.8957 - weighted_accuracy: 0.8764 - val_loss: 0.3442 - val_acc: 0.8432 - val_weighted_accuracy: 0.8193\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2400 - acc: 0.8955 - weighted_accuracy: 0.8765 - val_loss: 0.3563 - val_acc: 0.8424 - val_weighted_accuracy: 0.8212\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2396 - acc: 0.8956 - weighted_accuracy: 0.8767 - val_loss: 0.3562 - val_acc: 0.8439 - val_weighted_accuracy: 0.8169\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2391 - acc: 0.8959 - weighted_accuracy: 0.8769 - val_loss: 0.3620 - val_acc: 0.8430 - val_weighted_accuracy: 0.8159\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2386 - acc: 0.8960 - weighted_accuracy: 0.8766 - val_loss: 0.3511 - val_acc: 0.8402 - val_weighted_accuracy: 0.8161\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 50, 151)      0           embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 50, 151)      0           embedding_21[1][0]               \n",
      "                                                                 embedding_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 50, 151)      0           concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 50, 151)      0           concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_28 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 50, 42)       0           cu_dnngru_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 50, 42)       0           cu_dnngru_28[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_106 (Dot)                   (None, 50, 50)       0           dropout_66[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 50, 50)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_36 (Permute)            (None, 50, 50)       0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 50, 50)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_108 (Dot)                   (None, 50, 42)       0           permute_36[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_107 (Dot)                   (None, 50, 42)       0           lambda_82[0][0]                  \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 50, 235)      0           dropout_66[0][0]                 \n",
      "                                                                 dot_108[0][0]                    \n",
      "                                                                 spatial_dropout1d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 50, 235)      0           dropout_67[0][0]                 \n",
      "                                                                 dot_107[0][0]                    \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_29 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_142[0][0]            \n",
      "                                                                 concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 50, 42)       0           cu_dnngru_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 50, 42)       0           cu_dnngru_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_109 (Dot)                   (None, 50, 50)       0           dropout_68[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 50, 50)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_37 (Permute)            (None, 50, 50)       0           lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 50, 50)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_111 (Dot)                   (None, 50, 42)       0           permute_37[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_110 (Dot)                   (None, 50, 42)       0           lambda_84[0][0]                  \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 50, 319)      0           dropout_68[0][0]                 \n",
      "                                                                 dot_111[0][0]                    \n",
      "                                                                 concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 50, 319)      0           dropout_69[0][0]                 \n",
      "                                                                 dot_110[0][0]                    \n",
      "                                                                 concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_30 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_144[0][0]            \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 50, 42)       0           cu_dnngru_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 50, 42)       0           cu_dnngru_30[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_112 (Dot)                   (None, 50, 50)       0           dropout_70[0][0]                 \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 50, 50)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_38 (Permute)            (None, 50, 50)       0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 50, 50)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_114 (Dot)                   (None, 50, 42)       0           permute_38[0][0]                 \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_113 (Dot)                   (None, 50, 42)       0           lambda_86[0][0]                  \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 50, 252)      0           dot_108[0][0]                    \n",
      "                                                                 dropout_66[0][0]                 \n",
      "                                                                 dot_111[0][0]                    \n",
      "                                                                 dropout_68[0][0]                 \n",
      "                                                                 dot_114[0][0]                    \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 50, 252)      0           dot_107[0][0]                    \n",
      "                                                                 dropout_67[0][0]                 \n",
      "                                                                 dot_110[0][0]                    \n",
      "                                                                 dropout_69[0][0]                 \n",
      "                                                                 dot_113[0][0]                    \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 252)          0           concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 252)          0           concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 252)          0           concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 252)          0           concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 504)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 504)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 504)          0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 504)          0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 2016)         0           concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "                                                                 lambda_88[0][0]                  \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 2016)         0           concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          516352      dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 3)            771         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 114s 405us/step - loss: 0.3540 - acc: 0.8354 - weighted_accuracy: 0.8046 - val_loss: 0.3393 - val_acc: 0.8415 - val_weighted_accuracy: 0.8268\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.3091 - acc: 0.8587 - weighted_accuracy: 0.8337 - val_loss: 0.3114 - val_acc: 0.8584 - val_weighted_accuracy: 0.8395\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2960 - acc: 0.8664 - weighted_accuracy: 0.8424 - val_loss: 0.3065 - val_acc: 0.8579 - val_weighted_accuracy: 0.8431\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2865 - acc: 0.8714 - weighted_accuracy: 0.8480 - val_loss: 0.3131 - val_acc: 0.8554 - val_weighted_accuracy: 0.8397\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2802 - acc: 0.8754 - weighted_accuracy: 0.8524 - val_loss: 0.3115 - val_acc: 0.8578 - val_weighted_accuracy: 0.8470\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2746 - acc: 0.8788 - weighted_accuracy: 0.8561 - val_loss: 0.2943 - val_acc: 0.8667 - val_weighted_accuracy: 0.8484\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2716 - acc: 0.8800 - weighted_accuracy: 0.8576 - val_loss: 0.3052 - val_acc: 0.8621 - val_weighted_accuracy: 0.8454\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2674 - acc: 0.8822 - weighted_accuracy: 0.8606 - val_loss: 0.2995 - val_acc: 0.8649 - val_weighted_accuracy: 0.8542\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2650 - acc: 0.8834 - weighted_accuracy: 0.8615 - val_loss: 0.2916 - val_acc: 0.8681 - val_weighted_accuracy: 0.8444\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2626 - acc: 0.8841 - weighted_accuracy: 0.8626 - val_loss: 0.2969 - val_acc: 0.8641 - val_weighted_accuracy: 0.8477\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2610 - acc: 0.8853 - weighted_accuracy: 0.8640 - val_loss: 0.2969 - val_acc: 0.8650 - val_weighted_accuracy: 0.8455\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2583 - acc: 0.8869 - weighted_accuracy: 0.8661 - val_loss: 0.2944 - val_acc: 0.8672 - val_weighted_accuracy: 0.8517\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2569 - acc: 0.8874 - weighted_accuracy: 0.8665 - val_loss: 0.2990 - val_acc: 0.8652 - val_weighted_accuracy: 0.8502\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2563 - acc: 0.8882 - weighted_accuracy: 0.8676 - val_loss: 0.3022 - val_acc: 0.8653 - val_weighted_accuracy: 0.8543\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2544 - acc: 0.8886 - weighted_accuracy: 0.8679 - val_loss: 0.3044 - val_acc: 0.8637 - val_weighted_accuracy: 0.8532\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2539 - acc: 0.8895 - weighted_accuracy: 0.8691 - val_loss: 0.2949 - val_acc: 0.8677 - val_weighted_accuracy: 0.8493\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2525 - acc: 0.8898 - weighted_accuracy: 0.8692 - val_loss: 0.3005 - val_acc: 0.8650 - val_weighted_accuracy: 0.8534\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2512 - acc: 0.8905 - weighted_accuracy: 0.8707 - val_loss: 0.3018 - val_acc: 0.8636 - val_weighted_accuracy: 0.8542\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2507 - acc: 0.8906 - weighted_accuracy: 0.8700 - val_loss: 0.2986 - val_acc: 0.8649 - val_weighted_accuracy: 0.8525\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2502 - acc: 0.8911 - weighted_accuracy: 0.8707 - val_loss: 0.2947 - val_acc: 0.8665 - val_weighted_accuracy: 0.8446\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2486 - acc: 0.8918 - weighted_accuracy: 0.8718 - val_loss: 0.3010 - val_acc: 0.8666 - val_weighted_accuracy: 0.8567\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2485 - acc: 0.8910 - weighted_accuracy: 0.8709 - val_loss: 0.2945 - val_acc: 0.8678 - val_weighted_accuracy: 0.8545\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2480 - acc: 0.8920 - weighted_accuracy: 0.8721 - val_loss: 0.2979 - val_acc: 0.8677 - val_weighted_accuracy: 0.8532\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2472 - acc: 0.8923 - weighted_accuracy: 0.8719 - val_loss: 0.3057 - val_acc: 0.8639 - val_weighted_accuracy: 0.8521\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2465 - acc: 0.8929 - weighted_accuracy: 0.8730 - val_loss: 0.2941 - val_acc: 0.8683 - val_weighted_accuracy: 0.8524\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2454 - acc: 0.8938 - weighted_accuracy: 0.8741 - val_loss: 0.3035 - val_acc: 0.8659 - val_weighted_accuracy: 0.8549\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2448 - acc: 0.8931 - weighted_accuracy: 0.8734 - val_loss: 0.2951 - val_acc: 0.8677 - val_weighted_accuracy: 0.8505\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2446 - acc: 0.8932 - weighted_accuracy: 0.8738 - val_loss: 0.3018 - val_acc: 0.8664 - val_weighted_accuracy: 0.8548\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2446 - acc: 0.8940 - weighted_accuracy: 0.8738 - val_loss: 0.3102 - val_acc: 0.8611 - val_weighted_accuracy: 0.8504\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2437 - acc: 0.8938 - weighted_accuracy: 0.8742 - val_loss: 0.3047 - val_acc: 0.8664 - val_weighted_accuracy: 0.8510\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2428 - acc: 0.8946 - weighted_accuracy: 0.8750 - val_loss: 0.3145 - val_acc: 0.8623 - val_weighted_accuracy: 0.8517\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2430 - acc: 0.8939 - weighted_accuracy: 0.8739 - val_loss: 0.3011 - val_acc: 0.8670 - val_weighted_accuracy: 0.8511\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2427 - acc: 0.8946 - weighted_accuracy: 0.8746 - val_loss: 0.2995 - val_acc: 0.8681 - val_weighted_accuracy: 0.8510\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2422 - acc: 0.8941 - weighted_accuracy: 0.8748 - val_loss: 0.3040 - val_acc: 0.8674 - val_weighted_accuracy: 0.8501\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 50, 1)        2           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 50, 151)      0           embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 50, 151)      0           embedding_23[1][0]               \n",
      "                                                                 embedding_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 50, 151)      0           concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 50, 151)      0           concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_31 (CuDNNGRU)         (None, 50, 42)       24570       spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 50, 42)       0           cu_dnngru_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 50, 42)       0           cu_dnngru_31[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_115 (Dot)                   (None, 50, 50)       0           dropout_73[0][0]                 \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_39 (Permute)            (None, 50, 50)       0           lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 50, 50)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_117 (Dot)                   (None, 50, 42)       0           permute_39[0][0]                 \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_116 (Dot)                   (None, 50, 42)       0           lambda_89[0][0]                  \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 50, 235)      0           dropout_73[0][0]                 \n",
      "                                                                 dot_117[0][0]                    \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 50, 235)      0           dropout_74[0][0]                 \n",
      "                                                                 dot_116[0][0]                    \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_32 (CuDNNGRU)         (None, 50, 42)       35154       concatenate_155[0][0]            \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 50, 42)       0           cu_dnngru_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 50, 42)       0           cu_dnngru_32[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_118 (Dot)                   (None, 50, 50)       0           dropout_75[0][0]                 \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_40 (Permute)            (None, 50, 50)       0           lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 50, 50)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_120 (Dot)                   (None, 50, 42)       0           permute_40[0][0]                 \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_119 (Dot)                   (None, 50, 42)       0           lambda_91[0][0]                  \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 50, 319)      0           dropout_75[0][0]                 \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 50, 319)      0           dropout_76[0][0]                 \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_33 (CuDNNGRU)         (None, 50, 42)       45738       concatenate_157[0][0]            \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 50, 42)       0           cu_dnngru_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 50, 42)       0           cu_dnngru_33[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_121 (Dot)                   (None, 50, 50)       0           dropout_77[0][0]                 \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_41 (Permute)            (None, 50, 50)       0           lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 50, 50)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_123 (Dot)                   (None, 50, 42)       0           permute_41[0][0]                 \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_122 (Dot)                   (None, 50, 42)       0           lambda_93[0][0]                  \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 50, 252)      0           dot_117[0][0]                    \n",
      "                                                                 dropout_73[0][0]                 \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 dropout_75[0][0]                 \n",
      "                                                                 dot_123[0][0]                    \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 50, 252)      0           dot_116[0][0]                    \n",
      "                                                                 dropout_74[0][0]                 \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 dropout_76[0][0]                 \n",
      "                                                                 dot_122[0][0]                    \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 252)          0           concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 252)          0           concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 252)          0           concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 252)          0           concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 504)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 504)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 504)          0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 504)          0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 2016)         0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "                                                                 lambda_95[0][0]                  \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 2016)         0           concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          516352      dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 3)            771         dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,372,587\n",
      "Trainable params: 622,587\n",
      "Non-trainable params: 750,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 114s 408us/step - loss: 0.3581 - acc: 0.8331 - weighted_accuracy: 0.8034 - val_loss: 0.3792 - val_acc: 0.8137 - val_weighted_accuracy: 0.8001\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.3113 - acc: 0.8579 - weighted_accuracy: 0.8336 - val_loss: 0.3087 - val_acc: 0.8546 - val_weighted_accuracy: 0.8242\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2969 - acc: 0.8664 - weighted_accuracy: 0.8429 - val_loss: 0.3083 - val_acc: 0.8610 - val_weighted_accuracy: 0.8352\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2891 - acc: 0.8703 - weighted_accuracy: 0.8472 - val_loss: 0.3101 - val_acc: 0.8556 - val_weighted_accuracy: 0.8453\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2818 - acc: 0.8741 - weighted_accuracy: 0.8518 - val_loss: 0.2893 - val_acc: 0.8703 - val_weighted_accuracy: 0.8488\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 113s 401us/step - loss: 0.2764 - acc: 0.8767 - weighted_accuracy: 0.8552 - val_loss: 0.2933 - val_acc: 0.8663 - val_weighted_accuracy: 0.8477\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 112s 401us/step - loss: 0.2729 - acc: 0.8787 - weighted_accuracy: 0.8574 - val_loss: 0.2849 - val_acc: 0.8739 - val_weighted_accuracy: 0.8474\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2701 - acc: 0.8801 - weighted_accuracy: 0.8590 - val_loss: 0.2855 - val_acc: 0.8709 - val_weighted_accuracy: 0.8515\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 112s 401us/step - loss: 0.2671 - acc: 0.8818 - weighted_accuracy: 0.8607 - val_loss: 0.2861 - val_acc: 0.8702 - val_weighted_accuracy: 0.8479\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 112s 399us/step - loss: 0.2636 - acc: 0.8844 - weighted_accuracy: 0.8634 - val_loss: 0.3021 - val_acc: 0.8616 - val_weighted_accuracy: 0.8481\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2622 - acc: 0.8848 - weighted_accuracy: 0.8642 - val_loss: 0.2845 - val_acc: 0.8717 - val_weighted_accuracy: 0.8505\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 112s 400us/step - loss: 0.2607 - acc: 0.8856 - weighted_accuracy: 0.8648 - val_loss: 0.2814 - val_acc: 0.8760 - val_weighted_accuracy: 0.8513\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 114s 405us/step - loss: 0.2575 - acc: 0.8868 - weighted_accuracy: 0.8661 - val_loss: 0.2861 - val_acc: 0.8709 - val_weighted_accuracy: 0.8489\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2570 - acc: 0.8880 - weighted_accuracy: 0.8675 - val_loss: 0.2839 - val_acc: 0.8743 - val_weighted_accuracy: 0.8475\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2562 - acc: 0.8880 - weighted_accuracy: 0.8679 - val_loss: 0.2932 - val_acc: 0.8698 - val_weighted_accuracy: 0.8556\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2537 - acc: 0.8892 - weighted_accuracy: 0.8691 - val_loss: 0.2848 - val_acc: 0.8728 - val_weighted_accuracy: 0.8544\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2531 - acc: 0.8892 - weighted_accuracy: 0.8693 - val_loss: 0.2839 - val_acc: 0.8747 - val_weighted_accuracy: 0.8562\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2516 - acc: 0.8895 - weighted_accuracy: 0.8699 - val_loss: 0.2855 - val_acc: 0.8717 - val_weighted_accuracy: 0.8527\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2513 - acc: 0.8901 - weighted_accuracy: 0.8705 - val_loss: 0.2812 - val_acc: 0.8737 - val_weighted_accuracy: 0.8520\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 111s 397us/step - loss: 0.2506 - acc: 0.8902 - weighted_accuracy: 0.8705 - val_loss: 0.2812 - val_acc: 0.8731 - val_weighted_accuracy: 0.8576\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2492 - acc: 0.8912 - weighted_accuracy: 0.8721 - val_loss: 0.2892 - val_acc: 0.8699 - val_weighted_accuracy: 0.8504\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2493 - acc: 0.8912 - weighted_accuracy: 0.8717 - val_loss: 0.2897 - val_acc: 0.8742 - val_weighted_accuracy: 0.8527\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2489 - acc: 0.8914 - weighted_accuracy: 0.8720 - val_loss: 0.2898 - val_acc: 0.8722 - val_weighted_accuracy: 0.8501\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 112s 398us/step - loss: 0.2476 - acc: 0.8920 - weighted_accuracy: 0.8727 - val_loss: 0.2862 - val_acc: 0.8735 - val_weighted_accuracy: 0.8521\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2470 - acc: 0.8925 - weighted_accuracy: 0.8732 - val_loss: 0.2793 - val_acc: 0.8755 - val_weighted_accuracy: 0.8559\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2464 - acc: 0.8924 - weighted_accuracy: 0.8730 - val_loss: 0.2930 - val_acc: 0.8686 - val_weighted_accuracy: 0.8530\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2449 - acc: 0.8931 - weighted_accuracy: 0.8736 - val_loss: 0.2916 - val_acc: 0.8720 - val_weighted_accuracy: 0.8541\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2456 - acc: 0.8927 - weighted_accuracy: 0.8729 - val_loss: 0.2883 - val_acc: 0.8711 - val_weighted_accuracy: 0.8550\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2446 - acc: 0.8934 - weighted_accuracy: 0.8742 - val_loss: 0.2879 - val_acc: 0.8748 - val_weighted_accuracy: 0.8558\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2443 - acc: 0.8934 - weighted_accuracy: 0.8740 - val_loss: 0.2875 - val_acc: 0.8739 - val_weighted_accuracy: 0.8535\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2435 - acc: 0.8939 - weighted_accuracy: 0.8750 - val_loss: 0.2837 - val_acc: 0.8753 - val_weighted_accuracy: 0.8529\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2435 - acc: 0.8943 - weighted_accuracy: 0.8752 - val_loss: 0.2917 - val_acc: 0.8696 - val_weighted_accuracy: 0.8529\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2425 - acc: 0.8945 - weighted_accuracy: 0.8757 - val_loss: 0.2951 - val_acc: 0.8702 - val_weighted_accuracy: 0.8504\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2424 - acc: 0.8947 - weighted_accuracy: 0.8758 - val_loss: 0.2919 - val_acc: 0.8730 - val_weighted_accuracy: 0.8557\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2422 - acc: 0.8943 - weighted_accuracy: 0.8752 - val_loss: 0.2900 - val_acc: 0.8725 - val_weighted_accuracy: 0.8543\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2420 - acc: 0.8946 - weighted_accuracy: 0.8760 - val_loss: 0.2852 - val_acc: 0.8748 - val_weighted_accuracy: 0.8558\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2412 - acc: 0.8947 - weighted_accuracy: 0.8756 - val_loss: 0.2829 - val_acc: 0.8762 - val_weighted_accuracy: 0.8592\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2420 - acc: 0.8944 - weighted_accuracy: 0.8753 - val_loss: 0.2865 - val_acc: 0.8760 - val_weighted_accuracy: 0.8541\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2409 - acc: 0.8956 - weighted_accuracy: 0.8768 - val_loss: 0.3121 - val_acc: 0.8639 - val_weighted_accuracy: 0.8505\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 111s 396us/step - loss: 0.2413 - acc: 0.8956 - weighted_accuracy: 0.8769 - val_loss: 0.2888 - val_acc: 0.8743 - val_weighted_accuracy: 0.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2409 - acc: 0.8950 - weighted_accuracy: 0.8765 - val_loss: 0.2874 - val_acc: 0.8749 - val_weighted_accuracy: 0.8573\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2405 - acc: 0.8957 - weighted_accuracy: 0.8767 - val_loss: 0.2956 - val_acc: 0.8744 - val_weighted_accuracy: 0.8546\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2405 - acc: 0.8954 - weighted_accuracy: 0.8763 - val_loss: 0.2984 - val_acc: 0.8721 - val_weighted_accuracy: 0.8519\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 111s 394us/step - loss: 0.2401 - acc: 0.8954 - weighted_accuracy: 0.8763 - val_loss: 0.2901 - val_acc: 0.8740 - val_weighted_accuracy: 0.8563\n",
      "Epoch 45/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2403 - acc: 0.8953 - weighted_accuracy: 0.8762 - val_loss: 0.2855 - val_acc: 0.8761 - val_weighted_accuracy: 0.8561\n",
      "Epoch 46/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2392 - acc: 0.8955 - weighted_accuracy: 0.8763 - val_loss: 0.2866 - val_acc: 0.8743 - val_weighted_accuracy: 0.8548\n",
      "Epoch 47/500\n",
      "280483/280483 [==============================] - 110s 393us/step - loss: 0.2395 - acc: 0.8959 - weighted_accuracy: 0.8765 - val_loss: 0.2891 - val_acc: 0.8753 - val_weighted_accuracy: 0.8558\n",
      "Epoch 48/500\n",
      "280483/280483 [==============================] - 110s 392us/step - loss: 0.2396 - acc: 0.8962 - weighted_accuracy: 0.8774 - val_loss: 0.2867 - val_acc: 0.8744 - val_weighted_accuracy: 0.8510\n",
      "Epoch 49/500\n",
      "280483/280483 [==============================] - 110s 394us/step - loss: 0.2376 - acc: 0.8966 - weighted_accuracy: 0.8778 - val_loss: 0.2833 - val_acc: 0.8770 - val_weighted_accuracy: 0.8590\n",
      "Epoch 50/500\n",
      "280483/280483 [==============================] - 111s 395us/step - loss: 0.2387 - acc: 0.8961 - weighted_accuracy: 0.8774 - val_loss: 0.2965 - val_acc: 0.8714 - val_weighted_accuracy: 0.8532\n",
      "score 0.8165832361817097\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 11s 138us/step\n",
      "80126/80126 [==============================] - 11s 140us/step\n",
      "80126/80126 [==============================] - 11s 140us/step\n",
      "80126/80126 [==============================] - 11s 139us/step\n",
      "80126/80126 [==============================] - 11s 139us/step\n",
      "80126/80126 [==============================] - 11s 139us/step\n",
      "80126/80126 [==============================] - 11s 139us/step\n",
      "80126/80126 [==============================] - 11s 138us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_darnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=25)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/oofs/\"\n",
    "    output_dir = \"../data/output/\"\n",
    "    onehot_pred_dir = \"../data/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"3Embedding-3LayersDenseRNN42-Drop01-NoMeta-NoClassWeighted-WithEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    meta_features_input = Input(shape=(36,), name='mata-features')\n",
    "    \n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    flex_embedding = Embedding(nb_words, 20,\n",
    "                      input_length=max_sequence_length,\n",
    "                      trainable=True)\n",
    "    \n",
    "    em_embeddings = Reshape((max_sequence_length, 1))\n",
    "    \n",
    "    q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match),])\n",
    "    q1_encoded = SpatialDropout1D(0.2)(q1_embed)\n",
    "    \n",
    "    q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match),])\n",
    "    q2_encoded = SpatialDropout1D(0.2)(q2_embed)\n",
    "\n",
    "\n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    nb_filters = 64\n",
    "    \n",
    "    cnns = [Conv1D(64, 1, strides=1, padding='same', activation='relu') for i in range(3)]\n",
    "    gates_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='tanh') for i in range(3)]\n",
    "    sigm_cnns = [Conv1D(nb_filters, 3, dilation_rate=1, padding='same', activation='sigmoid') for i in range(3)]\n",
    "    \n",
    "    for i in range(len(cnns)):\n",
    "        drop = Dropout(0.1)\n",
    "        q1_t = gates_cnns[i](q1_encoded)\n",
    "        q2_t = gates_cnns[i](q2_encoded)    \n",
    "        \n",
    "        q1_s = sigm_cnns[i](q1_encoded)\n",
    "        q2_s = sigm_cnns[i](q2_encoded)        \n",
    "        \n",
    "        q1_x = Multiply()([q1_t, q1_s])\n",
    "        q1_x = cnns[i](q1_x)\n",
    "        q1_x = drop(q1_x)\n",
    "        \n",
    "        q2_x = Multiply()([q2_t, q2_s])\n",
    "        q2_x = cnns[i](q2_x)\n",
    "        q2_x = drop(q2_x)\n",
    "\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_x, q2_x)\n",
    "        q1_encoded = Concatenate()([q1_x, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_x, q1_aligned, q2_encoded]) \n",
    "    \n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    attn = AttentionWeightedAverage()\n",
    "    \n",
    "    \n",
    "    q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])\n",
    "    q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])    \n",
    "    \n",
    "    \n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    #drops = Dropout(0.3)\n",
    "    #q1_rep = shrink(drops(q1_rep))\n",
    "    #q2_rep = shrink(drops(q2_rep))\n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    #h_all = Dropout(0.35)(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)    \n",
    "    h_all = Dense(64, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-6))(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, meta_features_input, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 151)      0           embedding_1[0][0]                \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 50, 151)      0           embedding_1[1][0]                \n",
      "                                                                 reshape_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 50, 151)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 50, 151)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 50, 64)       29056       spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 50, 64)       29056       spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 50, 64)       0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 50, 64)       0           conv1d_4[1][0]                   \n",
      "                                                                 conv1d_7[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 64)       4160        multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 64)       0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 50, 50)       0           dropout_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 50, 50)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 50, 64)       0           permute_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 50, 64)       0           lambda_1[0][0]                   \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 279)      0           dropout_1[0][0]                  \n",
      "                                                                 dot_3[0][0]                      \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 50, 279)      0           dropout_1[1][0]                  \n",
      "                                                                 dot_2[0][0]                      \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 50, 64)       53632       concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 50, 64)       53632       concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 50, 64)       0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 50, 64)       0           conv1d_5[1][0]                   \n",
      "                                                                 conv1d_8[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 64)       4160        multiply_3[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 64)       0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 50, 50)       0           dropout_2[0][0]                  \n",
      "                                                                 dropout_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 50, 50)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 50, 50)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 50, 50)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 50, 64)       0           permute_2[0][0]                  \n",
      "                                                                 dropout_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 50, 64)       0           lambda_3[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 50, 407)      0           dropout_2[0][0]                  \n",
      "                                                                 dot_6[0][0]                      \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 50, 407)      0           dropout_2[1][0]                  \n",
      "                                                                 dot_5[0][0]                      \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 50, 64)       78208       concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 50, 64)       78208       concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 50, 64)       0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 50, 64)       0           conv1d_6[1][0]                   \n",
      "                                                                 conv1d_9[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 64)       4160        multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50, 64)       0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 50, 50)       0           dropout_3[0][0]                  \n",
      "                                                                 dropout_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50, 50)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 50, 50)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50, 50)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 50, 64)       0           permute_3[0][0]                  \n",
      "                                                                 dropout_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 50, 64)       0           lambda_5[0][0]                   \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 50, 535)      0           dropout_3[0][0]                  \n",
      "                                                                 dot_9[0][0]                      \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 50, 535)      0           dropout_3[1][0]                  \n",
      "                                                                 dot_8[0][0]                      \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 535)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 535)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_1 (A (None, 535)          535         concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 535)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 535)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1605)         0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 attention_weighted_average_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1605)         0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 attention_weighted_average_1[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1605)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1605)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 6420)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6420)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 6420)         25680       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           410944      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 64s 228us/step - loss: 0.4104 - acc: 0.8121 - weighted_accuracy: 0.7840 - val_loss: 0.3446 - val_acc: 0.8413 - val_weighted_accuracy: 0.8235\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 62s 222us/step - loss: 0.3270 - acc: 0.8504 - weighted_accuracy: 0.8256 - val_loss: 0.3129 - val_acc: 0.8562 - val_weighted_accuracy: 0.8316\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 61s 216us/step - loss: 0.3045 - acc: 0.8634 - weighted_accuracy: 0.8399 - val_loss: 0.3083 - val_acc: 0.8614 - val_weighted_accuracy: 0.8374\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2914 - acc: 0.8692 - weighted_accuracy: 0.8460 - val_loss: 0.3200 - val_acc: 0.8530 - val_weighted_accuracy: 0.8371\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2819 - acc: 0.8740 - weighted_accuracy: 0.8515 - val_loss: 0.3092 - val_acc: 0.8596 - val_weighted_accuracy: 0.8415\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2745 - acc: 0.8785 - weighted_accuracy: 0.8568 - val_loss: 0.3025 - val_acc: 0.8631 - val_weighted_accuracy: 0.8404\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2676 - acc: 0.8820 - weighted_accuracy: 0.8605 - val_loss: 0.3094 - val_acc: 0.8613 - val_weighted_accuracy: 0.8445\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2623 - acc: 0.8853 - weighted_accuracy: 0.8646 - val_loss: 0.2996 - val_acc: 0.8654 - val_weighted_accuracy: 0.8438\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2574 - acc: 0.8874 - weighted_accuracy: 0.8667 - val_loss: 0.3014 - val_acc: 0.8673 - val_weighted_accuracy: 0.8400\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2534 - acc: 0.8892 - weighted_accuracy: 0.8690 - val_loss: 0.3060 - val_acc: 0.8640 - val_weighted_accuracy: 0.8433\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2502 - acc: 0.8908 - weighted_accuracy: 0.8707 - val_loss: 0.3080 - val_acc: 0.8627 - val_weighted_accuracy: 0.8422\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2467 - acc: 0.8923 - weighted_accuracy: 0.8726 - val_loss: 0.3043 - val_acc: 0.8652 - val_weighted_accuracy: 0.8402\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2436 - acc: 0.8942 - weighted_accuracy: 0.8744 - val_loss: 0.3026 - val_acc: 0.8670 - val_weighted_accuracy: 0.8432\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2410 - acc: 0.8957 - weighted_accuracy: 0.8764 - val_loss: 0.3073 - val_acc: 0.8660 - val_weighted_accuracy: 0.8442\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2375 - acc: 0.8975 - weighted_accuracy: 0.8792 - val_loss: 0.3066 - val_acc: 0.8674 - val_weighted_accuracy: 0.8453\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2362 - acc: 0.8986 - weighted_accuracy: 0.8799 - val_loss: 0.3083 - val_acc: 0.8627 - val_weighted_accuracy: 0.8352\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2334 - acc: 0.8999 - weighted_accuracy: 0.8820 - val_loss: 0.3104 - val_acc: 0.8657 - val_weighted_accuracy: 0.8432\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2322 - acc: 0.9006 - weighted_accuracy: 0.8825 - val_loss: 0.3066 - val_acc: 0.8671 - val_weighted_accuracy: 0.8456\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2294 - acc: 0.9015 - weighted_accuracy: 0.8838 - val_loss: 0.3066 - val_acc: 0.8680 - val_weighted_accuracy: 0.8417\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2278 - acc: 0.9023 - weighted_accuracy: 0.8846 - val_loss: 0.3055 - val_acc: 0.8653 - val_weighted_accuracy: 0.8433\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2262 - acc: 0.9036 - weighted_accuracy: 0.8860 - val_loss: 0.3010 - val_acc: 0.8689 - val_weighted_accuracy: 0.8474\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2245 - acc: 0.9042 - weighted_accuracy: 0.8867 - val_loss: 0.3062 - val_acc: 0.8665 - val_weighted_accuracy: 0.8468\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2223 - acc: 0.9048 - weighted_accuracy: 0.8877 - val_loss: 0.3096 - val_acc: 0.8654 - val_weighted_accuracy: 0.8427\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2217 - acc: 0.9050 - weighted_accuracy: 0.8878 - val_loss: 0.3064 - val_acc: 0.8685 - val_weighted_accuracy: 0.8478\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2198 - acc: 0.9058 - weighted_accuracy: 0.8889 - val_loss: 0.3038 - val_acc: 0.8715 - val_weighted_accuracy: 0.8453\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2185 - acc: 0.9069 - weighted_accuracy: 0.8900 - val_loss: 0.3063 - val_acc: 0.8686 - val_weighted_accuracy: 0.8444\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2180 - acc: 0.9071 - weighted_accuracy: 0.8899 - val_loss: 0.3051 - val_acc: 0.8685 - val_weighted_accuracy: 0.8458\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2167 - acc: 0.9080 - weighted_accuracy: 0.8907 - val_loss: 0.3120 - val_acc: 0.8673 - val_weighted_accuracy: 0.8432\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2154 - acc: 0.9083 - weighted_accuracy: 0.8916 - val_loss: 0.3061 - val_acc: 0.8703 - val_weighted_accuracy: 0.8472\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2147 - acc: 0.9086 - weighted_accuracy: 0.8921 - val_loss: 0.3103 - val_acc: 0.8688 - val_weighted_accuracy: 0.8430\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2140 - acc: 0.9092 - weighted_accuracy: 0.8929 - val_loss: 0.3051 - val_acc: 0.8689 - val_weighted_accuracy: 0.8477\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2124 - acc: 0.9096 - weighted_accuracy: 0.8934 - val_loss: 0.3111 - val_acc: 0.8668 - val_weighted_accuracy: 0.8465\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2119 - acc: 0.9100 - weighted_accuracy: 0.8939 - val_loss: 0.3113 - val_acc: 0.8680 - val_weighted_accuracy: 0.8463\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 50, 151)      0           embedding_3[0][0]                \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 50, 151)      0           embedding_3[1][0]                \n",
      "                                                                 reshape_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 50, 151)      0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 50, 151)      0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 50, 64)       0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 50, 64)       0           conv1d_13[1][0]                  \n",
      "                                                                 conv1d_16[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 50, 64)       4160        multiply_8[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 50, 64)       0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_10[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 50, 50)       0           dropout_5[0][0]                  \n",
      "                                                                 dropout_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 50, 50)       0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 50, 50)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_12 (Dot)                    (None, 50, 64)       0           permute_4[0][0]                  \n",
      "                                                                 dropout_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 50, 64)       0           lambda_8[0][0]                   \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 50, 279)      0           dropout_5[0][0]                  \n",
      "                                                                 dot_12[0][0]                     \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 50, 279)      0           dropout_5[1][0]                  \n",
      "                                                                 dot_11[0][0]                     \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 50, 64)       53632       concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 50, 64)       53632       concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 50, 64)       0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 50, 64)       0           conv1d_14[1][0]                  \n",
      "                                                                 conv1d_17[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 50, 64)       4160        multiply_10[0][0]                \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50, 64)       0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_11[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 50, 50)       0           dropout_6[0][0]                  \n",
      "                                                                 dropout_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 50, 50)       0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 50, 50)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 50, 64)       0           permute_5[0][0]                  \n",
      "                                                                 dropout_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 50, 64)       0           lambda_10[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 50, 407)      0           dropout_6[0][0]                  \n",
      "                                                                 dot_15[0][0]                     \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 50, 407)      0           dropout_6[1][0]                  \n",
      "                                                                 dot_14[0][0]                     \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 50, 64)       78208       concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 50, 64)       78208       concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 50, 64)       0           conv1d_15[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 50, 64)       0           conv1d_15[1][0]                  \n",
      "                                                                 conv1d_18[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 64)       4160        multiply_12[0][0]                \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 64)       0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_12[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_16 (Dot)                    (None, 50, 50)       0           dropout_7[0][0]                  \n",
      "                                                                 dropout_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 50, 50)       0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 50, 50)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 50, 64)       0           permute_6[0][0]                  \n",
      "                                                                 dropout_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 50, 64)       0           lambda_12[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 50, 535)      0           dropout_7[0][0]                  \n",
      "                                                                 dot_18[0][0]                     \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 50, 535)      0           dropout_7[1][0]                  \n",
      "                                                                 dot_17[0][0]                     \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 535)          0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 535)          0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 535)          535         concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 535)          0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 535)          0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 1605)         0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 attention_weighted_average_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 1605)         0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 attention_weighted_average_2[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1605)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 1605)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 6420)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 6420)         0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6420)         25680       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           410944      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            195         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 62s 220us/step - loss: 0.4205 - acc: 0.8097 - weighted_accuracy: 0.7804 - val_loss: 0.3354 - val_acc: 0.8391 - val_weighted_accuracy: 0.8200\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.3283 - acc: 0.8496 - weighted_accuracy: 0.8236 - val_loss: 0.3025 - val_acc: 0.8623 - val_weighted_accuracy: 0.8404\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3074 - acc: 0.8610 - weighted_accuracy: 0.8366 - val_loss: 0.2995 - val_acc: 0.8638 - val_weighted_accuracy: 0.8452\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2935 - acc: 0.8682 - weighted_accuracy: 0.8443 - val_loss: 0.2891 - val_acc: 0.8702 - val_weighted_accuracy: 0.8466\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2851 - acc: 0.8728 - weighted_accuracy: 0.8498 - val_loss: 0.2862 - val_acc: 0.8715 - val_weighted_accuracy: 0.8503\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2766 - acc: 0.8774 - weighted_accuracy: 0.8548 - val_loss: 0.2851 - val_acc: 0.8727 - val_weighted_accuracy: 0.8509\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2697 - acc: 0.8810 - weighted_accuracy: 0.8591 - val_loss: 0.2852 - val_acc: 0.8733 - val_weighted_accuracy: 0.8511\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2641 - acc: 0.8833 - weighted_accuracy: 0.8616 - val_loss: 0.2860 - val_acc: 0.8732 - val_weighted_accuracy: 0.8508\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2602 - acc: 0.8856 - weighted_accuracy: 0.8643 - val_loss: 0.2822 - val_acc: 0.8764 - val_weighted_accuracy: 0.8547\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2559 - acc: 0.8879 - weighted_accuracy: 0.8674 - val_loss: 0.2823 - val_acc: 0.8762 - val_weighted_accuracy: 0.8537\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2525 - acc: 0.8896 - weighted_accuracy: 0.8691 - val_loss: 0.2817 - val_acc: 0.8773 - val_weighted_accuracy: 0.8528\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2485 - acc: 0.8920 - weighted_accuracy: 0.8714 - val_loss: 0.2793 - val_acc: 0.8770 - val_weighted_accuracy: 0.8557\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2454 - acc: 0.8937 - weighted_accuracy: 0.8734 - val_loss: 0.2776 - val_acc: 0.8799 - val_weighted_accuracy: 0.8603\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2429 - acc: 0.8944 - weighted_accuracy: 0.8748 - val_loss: 0.2781 - val_acc: 0.8784 - val_weighted_accuracy: 0.8601\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2403 - acc: 0.8961 - weighted_accuracy: 0.8768 - val_loss: 0.2774 - val_acc: 0.8792 - val_weighted_accuracy: 0.8588\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2385 - acc: 0.8974 - weighted_accuracy: 0.8779 - val_loss: 0.2798 - val_acc: 0.8771 - val_weighted_accuracy: 0.8588\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2359 - acc: 0.8984 - weighted_accuracy: 0.8798 - val_loss: 0.2816 - val_acc: 0.8798 - val_weighted_accuracy: 0.8587\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2333 - acc: 0.8993 - weighted_accuracy: 0.8807 - val_loss: 0.2750 - val_acc: 0.8827 - val_weighted_accuracy: 0.8599\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2313 - acc: 0.9005 - weighted_accuracy: 0.8819 - val_loss: 0.2800 - val_acc: 0.8818 - val_weighted_accuracy: 0.8577\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2288 - acc: 0.9017 - weighted_accuracy: 0.8835 - val_loss: 0.2885 - val_acc: 0.8798 - val_weighted_accuracy: 0.8536\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2284 - acc: 0.9021 - weighted_accuracy: 0.8841 - val_loss: 0.2831 - val_acc: 0.8777 - val_weighted_accuracy: 0.8535\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2275 - acc: 0.9023 - weighted_accuracy: 0.8844 - val_loss: 0.2777 - val_acc: 0.8808 - val_weighted_accuracy: 0.8558\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2252 - acc: 0.9035 - weighted_accuracy: 0.8856 - val_loss: 0.2839 - val_acc: 0.8801 - val_weighted_accuracy: 0.8589\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2246 - acc: 0.9039 - weighted_accuracy: 0.8861 - val_loss: 0.2798 - val_acc: 0.8806 - val_weighted_accuracy: 0.8580\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2221 - acc: 0.9055 - weighted_accuracy: 0.8880 - val_loss: 0.2907 - val_acc: 0.8788 - val_weighted_accuracy: 0.8550\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2208 - acc: 0.9058 - weighted_accuracy: 0.8885 - val_loss: 0.2828 - val_acc: 0.8804 - val_weighted_accuracy: 0.8584\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2197 - acc: 0.9062 - weighted_accuracy: 0.8886 - val_loss: 0.2808 - val_acc: 0.8801 - val_weighted_accuracy: 0.8594\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2191 - acc: 0.9066 - weighted_accuracy: 0.8895 - val_loss: 0.2822 - val_acc: 0.8784 - val_weighted_accuracy: 0.8570\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2174 - acc: 0.9080 - weighted_accuracy: 0.8913 - val_loss: 0.2840 - val_acc: 0.8797 - val_weighted_accuracy: 0.8574\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2171 - acc: 0.9074 - weighted_accuracy: 0.8906 - val_loss: 0.2842 - val_acc: 0.8783 - val_weighted_accuracy: 0.8586\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2148 - acc: 0.9087 - weighted_accuracy: 0.8921 - val_loss: 0.2883 - val_acc: 0.8762 - val_weighted_accuracy: 0.8536\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2149 - acc: 0.9085 - weighted_accuracy: 0.8913 - val_loss: 0.2840 - val_acc: 0.8796 - val_weighted_accuracy: 0.8607\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2125 - acc: 0.9094 - weighted_accuracy: 0.8924 - val_loss: 0.2896 - val_acc: 0.8775 - val_weighted_accuracy: 0.8540\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2120 - acc: 0.9105 - weighted_accuracy: 0.8941 - val_loss: 0.2882 - val_acc: 0.8780 - val_weighted_accuracy: 0.8557\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2114 - acc: 0.9111 - weighted_accuracy: 0.8947 - val_loss: 0.2859 - val_acc: 0.8808 - val_weighted_accuracy: 0.8606\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2087 - acc: 0.9118 - weighted_accuracy: 0.8958 - val_loss: 0.2883 - val_acc: 0.8800 - val_weighted_accuracy: 0.8592\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2088 - acc: 0.9120 - weighted_accuracy: 0.8961 - val_loss: 0.2899 - val_acc: 0.8807 - val_weighted_accuracy: 0.8580\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2091 - acc: 0.9124 - weighted_accuracy: 0.8967 - val_loss: 0.2862 - val_acc: 0.8795 - val_weighted_accuracy: 0.8586\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2078 - acc: 0.9122 - weighted_accuracy: 0.8962 - val_loss: 0.2966 - val_acc: 0.8795 - val_weighted_accuracy: 0.8548\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2069 - acc: 0.9130 - weighted_accuracy: 0.8970 - val_loss: 0.2892 - val_acc: 0.8821 - val_weighted_accuracy: 0.8589\n",
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2063 - acc: 0.9131 - weighted_accuracy: 0.8972 - val_loss: 0.2884 - val_acc: 0.8818 - val_weighted_accuracy: 0.8601\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2061 - acc: 0.9135 - weighted_accuracy: 0.8975 - val_loss: 0.2905 - val_acc: 0.8815 - val_weighted_accuracy: 0.8595\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2057 - acc: 0.9129 - weighted_accuracy: 0.8971 - val_loss: 0.2859 - val_acc: 0.8823 - val_weighted_accuracy: 0.8617\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 50, 151)      0           embedding_5[0][0]                \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 50, 151)      0           embedding_5[1][0]                \n",
      "                                                                 reshape_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 50, 151)      0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 50, 151)      0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 50, 64)       0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 50, 64)       0           conv1d_22[1][0]                  \n",
      "                                                                 conv1d_25[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 50, 64)       4160        multiply_15[0][0]                \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 50, 64)       0           conv1d_19[0][0]                  \n",
      "                                                                 conv1d_19[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 50, 50)       0           dropout_9[0][0]                  \n",
      "                                                                 dropout_9[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 50, 50)       0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 50, 50)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 50, 64)       0           permute_7[0][0]                  \n",
      "                                                                 dropout_9[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 50, 64)       0           lambda_15[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 50, 279)      0           dropout_9[0][0]                  \n",
      "                                                                 dot_21[0][0]                     \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 50, 279)      0           dropout_9[1][0]                  \n",
      "                                                                 dot_20[0][0]                     \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 50, 64)       53632       concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 50, 64)       53632       concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 50, 64)       0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 50, 64)       0           conv1d_23[1][0]                  \n",
      "                                                                 conv1d_26[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 50, 64)       4160        multiply_17[0][0]                \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 50, 64)       0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_20[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 50, 50)       0           dropout_10[0][0]                 \n",
      "                                                                 dropout_10[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (None, 50, 50)       0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 50, 50)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 50, 64)       0           permute_8[0][0]                  \n",
      "                                                                 dropout_10[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 50, 64)       0           lambda_17[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 50, 407)      0           dropout_10[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 50, 407)      0           dropout_10[1][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 50, 64)       78208       concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 50, 64)       78208       concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 50, 64)       0           conv1d_24[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 50, 64)       0           conv1d_24[1][0]                  \n",
      "                                                                 conv1d_27[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 50, 64)       4160        multiply_19[0][0]                \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 50, 64)       0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_21[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 50, 50)       0           dropout_11[0][0]                 \n",
      "                                                                 dropout_11[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 50, 50)       0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 50, 50)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 50, 64)       0           permute_9[0][0]                  \n",
      "                                                                 dropout_11[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 50, 64)       0           lambda_19[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 50, 535)      0           dropout_11[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "                                                                 concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 50, 535)      0           dropout_11[1][0]                 \n",
      "                                                                 dot_26[0][0]                     \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 535)          0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 535)          0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 535)          535         concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 535)          0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 535)          0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 1605)         0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 1605)         0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 attention_weighted_average_3[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1605)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 1605)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 6420)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 6420)         0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6420)         25680       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           410944      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            195         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 62s 221us/step - loss: 0.4006 - acc: 0.8167 - weighted_accuracy: 0.7872 - val_loss: 0.3592 - val_acc: 0.8246 - val_weighted_accuracy: 0.8136\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.3235 - acc: 0.8527 - weighted_accuracy: 0.8265 - val_loss: 0.3403 - val_acc: 0.8381 - val_weighted_accuracy: 0.8267\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.3024 - acc: 0.8635 - weighted_accuracy: 0.8387 - val_loss: 0.3194 - val_acc: 0.8513 - val_weighted_accuracy: 0.8354\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2903 - acc: 0.8704 - weighted_accuracy: 0.8466 - val_loss: 0.3132 - val_acc: 0.8576 - val_weighted_accuracy: 0.8354\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2805 - acc: 0.8751 - weighted_accuracy: 0.8513 - val_loss: 0.3128 - val_acc: 0.8550 - val_weighted_accuracy: 0.8394\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2721 - acc: 0.8799 - weighted_accuracy: 0.8571 - val_loss: 0.3119 - val_acc: 0.8560 - val_weighted_accuracy: 0.8390\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2666 - acc: 0.8830 - weighted_accuracy: 0.8600 - val_loss: 0.3078 - val_acc: 0.8586 - val_weighted_accuracy: 0.8411\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2623 - acc: 0.8855 - weighted_accuracy: 0.8638 - val_loss: 0.3190 - val_acc: 0.8550 - val_weighted_accuracy: 0.8394\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2566 - acc: 0.8880 - weighted_accuracy: 0.8662 - val_loss: 0.3096 - val_acc: 0.8613 - val_weighted_accuracy: 0.8418\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 214us/step - loss: 0.2542 - acc: 0.8889 - weighted_accuracy: 0.8677 - val_loss: 0.3028 - val_acc: 0.8642 - val_weighted_accuracy: 0.8449\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2499 - acc: 0.8912 - weighted_accuracy: 0.8706 - val_loss: 0.3066 - val_acc: 0.8625 - val_weighted_accuracy: 0.8437\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2467 - acc: 0.8933 - weighted_accuracy: 0.8729 - val_loss: 0.3133 - val_acc: 0.8606 - val_weighted_accuracy: 0.8445\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2434 - acc: 0.8953 - weighted_accuracy: 0.8749 - val_loss: 0.3066 - val_acc: 0.8621 - val_weighted_accuracy: 0.8468\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2410 - acc: 0.8962 - weighted_accuracy: 0.8765 - val_loss: 0.3087 - val_acc: 0.8606 - val_weighted_accuracy: 0.8389\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2376 - acc: 0.8974 - weighted_accuracy: 0.8776 - val_loss: 0.3197 - val_acc: 0.8586 - val_weighted_accuracy: 0.8460\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2357 - acc: 0.8983 - weighted_accuracy: 0.8792 - val_loss: 0.3099 - val_acc: 0.8620 - val_weighted_accuracy: 0.8438\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2342 - acc: 0.8994 - weighted_accuracy: 0.8802 - val_loss: 0.3056 - val_acc: 0.8624 - val_weighted_accuracy: 0.8440\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2309 - acc: 0.9015 - weighted_accuracy: 0.8831 - val_loss: 0.3092 - val_acc: 0.8638 - val_weighted_accuracy: 0.8426\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2305 - acc: 0.9010 - weighted_accuracy: 0.8818 - val_loss: 0.3085 - val_acc: 0.8631 - val_weighted_accuracy: 0.8418\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2280 - acc: 0.9029 - weighted_accuracy: 0.8844 - val_loss: 0.3127 - val_acc: 0.8631 - val_weighted_accuracy: 0.8461\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2267 - acc: 0.9032 - weighted_accuracy: 0.8844 - val_loss: 0.3094 - val_acc: 0.8614 - val_weighted_accuracy: 0.8436\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2246 - acc: 0.9043 - weighted_accuracy: 0.8858 - val_loss: 0.3093 - val_acc: 0.8635 - val_weighted_accuracy: 0.8452\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2237 - acc: 0.9050 - weighted_accuracy: 0.8865 - val_loss: 0.3095 - val_acc: 0.8630 - val_weighted_accuracy: 0.8452\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2220 - acc: 0.9058 - weighted_accuracy: 0.8880 - val_loss: 0.3110 - val_acc: 0.8632 - val_weighted_accuracy: 0.8472\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2202 - acc: 0.9063 - weighted_accuracy: 0.8883 - val_loss: 0.3123 - val_acc: 0.8608 - val_weighted_accuracy: 0.8413\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2200 - acc: 0.9066 - weighted_accuracy: 0.8886 - val_loss: 0.3102 - val_acc: 0.8626 - val_weighted_accuracy: 0.8445\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2185 - acc: 0.9076 - weighted_accuracy: 0.8902 - val_loss: 0.3099 - val_acc: 0.8641 - val_weighted_accuracy: 0.8461\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2160 - acc: 0.9082 - weighted_accuracy: 0.8908 - val_loss: 0.3176 - val_acc: 0.8646 - val_weighted_accuracy: 0.8434\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2164 - acc: 0.9079 - weighted_accuracy: 0.8904 - val_loss: 0.3115 - val_acc: 0.8637 - val_weighted_accuracy: 0.8491\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2148 - acc: 0.9088 - weighted_accuracy: 0.8916 - val_loss: 0.3124 - val_acc: 0.8640 - val_weighted_accuracy: 0.8462\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2136 - acc: 0.9096 - weighted_accuracy: 0.8927 - val_loss: 0.3143 - val_acc: 0.8629 - val_weighted_accuracy: 0.8474\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2126 - acc: 0.9101 - weighted_accuracy: 0.8933 - val_loss: 0.3187 - val_acc: 0.8628 - val_weighted_accuracy: 0.8438\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2124 - acc: 0.9101 - weighted_accuracy: 0.8932 - val_loss: 0.3121 - val_acc: 0.8629 - val_weighted_accuracy: 0.8455\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2106 - acc: 0.9108 - weighted_accuracy: 0.8941 - val_loss: 0.3120 - val_acc: 0.8649 - val_weighted_accuracy: 0.8457\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2105 - acc: 0.9109 - weighted_accuracy: 0.8941 - val_loss: 0.3195 - val_acc: 0.8632 - val_weighted_accuracy: 0.8452\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 50, 151)      0           embedding_7[0][0]                \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 50, 151)      0           embedding_7[1][0]                \n",
      "                                                                 reshape_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 50, 151)      0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 50, 151)      0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 50, 64)       0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 50, 64)       0           conv1d_31[1][0]                  \n",
      "                                                                 conv1d_34[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 50, 64)       4160        multiply_22[0][0]                \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 50, 64)       0           conv1d_28[0][0]                  \n",
      "                                                                 conv1d_28[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 50, 50)       0           dropout_13[0][0]                 \n",
      "                                                                 dropout_13[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 50, 50)       0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 50, 50)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 50, 64)       0           permute_10[0][0]                 \n",
      "                                                                 dropout_13[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 50, 64)       0           lambda_22[0][0]                  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 50, 279)      0           dropout_13[0][0]                 \n",
      "                                                                 dot_30[0][0]                     \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 50, 279)      0           dropout_13[1][0]                 \n",
      "                                                                 dot_29[0][0]                     \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 50, 64)       53632       concatenate_36[0][0]             \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 50, 64)       53632       concatenate_36[0][0]             \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 50, 64)       0           conv1d_32[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 50, 64)       0           conv1d_32[1][0]                  \n",
      "                                                                 conv1d_35[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 50, 64)       4160        multiply_24[0][0]                \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 50, 64)       0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_29[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 50, 50)       0           dropout_14[0][0]                 \n",
      "                                                                 dropout_14[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 50, 50)       0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 50, 50)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 50, 64)       0           permute_11[0][0]                 \n",
      "                                                                 dropout_14[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 50, 64)       0           lambda_24[0][0]                  \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 50, 407)      0           dropout_14[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 50, 407)      0           dropout_14[1][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 50, 64)       78208       concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 50, 64)       78208       concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 50, 64)       0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 50, 64)       0           conv1d_33[1][0]                  \n",
      "                                                                 conv1d_36[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 50, 64)       4160        multiply_26[0][0]                \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 50, 64)       0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_30[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 50, 50)       0           dropout_15[0][0]                 \n",
      "                                                                 dropout_15[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 50, 50)       0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 50, 50)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 50, 64)       0           permute_12[0][0]                 \n",
      "                                                                 dropout_15[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 50, 64)       0           lambda_26[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 50, 535)      0           dropout_15[0][0]                 \n",
      "                                                                 dot_36[0][0]                     \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 50, 535)      0           dropout_15[1][0]                 \n",
      "                                                                 dot_35[0][0]                     \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 535)          0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 535)          0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_4 (A (None, 535)          535         concatenate_40[0][0]             \n",
      "                                                                 concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 535)          0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 535)          0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 1605)         0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 attention_weighted_average_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 1605)         0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 attention_weighted_average_4[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1605)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 1605)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 6420)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 6420)         0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6420)         25680       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           410944      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            195         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 62s 222us/step - loss: 0.3939 - acc: 0.8179 - weighted_accuracy: 0.7885 - val_loss: 0.3590 - val_acc: 0.8289 - val_weighted_accuracy: 0.8113\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3248 - acc: 0.8517 - weighted_accuracy: 0.8260 - val_loss: 0.3341 - val_acc: 0.8466 - val_weighted_accuracy: 0.8315\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3029 - acc: 0.8635 - weighted_accuracy: 0.8388 - val_loss: 0.3239 - val_acc: 0.8493 - val_weighted_accuracy: 0.8315\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2900 - acc: 0.8707 - weighted_accuracy: 0.8472 - val_loss: 0.3163 - val_acc: 0.8549 - val_weighted_accuracy: 0.8392\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2808 - acc: 0.8751 - weighted_accuracy: 0.8526 - val_loss: 0.3051 - val_acc: 0.8618 - val_weighted_accuracy: 0.8429\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2736 - acc: 0.8789 - weighted_accuracy: 0.8563 - val_loss: 0.3057 - val_acc: 0.8629 - val_weighted_accuracy: 0.8480\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2675 - acc: 0.8817 - weighted_accuracy: 0.8600 - val_loss: 0.3051 - val_acc: 0.8627 - val_weighted_accuracy: 0.8478\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2618 - acc: 0.8852 - weighted_accuracy: 0.8639 - val_loss: 0.3071 - val_acc: 0.8612 - val_weighted_accuracy: 0.8474\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2573 - acc: 0.8873 - weighted_accuracy: 0.8663 - val_loss: 0.2989 - val_acc: 0.8676 - val_weighted_accuracy: 0.8501\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2531 - acc: 0.8894 - weighted_accuracy: 0.8687 - val_loss: 0.3003 - val_acc: 0.8662 - val_weighted_accuracy: 0.8481\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2501 - acc: 0.8908 - weighted_accuracy: 0.8707 - val_loss: 0.3010 - val_acc: 0.8673 - val_weighted_accuracy: 0.8498\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2468 - acc: 0.8929 - weighted_accuracy: 0.8728 - val_loss: 0.2986 - val_acc: 0.8688 - val_weighted_accuracy: 0.8483\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2443 - acc: 0.8938 - weighted_accuracy: 0.8738 - val_loss: 0.3010 - val_acc: 0.8683 - val_weighted_accuracy: 0.8478\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2409 - acc: 0.8955 - weighted_accuracy: 0.8762 - val_loss: 0.2969 - val_acc: 0.8675 - val_weighted_accuracy: 0.8522\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2397 - acc: 0.8969 - weighted_accuracy: 0.8776 - val_loss: 0.2998 - val_acc: 0.8674 - val_weighted_accuracy: 0.8463\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2349 - acc: 0.8992 - weighted_accuracy: 0.8805 - val_loss: 0.3042 - val_acc: 0.8677 - val_weighted_accuracy: 0.8486\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2343 - acc: 0.8985 - weighted_accuracy: 0.8796 - val_loss: 0.3053 - val_acc: 0.8672 - val_weighted_accuracy: 0.8455\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2328 - acc: 0.8998 - weighted_accuracy: 0.8807 - val_loss: 0.3004 - val_acc: 0.8691 - val_weighted_accuracy: 0.8510\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2300 - acc: 0.9012 - weighted_accuracy: 0.8828 - val_loss: 0.3046 - val_acc: 0.8702 - val_weighted_accuracy: 0.8486\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2290 - acc: 0.9018 - weighted_accuracy: 0.8836 - val_loss: 0.3025 - val_acc: 0.8685 - val_weighted_accuracy: 0.8492\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2264 - acc: 0.9028 - weighted_accuracy: 0.8843 - val_loss: 0.3042 - val_acc: 0.8700 - val_weighted_accuracy: 0.8470\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2245 - acc: 0.9037 - weighted_accuracy: 0.8858 - val_loss: 0.3017 - val_acc: 0.8685 - val_weighted_accuracy: 0.8484\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2233 - acc: 0.9040 - weighted_accuracy: 0.8862 - val_loss: 0.3036 - val_acc: 0.8691 - val_weighted_accuracy: 0.8518\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2225 - acc: 0.9051 - weighted_accuracy: 0.8875 - val_loss: 0.3012 - val_acc: 0.8716 - val_weighted_accuracy: 0.8532\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2207 - acc: 0.9061 - weighted_accuracy: 0.8881 - val_loss: 0.2998 - val_acc: 0.8719 - val_weighted_accuracy: 0.8502\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2196 - acc: 0.9060 - weighted_accuracy: 0.8887 - val_loss: 0.3063 - val_acc: 0.8690 - val_weighted_accuracy: 0.8461\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2185 - acc: 0.9068 - weighted_accuracy: 0.8896 - val_loss: 0.3039 - val_acc: 0.8698 - val_weighted_accuracy: 0.8471\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2167 - acc: 0.9075 - weighted_accuracy: 0.8902 - val_loss: 0.3009 - val_acc: 0.8702 - val_weighted_accuracy: 0.8522\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2155 - acc: 0.9078 - weighted_accuracy: 0.8909 - val_loss: 0.3074 - val_acc: 0.8714 - val_weighted_accuracy: 0.8519\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2147 - acc: 0.9092 - weighted_accuracy: 0.8922 - val_loss: 0.3066 - val_acc: 0.8692 - val_weighted_accuracy: 0.8515\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2139 - acc: 0.9088 - weighted_accuracy: 0.8919 - val_loss: 0.3064 - val_acc: 0.8689 - val_weighted_accuracy: 0.8487\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2126 - acc: 0.9097 - weighted_accuracy: 0.8928 - val_loss: 0.3063 - val_acc: 0.8700 - val_weighted_accuracy: 0.8499\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2133 - acc: 0.9092 - weighted_accuracy: 0.8925 - val_loss: 0.3039 - val_acc: 0.8705 - val_weighted_accuracy: 0.8516\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2107 - acc: 0.9107 - weighted_accuracy: 0.8943 - val_loss: 0.3077 - val_acc: 0.8692 - val_weighted_accuracy: 0.8512\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2113 - acc: 0.9106 - weighted_accuracy: 0.8936 - val_loss: 0.3065 - val_acc: 0.8682 - val_weighted_accuracy: 0.8490\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2094 - acc: 0.9114 - weighted_accuracy: 0.8949 - val_loss: 0.3068 - val_acc: 0.8709 - val_weighted_accuracy: 0.8516\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2089 - acc: 0.9115 - weighted_accuracy: 0.8946 - val_loss: 0.3079 - val_acc: 0.8714 - val_weighted_accuracy: 0.8485\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2082 - acc: 0.9126 - weighted_accuracy: 0.8962 - val_loss: 0.3069 - val_acc: 0.8693 - val_weighted_accuracy: 0.8535\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2075 - acc: 0.9124 - weighted_accuracy: 0.8964 - val_loss: 0.3058 - val_acc: 0.8698 - val_weighted_accuracy: 0.8506\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 50, 151)      0           embedding_9[0][0]                \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 50, 151)      0           embedding_9[1][0]                \n",
      "                                                                 reshape_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 50, 151)      0           concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 50, 151)      0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 50, 64)       0           conv1d_40[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 50, 64)       0           conv1d_40[1][0]                  \n",
      "                                                                 conv1d_43[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 50, 64)       4160        multiply_29[0][0]                \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 50, 64)       0           conv1d_37[0][0]                  \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 50, 50)       0           dropout_17[0][0]                 \n",
      "                                                                 dropout_17[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 50, 50)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 50, 50)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 50, 64)       0           permute_13[0][0]                 \n",
      "                                                                 dropout_17[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 50, 64)       0           lambda_29[0][0]                  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 50, 279)      0           dropout_17[0][0]                 \n",
      "                                                                 dot_39[0][0]                     \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 50, 279)      0           dropout_17[1][0]                 \n",
      "                                                                 dot_38[0][0]                     \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 50, 64)       53632       concatenate_47[0][0]             \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 50, 64)       53632       concatenate_47[0][0]             \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 50, 64)       0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 50, 64)       0           conv1d_41[1][0]                  \n",
      "                                                                 conv1d_44[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 50, 64)       4160        multiply_31[0][0]                \n",
      "                                                                 multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 50, 64)       0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 50, 50)       0           dropout_18[0][0]                 \n",
      "                                                                 dropout_18[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 50, 50)       0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 50, 50)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 50, 64)       0           permute_14[0][0]                 \n",
      "                                                                 dropout_18[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 50, 64)       0           lambda_31[0][0]                  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 50, 407)      0           dropout_18[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 50, 407)      0           dropout_18[1][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 50, 64)       78208       concatenate_49[0][0]             \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 50, 64)       78208       concatenate_49[0][0]             \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 50, 64)       0           conv1d_42[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 50, 64)       0           conv1d_42[1][0]                  \n",
      "                                                                 conv1d_45[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 50, 64)       4160        multiply_33[0][0]                \n",
      "                                                                 multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 50, 64)       0           conv1d_39[0][0]                  \n",
      "                                                                 conv1d_39[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 50, 50)       0           dropout_19[0][0]                 \n",
      "                                                                 dropout_19[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 50, 50)       0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 50, 50)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 50, 64)       0           permute_15[0][0]                 \n",
      "                                                                 dropout_19[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 50, 64)       0           lambda_33[0][0]                  \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 50, 535)      0           dropout_19[0][0]                 \n",
      "                                                                 dot_45[0][0]                     \n",
      "                                                                 concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 50, 535)      0           dropout_19[1][0]                 \n",
      "                                                                 dot_44[0][0]                     \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 535)          0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 535)          0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_5 (A (None, 535)          535         concatenate_51[0][0]             \n",
      "                                                                 concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 535)          0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 535)          0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 1605)         0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 attention_weighted_average_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 1605)         0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 attention_weighted_average_5[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1605)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 1605)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 6420)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 6420)         0           concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6420)         25680       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           410944      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            195         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 62s 222us/step - loss: 0.4116 - acc: 0.8128 - weighted_accuracy: 0.7848 - val_loss: 0.3754 - val_acc: 0.8139 - val_weighted_accuracy: 0.7970\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3265 - acc: 0.8505 - weighted_accuracy: 0.8247 - val_loss: 0.3446 - val_acc: 0.8340 - val_weighted_accuracy: 0.8074\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3036 - acc: 0.8629 - weighted_accuracy: 0.8380 - val_loss: 0.3414 - val_acc: 0.8362 - val_weighted_accuracy: 0.8208\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2893 - acc: 0.8707 - weighted_accuracy: 0.8467 - val_loss: 0.3226 - val_acc: 0.8492 - val_weighted_accuracy: 0.8255\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2808 - acc: 0.8756 - weighted_accuracy: 0.8522 - val_loss: 0.3243 - val_acc: 0.8485 - val_weighted_accuracy: 0.8276\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2722 - acc: 0.8797 - weighted_accuracy: 0.8572 - val_loss: 0.3331 - val_acc: 0.8438 - val_weighted_accuracy: 0.8246\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2674 - acc: 0.8824 - weighted_accuracy: 0.8599 - val_loss: 0.3187 - val_acc: 0.8531 - val_weighted_accuracy: 0.8321\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2617 - acc: 0.8858 - weighted_accuracy: 0.8643 - val_loss: 0.3154 - val_acc: 0.8572 - val_weighted_accuracy: 0.8362\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2581 - acc: 0.8872 - weighted_accuracy: 0.8658 - val_loss: 0.3186 - val_acc: 0.8545 - val_weighted_accuracy: 0.8379\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2534 - acc: 0.8895 - weighted_accuracy: 0.8683 - val_loss: 0.3168 - val_acc: 0.8562 - val_weighted_accuracy: 0.8377\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2509 - acc: 0.8912 - weighted_accuracy: 0.8701 - val_loss: 0.3137 - val_acc: 0.8549 - val_weighted_accuracy: 0.8343\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2461 - acc: 0.8935 - weighted_accuracy: 0.8731 - val_loss: 0.3192 - val_acc: 0.8555 - val_weighted_accuracy: 0.8320\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2437 - acc: 0.8941 - weighted_accuracy: 0.8742 - val_loss: 0.3190 - val_acc: 0.8524 - val_weighted_accuracy: 0.8342\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2414 - acc: 0.8954 - weighted_accuracy: 0.8755 - val_loss: 0.3221 - val_acc: 0.8528 - val_weighted_accuracy: 0.8376\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2388 - acc: 0.8968 - weighted_accuracy: 0.8772 - val_loss: 0.3154 - val_acc: 0.8566 - val_weighted_accuracy: 0.8356\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2360 - acc: 0.8985 - weighted_accuracy: 0.8791 - val_loss: 0.3158 - val_acc: 0.8553 - val_weighted_accuracy: 0.8347\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2343 - acc: 0.8992 - weighted_accuracy: 0.8799 - val_loss: 0.3141 - val_acc: 0.8572 - val_weighted_accuracy: 0.8388\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2327 - acc: 0.8997 - weighted_accuracy: 0.8802 - val_loss: 0.3137 - val_acc: 0.8570 - val_weighted_accuracy: 0.8358\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2300 - acc: 0.9009 - weighted_accuracy: 0.8819 - val_loss: 0.3112 - val_acc: 0.8597 - val_weighted_accuracy: 0.8412\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2284 - acc: 0.9020 - weighted_accuracy: 0.8837 - val_loss: 0.3169 - val_acc: 0.8560 - val_weighted_accuracy: 0.8352\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2267 - acc: 0.9024 - weighted_accuracy: 0.8839 - val_loss: 0.3164 - val_acc: 0.8581 - val_weighted_accuracy: 0.8360\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2249 - acc: 0.9040 - weighted_accuracy: 0.8857 - val_loss: 0.3179 - val_acc: 0.8571 - val_weighted_accuracy: 0.8377\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2236 - acc: 0.9041 - weighted_accuracy: 0.8863 - val_loss: 0.3212 - val_acc: 0.8558 - val_weighted_accuracy: 0.8373\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2224 - acc: 0.9050 - weighted_accuracy: 0.8867 - val_loss: 0.3134 - val_acc: 0.8606 - val_weighted_accuracy: 0.8423\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2203 - acc: 0.9059 - weighted_accuracy: 0.8882 - val_loss: 0.3115 - val_acc: 0.8591 - val_weighted_accuracy: 0.8366\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2201 - acc: 0.9058 - weighted_accuracy: 0.8876 - val_loss: 0.3168 - val_acc: 0.8575 - val_weighted_accuracy: 0.8362\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2179 - acc: 0.9074 - weighted_accuracy: 0.8899 - val_loss: 0.3144 - val_acc: 0.8584 - val_weighted_accuracy: 0.8358\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2164 - acc: 0.9084 - weighted_accuracy: 0.8913 - val_loss: 0.3220 - val_acc: 0.8586 - val_weighted_accuracy: 0.8392\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2161 - acc: 0.9082 - weighted_accuracy: 0.8910 - val_loss: 0.3170 - val_acc: 0.8570 - val_weighted_accuracy: 0.8386\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2152 - acc: 0.9086 - weighted_accuracy: 0.8914 - val_loss: 0.3228 - val_acc: 0.8572 - val_weighted_accuracy: 0.8406\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2138 - acc: 0.9093 - weighted_accuracy: 0.8920 - val_loss: 0.3198 - val_acc: 0.8582 - val_weighted_accuracy: 0.8426\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2132 - acc: 0.9096 - weighted_accuracy: 0.8924 - val_loss: 0.3198 - val_acc: 0.8608 - val_weighted_accuracy: 0.8449\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2123 - acc: 0.9101 - weighted_accuracy: 0.8931 - val_loss: 0.3154 - val_acc: 0.8598 - val_weighted_accuracy: 0.8385\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2112 - acc: 0.9109 - weighted_accuracy: 0.8937 - val_loss: 0.3283 - val_acc: 0.8558 - val_weighted_accuracy: 0.8380\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2102 - acc: 0.9114 - weighted_accuracy: 0.8944 - val_loss: 0.3362 - val_acc: 0.8511 - val_weighted_accuracy: 0.8314\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2092 - acc: 0.9115 - weighted_accuracy: 0.8948 - val_loss: 0.3196 - val_acc: 0.8578 - val_weighted_accuracy: 0.8405\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2093 - acc: 0.9121 - weighted_accuracy: 0.8954 - val_loss: 0.3186 - val_acc: 0.8572 - val_weighted_accuracy: 0.8367\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2080 - acc: 0.9125 - weighted_accuracy: 0.8961 - val_loss: 0.3246 - val_acc: 0.8579 - val_weighted_accuracy: 0.8377\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2080 - acc: 0.9128 - weighted_accuracy: 0.8965 - val_loss: 0.3189 - val_acc: 0.8609 - val_weighted_accuracy: 0.8442\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2071 - acc: 0.9128 - weighted_accuracy: 0.8960 - val_loss: 0.3251 - val_acc: 0.8574 - val_weighted_accuracy: 0.8397\n",
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2046 - acc: 0.9140 - weighted_accuracy: 0.8976 - val_loss: 0.3242 - val_acc: 0.8583 - val_weighted_accuracy: 0.8404\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2053 - acc: 0.9135 - weighted_accuracy: 0.8972 - val_loss: 0.3236 - val_acc: 0.8615 - val_weighted_accuracy: 0.8431\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2046 - acc: 0.9142 - weighted_accuracy: 0.8978 - val_loss: 0.3181 - val_acc: 0.8608 - val_weighted_accuracy: 0.8420\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2038 - acc: 0.9145 - weighted_accuracy: 0.8986 - val_loss: 0.3304 - val_acc: 0.8572 - val_weighted_accuracy: 0.8378\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 50, 151)      0           embedding_11[0][0]               \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 50, 151)      0           embedding_11[1][0]               \n",
      "                                                                 reshape_6[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 50, 151)      0           concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 50, 151)      0           concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 50, 64)       0           conv1d_49[0][0]                  \n",
      "                                                                 conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 50, 64)       0           conv1d_49[1][0]                  \n",
      "                                                                 conv1d_52[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 50, 64)       4160        multiply_36[0][0]                \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 50, 64)       0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_46[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 50, 50)       0           dropout_21[0][0]                 \n",
      "                                                                 dropout_21[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 50, 50)       0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 50, 50)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 50, 64)       0           permute_16[0][0]                 \n",
      "                                                                 dropout_21[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 50, 64)       0           lambda_36[0][0]                  \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 50, 279)      0           dropout_21[0][0]                 \n",
      "                                                                 dot_48[0][0]                     \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 50, 279)      0           dropout_21[1][0]                 \n",
      "                                                                 dot_47[0][0]                     \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 50, 64)       53632       concatenate_58[0][0]             \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 50, 64)       53632       concatenate_58[0][0]             \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 50, 64)       0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 50, 64)       0           conv1d_50[1][0]                  \n",
      "                                                                 conv1d_53[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 50, 64)       4160        multiply_38[0][0]                \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 50, 64)       0           conv1d_47[0][0]                  \n",
      "                                                                 conv1d_47[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 50, 50)       0           dropout_22[0][0]                 \n",
      "                                                                 dropout_22[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 50, 50)       0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 50, 50)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 50, 64)       0           permute_17[0][0]                 \n",
      "                                                                 dropout_22[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 50, 64)       0           lambda_38[0][0]                  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 50, 407)      0           dropout_22[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "                                                                 concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 50, 407)      0           dropout_22[1][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 50, 64)       78208       concatenate_60[0][0]             \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 50, 64)       78208       concatenate_60[0][0]             \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 50, 64)       0           conv1d_51[0][0]                  \n",
      "                                                                 conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 50, 64)       0           conv1d_51[1][0]                  \n",
      "                                                                 conv1d_54[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 50, 64)       4160        multiply_40[0][0]                \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 50, 64)       0           conv1d_48[0][0]                  \n",
      "                                                                 conv1d_48[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 50, 50)       0           dropout_23[0][0]                 \n",
      "                                                                 dropout_23[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 50, 50)       0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 50, 50)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 50, 64)       0           permute_18[0][0]                 \n",
      "                                                                 dropout_23[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 50, 64)       0           lambda_40[0][0]                  \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 50, 535)      0           dropout_23[0][0]                 \n",
      "                                                                 dot_54[0][0]                     \n",
      "                                                                 concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 50, 535)      0           dropout_23[1][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 535)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 535)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_6 (A (None, 535)          535         concatenate_62[0][0]             \n",
      "                                                                 concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 535)          0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 535)          0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 1605)         0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 attention_weighted_average_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 1605)         0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 attention_weighted_average_6[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1605)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 1605)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 6420)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 6420)         0           concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6420)         25680       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           410944      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            195         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 63s 224us/step - loss: 0.3977 - acc: 0.8170 - weighted_accuracy: 0.7882 - val_loss: 0.3939 - val_acc: 0.8075 - val_weighted_accuracy: 0.7779\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3201 - acc: 0.8532 - weighted_accuracy: 0.8278 - val_loss: 0.3539 - val_acc: 0.8328 - val_weighted_accuracy: 0.8039\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3004 - acc: 0.8640 - weighted_accuracy: 0.8395 - val_loss: 0.3544 - val_acc: 0.8340 - val_weighted_accuracy: 0.8016\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2874 - acc: 0.8706 - weighted_accuracy: 0.8471 - val_loss: 0.3475 - val_acc: 0.8424 - val_weighted_accuracy: 0.8065\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2778 - acc: 0.8762 - weighted_accuracy: 0.8536 - val_loss: 0.3415 - val_acc: 0.8423 - val_weighted_accuracy: 0.8079\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2714 - acc: 0.8798 - weighted_accuracy: 0.8575 - val_loss: 0.3313 - val_acc: 0.8453 - val_weighted_accuracy: 0.8210\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2651 - acc: 0.8835 - weighted_accuracy: 0.8617 - val_loss: 0.3302 - val_acc: 0.8462 - val_weighted_accuracy: 0.8137\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2601 - acc: 0.8853 - weighted_accuracy: 0.8637 - val_loss: 0.3347 - val_acc: 0.8454 - val_weighted_accuracy: 0.8149\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2568 - acc: 0.8875 - weighted_accuracy: 0.8662 - val_loss: 0.3307 - val_acc: 0.8459 - val_weighted_accuracy: 0.8186\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2510 - acc: 0.8903 - weighted_accuracy: 0.8699 - val_loss: 0.3318 - val_acc: 0.8467 - val_weighted_accuracy: 0.8175\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2487 - acc: 0.8917 - weighted_accuracy: 0.8719 - val_loss: 0.3322 - val_acc: 0.8485 - val_weighted_accuracy: 0.8192\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2440 - acc: 0.8937 - weighted_accuracy: 0.8738 - val_loss: 0.3323 - val_acc: 0.8505 - val_weighted_accuracy: 0.8215\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2412 - acc: 0.8955 - weighted_accuracy: 0.8758 - val_loss: 0.3287 - val_acc: 0.8512 - val_weighted_accuracy: 0.8242\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2389 - acc: 0.8962 - weighted_accuracy: 0.8771 - val_loss: 0.3411 - val_acc: 0.8466 - val_weighted_accuracy: 0.8153\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2367 - acc: 0.8974 - weighted_accuracy: 0.8786 - val_loss: 0.3457 - val_acc: 0.8476 - val_weighted_accuracy: 0.8121\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2345 - acc: 0.8992 - weighted_accuracy: 0.8803 - val_loss: 0.3315 - val_acc: 0.8503 - val_weighted_accuracy: 0.8229\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2316 - acc: 0.9009 - weighted_accuracy: 0.8828 - val_loss: 0.3369 - val_acc: 0.8503 - val_weighted_accuracy: 0.8199\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2298 - acc: 0.9011 - weighted_accuracy: 0.8828 - val_loss: 0.3312 - val_acc: 0.8514 - val_weighted_accuracy: 0.8216\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2281 - acc: 0.9016 - weighted_accuracy: 0.8832 - val_loss: 0.3379 - val_acc: 0.8509 - val_weighted_accuracy: 0.8179\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2268 - acc: 0.9027 - weighted_accuracy: 0.8847 - val_loss: 0.3384 - val_acc: 0.8518 - val_weighted_accuracy: 0.8183\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2252 - acc: 0.9033 - weighted_accuracy: 0.8861 - val_loss: 0.3343 - val_acc: 0.8511 - val_weighted_accuracy: 0.8246\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2232 - acc: 0.9048 - weighted_accuracy: 0.8872 - val_loss: 0.3390 - val_acc: 0.8498 - val_weighted_accuracy: 0.8196\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2210 - acc: 0.9052 - weighted_accuracy: 0.8878 - val_loss: 0.3463 - val_acc: 0.8505 - val_weighted_accuracy: 0.8149\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2209 - acc: 0.9057 - weighted_accuracy: 0.8887 - val_loss: 0.3472 - val_acc: 0.8474 - val_weighted_accuracy: 0.8180\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2187 - acc: 0.9067 - weighted_accuracy: 0.8899 - val_loss: 0.3365 - val_acc: 0.8511 - val_weighted_accuracy: 0.8171\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2175 - acc: 0.9072 - weighted_accuracy: 0.8902 - val_loss: 0.3412 - val_acc: 0.8521 - val_weighted_accuracy: 0.8241\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2163 - acc: 0.9076 - weighted_accuracy: 0.8907 - val_loss: 0.3441 - val_acc: 0.8525 - val_weighted_accuracy: 0.8183\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2152 - acc: 0.9085 - weighted_accuracy: 0.8917 - val_loss: 0.3356 - val_acc: 0.8543 - val_weighted_accuracy: 0.8236\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2143 - acc: 0.9092 - weighted_accuracy: 0.8927 - val_loss: 0.3408 - val_acc: 0.8517 - val_weighted_accuracy: 0.8183\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2142 - acc: 0.9089 - weighted_accuracy: 0.8922 - val_loss: 0.3408 - val_acc: 0.8491 - val_weighted_accuracy: 0.8184\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2130 - acc: 0.9098 - weighted_accuracy: 0.8930 - val_loss: 0.3371 - val_acc: 0.8500 - val_weighted_accuracy: 0.8203\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2121 - acc: 0.9094 - weighted_accuracy: 0.8932 - val_loss: 0.3458 - val_acc: 0.8494 - val_weighted_accuracy: 0.8165\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2102 - acc: 0.9111 - weighted_accuracy: 0.8949 - val_loss: 0.3465 - val_acc: 0.8486 - val_weighted_accuracy: 0.8172\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2094 - acc: 0.9115 - weighted_accuracy: 0.8953 - val_loss: 0.3460 - val_acc: 0.8508 - val_weighted_accuracy: 0.8138\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2086 - acc: 0.9122 - weighted_accuracy: 0.8966 - val_loss: 0.3390 - val_acc: 0.8534 - val_weighted_accuracy: 0.8192\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2087 - acc: 0.9114 - weighted_accuracy: 0.8955 - val_loss: 0.3426 - val_acc: 0.8513 - val_weighted_accuracy: 0.8167\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2068 - acc: 0.9122 - weighted_accuracy: 0.8964 - val_loss: 0.3424 - val_acc: 0.8514 - val_weighted_accuracy: 0.8241\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2056 - acc: 0.9129 - weighted_accuracy: 0.8976 - val_loss: 0.3449 - val_acc: 0.8519 - val_weighted_accuracy: 0.8189\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 50, 151)      0           embedding_13[0][0]               \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 50, 151)      0           embedding_13[1][0]               \n",
      "                                                                 reshape_7[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 50, 151)      0           concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 50, 151)      0           concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 50, 64)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 50, 64)       0           conv1d_58[1][0]                  \n",
      "                                                                 conv1d_61[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 50, 64)       4160        multiply_43[0][0]                \n",
      "                                                                 multiply_44[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 64)       0           conv1d_55[0][0]                  \n",
      "                                                                 conv1d_55[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 50, 50)       0           dropout_25[0][0]                 \n",
      "                                                                 dropout_25[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 50, 50)       0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50, 50)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 50, 64)       0           permute_19[0][0]                 \n",
      "                                                                 dropout_25[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 50, 64)       0           lambda_43[0][0]                  \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 50, 279)      0           dropout_25[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 50, 279)      0           dropout_25[1][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 50, 64)       53632       concatenate_69[0][0]             \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 50, 64)       53632       concatenate_69[0][0]             \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 50, 64)       0           conv1d_59[0][0]                  \n",
      "                                                                 conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 50, 64)       0           conv1d_59[1][0]                  \n",
      "                                                                 conv1d_62[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 50, 64)       4160        multiply_45[0][0]                \n",
      "                                                                 multiply_46[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 50, 64)       0           conv1d_56[0][0]                  \n",
      "                                                                 conv1d_56[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 50, 50)       0           dropout_26[0][0]                 \n",
      "                                                                 dropout_26[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 50, 50)       0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50, 50)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 50, 64)       0           permute_20[0][0]                 \n",
      "                                                                 dropout_26[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 50, 64)       0           lambda_45[0][0]                  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 50, 407)      0           dropout_26[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 50, 407)      0           dropout_26[1][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 50, 64)       78208       concatenate_71[0][0]             \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 50, 64)       78208       concatenate_71[0][0]             \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 50, 64)       0           conv1d_60[0][0]                  \n",
      "                                                                 conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 50, 64)       0           conv1d_60[1][0]                  \n",
      "                                                                 conv1d_63[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 50, 64)       4160        multiply_47[0][0]                \n",
      "                                                                 multiply_48[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 50, 64)       0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 50, 50)       0           dropout_27[0][0]                 \n",
      "                                                                 dropout_27[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 50, 50)       0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 50, 64)       0           permute_21[0][0]                 \n",
      "                                                                 dropout_27[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 50, 64)       0           lambda_47[0][0]                  \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 50, 535)      0           dropout_27[0][0]                 \n",
      "                                                                 dot_63[0][0]                     \n",
      "                                                                 concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 50, 535)      0           dropout_27[1][0]                 \n",
      "                                                                 dot_62[0][0]                     \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 535)          0           concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 535)          0           concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_7 (A (None, 535)          535         concatenate_73[0][0]             \n",
      "                                                                 concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 535)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 535)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 1605)         0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 attention_weighted_average_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 1605)         0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "                                                                 attention_weighted_average_7[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1605)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 1605)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 6420)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 multiply_49[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 6420)         0           concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6420)         25680       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           410944      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            195         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 63s 224us/step - loss: 0.4101 - acc: 0.8123 - weighted_accuracy: 0.7831 - val_loss: 0.3517 - val_acc: 0.8357 - val_weighted_accuracy: 0.8177\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3264 - acc: 0.8506 - weighted_accuracy: 0.8249 - val_loss: 0.3172 - val_acc: 0.8543 - val_weighted_accuracy: 0.8306\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3040 - acc: 0.8624 - weighted_accuracy: 0.8379 - val_loss: 0.3152 - val_acc: 0.8574 - val_weighted_accuracy: 0.8347\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2920 - acc: 0.8680 - weighted_accuracy: 0.8441 - val_loss: 0.3098 - val_acc: 0.8595 - val_weighted_accuracy: 0.8366\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2823 - acc: 0.8741 - weighted_accuracy: 0.8509 - val_loss: 0.3079 - val_acc: 0.8600 - val_weighted_accuracy: 0.8417\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2746 - acc: 0.8782 - weighted_accuracy: 0.8558 - val_loss: 0.3019 - val_acc: 0.8669 - val_weighted_accuracy: 0.8432\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2690 - acc: 0.8814 - weighted_accuracy: 0.8595 - val_loss: 0.3081 - val_acc: 0.8616 - val_weighted_accuracy: 0.8385\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2644 - acc: 0.8831 - weighted_accuracy: 0.8615 - val_loss: 0.3047 - val_acc: 0.8635 - val_weighted_accuracy: 0.8464\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2593 - acc: 0.8863 - weighted_accuracy: 0.8653 - val_loss: 0.2992 - val_acc: 0.8675 - val_weighted_accuracy: 0.8457\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2549 - acc: 0.8887 - weighted_accuracy: 0.8682 - val_loss: 0.3056 - val_acc: 0.8649 - val_weighted_accuracy: 0.8456\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2515 - acc: 0.8896 - weighted_accuracy: 0.8692 - val_loss: 0.2998 - val_acc: 0.8671 - val_weighted_accuracy: 0.8479\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2480 - acc: 0.8918 - weighted_accuracy: 0.8720 - val_loss: 0.3001 - val_acc: 0.8670 - val_weighted_accuracy: 0.8469\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2449 - acc: 0.8936 - weighted_accuracy: 0.8738 - val_loss: 0.2989 - val_acc: 0.8655 - val_weighted_accuracy: 0.8395\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2425 - acc: 0.8953 - weighted_accuracy: 0.8755 - val_loss: 0.3026 - val_acc: 0.8657 - val_weighted_accuracy: 0.8413\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2399 - acc: 0.8963 - weighted_accuracy: 0.8774 - val_loss: 0.3025 - val_acc: 0.8666 - val_weighted_accuracy: 0.8453\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2374 - acc: 0.8968 - weighted_accuracy: 0.8778 - val_loss: 0.3032 - val_acc: 0.8668 - val_weighted_accuracy: 0.8500\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2353 - acc: 0.8983 - weighted_accuracy: 0.8795 - val_loss: 0.3034 - val_acc: 0.8686 - val_weighted_accuracy: 0.8440\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2329 - acc: 0.8989 - weighted_accuracy: 0.8801 - val_loss: 0.3017 - val_acc: 0.8684 - val_weighted_accuracy: 0.8425\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2316 - acc: 0.9003 - weighted_accuracy: 0.8819 - val_loss: 0.3021 - val_acc: 0.8697 - val_weighted_accuracy: 0.8473\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2290 - acc: 0.9016 - weighted_accuracy: 0.8839 - val_loss: 0.2996 - val_acc: 0.8705 - val_weighted_accuracy: 0.8445\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2266 - acc: 0.9023 - weighted_accuracy: 0.8845 - val_loss: 0.2993 - val_acc: 0.8707 - val_weighted_accuracy: 0.8504\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2243 - acc: 0.9038 - weighted_accuracy: 0.8861 - val_loss: 0.2990 - val_acc: 0.8697 - val_weighted_accuracy: 0.8490\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2240 - acc: 0.9044 - weighted_accuracy: 0.8867 - val_loss: 0.2998 - val_acc: 0.8697 - val_weighted_accuracy: 0.8468\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2241 - acc: 0.9041 - weighted_accuracy: 0.8862 - val_loss: 0.2979 - val_acc: 0.8696 - val_weighted_accuracy: 0.8470\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2221 - acc: 0.9052 - weighted_accuracy: 0.8878 - val_loss: 0.3026 - val_acc: 0.8701 - val_weighted_accuracy: 0.8433\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2207 - acc: 0.9057 - weighted_accuracy: 0.8889 - val_loss: 0.3009 - val_acc: 0.8696 - val_weighted_accuracy: 0.8436\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2186 - acc: 0.9071 - weighted_accuracy: 0.8901 - val_loss: 0.3049 - val_acc: 0.8702 - val_weighted_accuracy: 0.8435\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2172 - acc: 0.9080 - weighted_accuracy: 0.8910 - val_loss: 0.3056 - val_acc: 0.8709 - val_weighted_accuracy: 0.8457\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2165 - acc: 0.9075 - weighted_accuracy: 0.8905 - val_loss: 0.3151 - val_acc: 0.8660 - val_weighted_accuracy: 0.8346\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2150 - acc: 0.9090 - weighted_accuracy: 0.8922 - val_loss: 0.3097 - val_acc: 0.8698 - val_weighted_accuracy: 0.8490\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2139 - acc: 0.9094 - weighted_accuracy: 0.8929 - val_loss: 0.3012 - val_acc: 0.8700 - val_weighted_accuracy: 0.8483\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2135 - acc: 0.9092 - weighted_accuracy: 0.8931 - val_loss: 0.3065 - val_acc: 0.8698 - val_weighted_accuracy: 0.8445\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2123 - acc: 0.9101 - weighted_accuracy: 0.8939 - val_loss: 0.3082 - val_acc: 0.8693 - val_weighted_accuracy: 0.8488\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2116 - acc: 0.9108 - weighted_accuracy: 0.8947 - val_loss: 0.3157 - val_acc: 0.8680 - val_weighted_accuracy: 0.8356\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2109 - acc: 0.9109 - weighted_accuracy: 0.8949 - val_loss: 0.3053 - val_acc: 0.8692 - val_weighted_accuracy: 0.8423\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2086 - acc: 0.9119 - weighted_accuracy: 0.8956 - val_loss: 0.3090 - val_acc: 0.8673 - val_weighted_accuracy: 0.8408\n",
      "Epoch 37/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2092 - acc: 0.9118 - weighted_accuracy: 0.8957 - val_loss: 0.3072 - val_acc: 0.8669 - val_weighted_accuracy: 0.8445\n",
      "Epoch 38/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2080 - acc: 0.9123 - weighted_accuracy: 0.8967 - val_loss: 0.3149 - val_acc: 0.8685 - val_weighted_accuracy: 0.8420\n",
      "Epoch 39/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2077 - acc: 0.9123 - weighted_accuracy: 0.8959 - val_loss: 0.3044 - val_acc: 0.8707 - val_weighted_accuracy: 0.8481\n",
      "Epoch 40/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2060 - acc: 0.9129 - weighted_accuracy: 0.8974 - val_loss: 0.3086 - val_acc: 0.8695 - val_weighted_accuracy: 0.8438\n",
      "Epoch 41/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2057 - acc: 0.9133 - weighted_accuracy: 0.8975 - val_loss: 0.3069 - val_acc: 0.8697 - val_weighted_accuracy: 0.8443\n",
      "Epoch 42/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2061 - acc: 0.9133 - weighted_accuracy: 0.8976 - val_loss: 0.3154 - val_acc: 0.8697 - val_weighted_accuracy: 0.8416\n",
      "Epoch 43/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2042 - acc: 0.9139 - weighted_accuracy: 0.8986 - val_loss: 0.3185 - val_acc: 0.8677 - val_weighted_accuracy: 0.8403\n",
      "Epoch 44/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2029 - acc: 0.9151 - weighted_accuracy: 0.8995 - val_loss: 0.3186 - val_acc: 0.8679 - val_weighted_accuracy: 0.8421\n",
      "Epoch 45/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2034 - acc: 0.9142 - weighted_accuracy: 0.8990 - val_loss: 0.3116 - val_acc: 0.8674 - val_weighted_accuracy: 0.8420\n",
      "Epoch 46/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2025 - acc: 0.9151 - weighted_accuracy: 0.9001 - val_loss: 0.3167 - val_acc: 0.8659 - val_weighted_accuracy: 0.8402\n",
      "Epoch 47/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2025 - acc: 0.9150 - weighted_accuracy: 0.8998 - val_loss: 0.3150 - val_acc: 0.8687 - val_weighted_accuracy: 0.8438\n",
      "Epoch 48/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2020 - acc: 0.9153 - weighted_accuracy: 0.8998 - val_loss: 0.3156 - val_acc: 0.8659 - val_weighted_accuracy: 0.8392\n",
      "Epoch 49/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2012 - acc: 0.9152 - weighted_accuracy: 0.8999 - val_loss: 0.3150 - val_acc: 0.8682 - val_weighted_accuracy: 0.8408\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_exact_match (InputLayer)  (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_exact_match (InputLayer) (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 50, 1)        0           first_exact_match[0][0]          \n",
      "                                                                 second_exact_match[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 50, 151)      0           embedding_15[0][0]               \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 50, 151)      0           embedding_15[1][0]               \n",
      "                                                                 reshape_8[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 50, 151)      0           concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 50, 151)      0           concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 50, 64)       29056       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 50, 64)       0           conv1d_67[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 50, 64)       0           conv1d_67[1][0]                  \n",
      "                                                                 conv1d_70[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 50, 64)       4160        multiply_50[0][0]                \n",
      "                                                                 multiply_51[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 50, 64)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 50, 50)       0           dropout_29[0][0]                 \n",
      "                                                                 dropout_29[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 50, 50)       0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 50, 64)       0           permute_22[0][0]                 \n",
      "                                                                 dropout_29[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 50, 64)       0           lambda_50[0][0]                  \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 50, 279)      0           dropout_29[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 50, 279)      0           dropout_29[1][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 50, 64)       53632       concatenate_80[0][0]             \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 50, 64)       53632       concatenate_80[0][0]             \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 50, 64)       0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 50, 64)       0           conv1d_68[1][0]                  \n",
      "                                                                 conv1d_71[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 50, 64)       4160        multiply_52[0][0]                \n",
      "                                                                 multiply_53[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 50, 64)       0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 50, 50)       0           dropout_30[0][0]                 \n",
      "                                                                 dropout_30[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 50, 50)       0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 50, 64)       0           permute_23[0][0]                 \n",
      "                                                                 dropout_30[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 50, 64)       0           lambda_52[0][0]                  \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 50, 407)      0           dropout_30[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 50, 407)      0           dropout_30[1][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 50, 64)       78208       concatenate_82[0][0]             \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 50, 64)       78208       concatenate_82[0][0]             \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 50, 64)       0           conv1d_69[0][0]                  \n",
      "                                                                 conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 50, 64)       0           conv1d_69[1][0]                  \n",
      "                                                                 conv1d_72[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 50, 64)       4160        multiply_54[0][0]                \n",
      "                                                                 multiply_55[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 50, 64)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 50, 50)       0           dropout_31[0][0]                 \n",
      "                                                                 dropout_31[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 50, 50)       0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 50, 64)       0           permute_24[0][0]                 \n",
      "                                                                 dropout_31[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 50, 64)       0           lambda_54[0][0]                  \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 50, 535)      0           dropout_31[0][0]                 \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 50, 535)      0           dropout_31[1][0]                 \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 535)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 535)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_8 (A (None, 535)          535         concatenate_84[0][0]             \n",
      "                                                                 concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 535)          0           concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 535)          0           concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 1605)         0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "                                                                 attention_weighted_average_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 1605)         0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "                                                                 attention_weighted_average_8[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1605)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 1605)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 6420)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 multiply_56[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 6420)         0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6420)         25680       dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           410944      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            195         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,521,626\n",
      "Trainable params: 758,786\n",
      "Non-trainable params: 762,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 63s 225us/step - loss: 0.4110 - acc: 0.8116 - weighted_accuracy: 0.7838 - val_loss: 0.3382 - val_acc: 0.8397 - val_weighted_accuracy: 0.8160\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3278 - acc: 0.8501 - weighted_accuracy: 0.8250 - val_loss: 0.3208 - val_acc: 0.8526 - val_weighted_accuracy: 0.8312\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.3061 - acc: 0.8615 - weighted_accuracy: 0.8377 - val_loss: 0.3009 - val_acc: 0.8634 - val_weighted_accuracy: 0.8378\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2934 - acc: 0.8685 - weighted_accuracy: 0.8456 - val_loss: 0.2974 - val_acc: 0.8650 - val_weighted_accuracy: 0.8375\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2847 - acc: 0.8735 - weighted_accuracy: 0.8508 - val_loss: 0.2896 - val_acc: 0.8687 - val_weighted_accuracy: 0.8431\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2758 - acc: 0.8771 - weighted_accuracy: 0.8552 - val_loss: 0.2961 - val_acc: 0.8662 - val_weighted_accuracy: 0.8434\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2695 - acc: 0.8807 - weighted_accuracy: 0.8589 - val_loss: 0.2851 - val_acc: 0.8715 - val_weighted_accuracy: 0.8461\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2637 - acc: 0.8845 - weighted_accuracy: 0.8634 - val_loss: 0.2865 - val_acc: 0.8702 - val_weighted_accuracy: 0.8431\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2601 - acc: 0.8861 - weighted_accuracy: 0.8652 - val_loss: 0.2904 - val_acc: 0.8712 - val_weighted_accuracy: 0.8430\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2567 - acc: 0.8874 - weighted_accuracy: 0.8668 - val_loss: 0.2847 - val_acc: 0.8727 - val_weighted_accuracy: 0.8541\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2527 - acc: 0.8897 - weighted_accuracy: 0.8700 - val_loss: 0.2822 - val_acc: 0.8741 - val_weighted_accuracy: 0.8498\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2496 - acc: 0.8914 - weighted_accuracy: 0.8717 - val_loss: 0.2843 - val_acc: 0.8741 - val_weighted_accuracy: 0.8498\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2461 - acc: 0.8927 - weighted_accuracy: 0.8733 - val_loss: 0.2865 - val_acc: 0.8726 - val_weighted_accuracy: 0.8494\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2433 - acc: 0.8944 - weighted_accuracy: 0.8752 - val_loss: 0.2912 - val_acc: 0.8694 - val_weighted_accuracy: 0.8503\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2401 - acc: 0.8961 - weighted_accuracy: 0.8774 - val_loss: 0.2857 - val_acc: 0.8737 - val_weighted_accuracy: 0.8501\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2386 - acc: 0.8970 - weighted_accuracy: 0.8778 - val_loss: 0.2850 - val_acc: 0.8741 - val_weighted_accuracy: 0.8490\n",
      "Epoch 17/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2364 - acc: 0.8981 - weighted_accuracy: 0.8795 - val_loss: 0.2930 - val_acc: 0.8724 - val_weighted_accuracy: 0.8468\n",
      "Epoch 18/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2340 - acc: 0.8995 - weighted_accuracy: 0.8810 - val_loss: 0.2881 - val_acc: 0.8723 - val_weighted_accuracy: 0.8502\n",
      "Epoch 19/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2314 - acc: 0.9000 - weighted_accuracy: 0.8819 - val_loss: 0.2909 - val_acc: 0.8729 - val_weighted_accuracy: 0.8478\n",
      "Epoch 20/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2297 - acc: 0.9007 - weighted_accuracy: 0.8827 - val_loss: 0.2875 - val_acc: 0.8739 - val_weighted_accuracy: 0.8533\n",
      "Epoch 21/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2287 - acc: 0.9017 - weighted_accuracy: 0.8836 - val_loss: 0.2850 - val_acc: 0.8772 - val_weighted_accuracy: 0.8490\n",
      "Epoch 22/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2266 - acc: 0.9028 - weighted_accuracy: 0.8849 - val_loss: 0.2883 - val_acc: 0.8742 - val_weighted_accuracy: 0.8528\n",
      "Epoch 23/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2249 - acc: 0.9038 - weighted_accuracy: 0.8862 - val_loss: 0.2912 - val_acc: 0.8729 - val_weighted_accuracy: 0.8495\n",
      "Epoch 24/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2234 - acc: 0.9049 - weighted_accuracy: 0.8875 - val_loss: 0.2908 - val_acc: 0.8742 - val_weighted_accuracy: 0.8511\n",
      "Epoch 25/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2229 - acc: 0.9055 - weighted_accuracy: 0.8884 - val_loss: 0.2919 - val_acc: 0.8745 - val_weighted_accuracy: 0.8536\n",
      "Epoch 26/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2206 - acc: 0.9062 - weighted_accuracy: 0.8893 - val_loss: 0.2901 - val_acc: 0.8736 - val_weighted_accuracy: 0.8520\n",
      "Epoch 27/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2214 - acc: 0.9059 - weighted_accuracy: 0.8891 - val_loss: 0.2888 - val_acc: 0.8728 - val_weighted_accuracy: 0.8504\n",
      "Epoch 28/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2197 - acc: 0.9066 - weighted_accuracy: 0.8894 - val_loss: 0.2939 - val_acc: 0.8737 - val_weighted_accuracy: 0.8514\n",
      "Epoch 29/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2179 - acc: 0.9071 - weighted_accuracy: 0.8901 - val_loss: 0.2919 - val_acc: 0.8752 - val_weighted_accuracy: 0.8512\n",
      "Epoch 30/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2168 - acc: 0.9075 - weighted_accuracy: 0.8904 - val_loss: 0.2926 - val_acc: 0.8747 - val_weighted_accuracy: 0.8533\n",
      "Epoch 31/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2161 - acc: 0.9078 - weighted_accuracy: 0.8911 - val_loss: 0.2937 - val_acc: 0.8739 - val_weighted_accuracy: 0.8485\n",
      "Epoch 32/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2153 - acc: 0.9086 - weighted_accuracy: 0.8919 - val_loss: 0.2929 - val_acc: 0.8730 - val_weighted_accuracy: 0.8487\n",
      "Epoch 33/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2139 - acc: 0.9096 - weighted_accuracy: 0.8930 - val_loss: 0.2974 - val_acc: 0.8699 - val_weighted_accuracy: 0.8468\n",
      "Epoch 34/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2131 - acc: 0.9098 - weighted_accuracy: 0.8933 - val_loss: 0.2990 - val_acc: 0.8714 - val_weighted_accuracy: 0.8523\n",
      "Epoch 35/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2130 - acc: 0.9096 - weighted_accuracy: 0.8936 - val_loss: 0.2936 - val_acc: 0.8748 - val_weighted_accuracy: 0.8486\n",
      "Epoch 36/500\n",
      "280483/280483 [==============================] - 60s 215us/step - loss: 0.2113 - acc: 0.9107 - weighted_accuracy: 0.8942 - val_loss: 0.2949 - val_acc: 0.8749 - val_weighted_accuracy: 0.8509\n",
      "score 0.8096330878931333\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 82us/step\n",
      "80126/80126 [==============================] - 7s 83us/step\n",
      "80126/80126 [==============================] - 7s 82us/step\n",
      "80126/80126 [==============================] - 7s 83us/step\n",
      "80126/80126 [==============================] - 7s 82us/step\n",
      "80126/80126 [==============================] - 7s 81us/step\n",
      "80126/80126 [==============================] - 7s 81us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, augments=None, fold_count=fold_count, batch_size=1024,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=25)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/oofs/\"\n",
    "    output_dir = \"../data/output/\"\n",
    "    onehot_pred_dir = \"../data/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"3Embedding-3LayersDenseCNN42-NoDrop-NoClassWeighted-withEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2][:, -1],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_ESIM(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "\n",
    "    #input_encoded = BatchNormalization()(input_layer_3)\n",
    "    input_encoded = Dense(2016, activation='elu')(input_layer_3)\n",
    "    input_encoded = Dropout(0.25)(input_encoded)\n",
    "    \n",
    "    embedding = Embedding(nb_words, 150,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    " \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    #q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    #q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    batch_norm = BatchNormalization(axis=-1)\n",
    "    q1_embed = batch_norm(q1_embed)\n",
    "    q2_embed = batch_norm(q2_embed)\n",
    "    \n",
    "    aggreation_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    " \n",
    "    q1_seq = aggreation_gru(q1_embed)\n",
    "    q2_seq = aggreation_gru(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "    q1_vec = Concatenate()([q1_seq, q2_aligned, substract(q1_seq, q2_aligned), Multiply()([q1_seq, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_seq, q1_aligned, substract(q2_seq, q1_aligned), Multiply()([q2_seq, q1_aligned])])\n",
    "    \n",
    "    compare_gru = Bidirectional(CuDNNLSTM(72, return_sequences=True))\n",
    "    \n",
    "    q1_rep = compare_gru(q1_vec)\n",
    "    q2_rep = compare_gru(q2_vec)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5, amsgrad=True), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 50, 150)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 50, 150)      0           embedding_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, 150)      600         spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 50, 144)      129024      batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_12[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 50, 50)       0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 50, 50)       0           lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 50)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 50, 144)      0           permute_21[0][0]                 \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 50, 144)      0           lambda_51[0][0]                  \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 50, 144)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 50, 144)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 50, 576)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_63[0][0]                     \n",
      "                                                                 lambda_53[0][0]                  \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 50, 576)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_62[0][0]                     \n",
      "                                                                 lambda_54[0][0]                  \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 50, 144)      374400      concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 144)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 144)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 288)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 288)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 576)          0           concatenate_91[0][0]             \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 576)          2304        concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 256)          147712      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          65792       dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 3)            771         dropout_55[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 251s 894us/step - loss: 0.3533 - acc: 0.8434 - weighted_accuracy: 0.8143 - val_loss: 0.3416 - val_acc: 0.8421 - val_weighted_accuracy: 0.8225\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 220s 786us/step - loss: 0.2766 - acc: 0.8787 - weighted_accuracy: 0.8565 - val_loss: 0.2930 - val_acc: 0.8692 - val_weighted_accuracy: 0.8501\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 220s 785us/step - loss: 0.2533 - acc: 0.8909 - weighted_accuracy: 0.8705 - val_loss: 0.3151 - val_acc: 0.8620 - val_weighted_accuracy: 0.8483\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 218s 779us/step - loss: 0.2371 - acc: 0.8989 - weighted_accuracy: 0.8800 - val_loss: 0.3167 - val_acc: 0.8625 - val_weighted_accuracy: 0.8527\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 218s 779us/step - loss: 0.2245 - acc: 0.9048 - weighted_accuracy: 0.8865 - val_loss: 0.3254 - val_acc: 0.8571 - val_weighted_accuracy: 0.8449\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 235s 836us/step - loss: 0.2134 - acc: 0.9101 - weighted_accuracy: 0.8929 - val_loss: 0.3202 - val_acc: 0.8640 - val_weighted_accuracy: 0.8506\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 245s 873us/step - loss: 0.2032 - acc: 0.9148 - weighted_accuracy: 0.8987 - val_loss: 0.3185 - val_acc: 0.8663 - val_weighted_accuracy: 0.8522\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 230s 821us/step - loss: 0.1931 - acc: 0.9189 - weighted_accuracy: 0.9037 - val_loss: 0.3306 - val_acc: 0.8590 - val_weighted_accuracy: 0.8469\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 218s 778us/step - loss: 0.1856 - acc: 0.9222 - weighted_accuracy: 0.9077 - val_loss: 0.3352 - val_acc: 0.8637 - val_weighted_accuracy: 0.8527\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 218s 778us/step - loss: 0.1775 - acc: 0.9255 - weighted_accuracy: 0.9115 - val_loss: 0.3276 - val_acc: 0.8678 - val_weighted_accuracy: 0.8499\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 219s 780us/step - loss: 0.1725 - acc: 0.9284 - weighted_accuracy: 0.9154 - val_loss: 0.3359 - val_acc: 0.8649 - val_weighted_accuracy: 0.8490\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.1643 - acc: 0.9314 - weighted_accuracy: 0.9189 - val_loss: 0.3464 - val_acc: 0.8642 - val_weighted_accuracy: 0.8462\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 50, 150)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 50, 150)      0           embedding_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 50, 150)      600         spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 50, 144)      129024      batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_16[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 50, 50)       0           bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 50, 50)       0           lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50, 50)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 50, 144)      0           permute_22[0][0]                 \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 50, 144)      0           lambda_55[0][0]                  \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 50, 144)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 50, 144)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 50, 576)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 lambda_57[0][0]                  \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 50, 576)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 lambda_58[0][0]                  \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 50, 144)      374400      concatenate_94[0][0]             \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 144)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 144)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 288)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 288)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 576)          0           concatenate_96[0][0]             \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 576)          2304        concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 256)          147712      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256)          1024        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 256)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 256)          65792       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 3)            771         dropout_58[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 251s 896us/step - loss: 0.3591 - acc: 0.8409 - weighted_accuracy: 0.8119 - val_loss: 0.3082 - val_acc: 0.8619 - val_weighted_accuracy: 0.8438\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 234s 833us/step - loss: 0.2801 - acc: 0.8770 - weighted_accuracy: 0.8548 - val_loss: 0.2799 - val_acc: 0.8766 - val_weighted_accuracy: 0.8581\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 219s 782us/step - loss: 0.2561 - acc: 0.8893 - weighted_accuracy: 0.8685 - val_loss: 0.2781 - val_acc: 0.8786 - val_weighted_accuracy: 0.8580\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 220s 783us/step - loss: 0.2389 - acc: 0.8972 - weighted_accuracy: 0.8778 - val_loss: 0.2722 - val_acc: 0.8817 - val_weighted_accuracy: 0.8652\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 219s 780us/step - loss: 0.2270 - acc: 0.9035 - weighted_accuracy: 0.8851 - val_loss: 0.2776 - val_acc: 0.8799 - val_weighted_accuracy: 0.8621\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 220s 784us/step - loss: 0.2156 - acc: 0.9090 - weighted_accuracy: 0.8918 - val_loss: 0.2762 - val_acc: 0.8824 - val_weighted_accuracy: 0.8623\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 244s 871us/step - loss: 0.2056 - acc: 0.9136 - weighted_accuracy: 0.8970 - val_loss: 0.2741 - val_acc: 0.8813 - val_weighted_accuracy: 0.8645\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 245s 874us/step - loss: 0.1968 - acc: 0.9177 - weighted_accuracy: 0.9023 - val_loss: 0.2799 - val_acc: 0.8810 - val_weighted_accuracy: 0.8607\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 222s 792us/step - loss: 0.1883 - acc: 0.9217 - weighted_accuracy: 0.9070 - val_loss: 0.2987 - val_acc: 0.8780 - val_weighted_accuracy: 0.8625\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 220s 784us/step - loss: 0.1805 - acc: 0.9242 - weighted_accuracy: 0.9101 - val_loss: 0.2914 - val_acc: 0.8826 - val_weighted_accuracy: 0.8641\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 219s 782us/step - loss: 0.1740 - acc: 0.9273 - weighted_accuracy: 0.9139 - val_loss: 0.2949 - val_acc: 0.8805 - val_weighted_accuracy: 0.8651\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 219s 781us/step - loss: 0.1666 - acc: 0.9304 - weighted_accuracy: 0.9175 - val_loss: 0.3045 - val_acc: 0.8802 - val_weighted_accuracy: 0.8637\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 233s 832us/step - loss: 0.1609 - acc: 0.9330 - weighted_accuracy: 0.9207 - val_loss: 0.3072 - val_acc: 0.8807 - val_weighted_accuracy: 0.8645\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 245s 872us/step - loss: 0.1555 - acc: 0.9357 - weighted_accuracy: 0.9240 - val_loss: 0.3016 - val_acc: 0.8806 - val_weighted_accuracy: 0.8669\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 50, 150)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 50, 150)      0           embedding_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 150)      600         spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 50, 144)      129024      batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_20[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 50, 50)       0           bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 50, 50)       0           lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50, 50)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 50, 144)      0           permute_23[0][0]                 \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 50, 144)      0           lambda_59[0][0]                  \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 50, 144)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 50, 144)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 50, 576)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 lambda_61[0][0]                  \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 50, 576)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 lambda_62[0][0]                  \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 50, 144)      374400      concatenate_99[0][0]             \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 144)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 144)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 288)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 288)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 576)          0           concatenate_101[0][0]            \n",
      "                                                                 concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 576)          2304        concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 256)          147712      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 256)          65792       dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 3)            771         dropout_61[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 253s 903us/step - loss: 0.3538 - acc: 0.8438 - weighted_accuracy: 0.8142 - val_loss: 0.3376 - val_acc: 0.8444 - val_weighted_accuracy: 0.8347\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 229s 815us/step - loss: 0.2761 - acc: 0.8787 - weighted_accuracy: 0.8559 - val_loss: 0.3302 - val_acc: 0.8460 - val_weighted_accuracy: 0.8331\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 232s 825us/step - loss: 0.2531 - acc: 0.8906 - weighted_accuracy: 0.8693 - val_loss: 0.2969 - val_acc: 0.8683 - val_weighted_accuracy: 0.8522\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 231s 823us/step - loss: 0.2380 - acc: 0.8983 - weighted_accuracy: 0.8785 - val_loss: 0.2997 - val_acc: 0.8673 - val_weighted_accuracy: 0.8548\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 244s 869us/step - loss: 0.2246 - acc: 0.9046 - weighted_accuracy: 0.8862 - val_loss: 0.3088 - val_acc: 0.8678 - val_weighted_accuracy: 0.8519\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 255s 909us/step - loss: 0.2145 - acc: 0.9096 - weighted_accuracy: 0.8922 - val_loss: 0.3015 - val_acc: 0.8696 - val_weighted_accuracy: 0.8538\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 239s 851us/step - loss: 0.2044 - acc: 0.9142 - weighted_accuracy: 0.8973 - val_loss: 0.3174 - val_acc: 0.8663 - val_weighted_accuracy: 0.8534\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 226s 804us/step - loss: 0.1953 - acc: 0.9185 - weighted_accuracy: 0.9023 - val_loss: 0.3189 - val_acc: 0.8660 - val_weighted_accuracy: 0.8544\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.1886 - acc: 0.9212 - weighted_accuracy: 0.9059 - val_loss: 0.3236 - val_acc: 0.8643 - val_weighted_accuracy: 0.8491\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 229s 817us/step - loss: 0.1809 - acc: 0.9248 - weighted_accuracy: 0.9104 - val_loss: 0.3253 - val_acc: 0.8695 - val_weighted_accuracy: 0.8560\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 228s 812us/step - loss: 0.1740 - acc: 0.9271 - weighted_accuracy: 0.9134 - val_loss: 0.3270 - val_acc: 0.8662 - val_weighted_accuracy: 0.8522\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 250s 891us/step - loss: 0.1675 - acc: 0.9305 - weighted_accuracy: 0.9175 - val_loss: 0.3285 - val_acc: 0.8642 - val_weighted_accuracy: 0.8502\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 246s 876us/step - loss: 0.1613 - acc: 0.9332 - weighted_accuracy: 0.9206 - val_loss: 0.3455 - val_acc: 0.8657 - val_weighted_accuracy: 0.8513\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 50, 150)      0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 50, 150)      0           embedding_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 50, 150)      600         spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 50, 144)      129024      batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_24[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 50, 50)       0           bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 50, 50)       0           lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 50, 50)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 50, 144)      0           permute_24[0][0]                 \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 50, 144)      0           lambda_63[0][0]                  \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 50, 144)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 50, 144)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 50, 576)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 lambda_65[0][0]                  \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 50, 576)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 lambda_66[0][0]                  \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 50, 144)      374400      concatenate_104[0][0]            \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 144)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 144)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 288)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 288)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 576)          0           concatenate_106[0][0]            \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 576)          2304        concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 256)          147712      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 256)          65792       dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 3)            771         dropout_64[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 230s 820us/step - loss: 0.3545 - acc: 0.8431 - weighted_accuracy: 0.8134 - val_loss: 0.3102 - val_acc: 0.8575 - val_weighted_accuracy: 0.8371\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 224s 798us/step - loss: 0.2760 - acc: 0.8789 - weighted_accuracy: 0.8562 - val_loss: 0.2983 - val_acc: 0.8642 - val_weighted_accuracy: 0.8503\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.2534 - acc: 0.8907 - weighted_accuracy: 0.8699 - val_loss: 0.2934 - val_acc: 0.8686 - val_weighted_accuracy: 0.8579\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 224s 797us/step - loss: 0.2377 - acc: 0.8986 - weighted_accuracy: 0.8791 - val_loss: 0.3054 - val_acc: 0.8635 - val_weighted_accuracy: 0.8561\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 250s 891us/step - loss: 0.2258 - acc: 0.9042 - weighted_accuracy: 0.8857 - val_loss: 0.2937 - val_acc: 0.8712 - val_weighted_accuracy: 0.8501\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 249s 887us/step - loss: 0.2143 - acc: 0.9097 - weighted_accuracy: 0.8922 - val_loss: 0.2880 - val_acc: 0.8723 - val_weighted_accuracy: 0.8584\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 223s 793us/step - loss: 0.2056 - acc: 0.9141 - weighted_accuracy: 0.8974 - val_loss: 0.3125 - val_acc: 0.8669 - val_weighted_accuracy: 0.8557\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.1971 - acc: 0.9179 - weighted_accuracy: 0.9020 - val_loss: 0.3080 - val_acc: 0.8674 - val_weighted_accuracy: 0.8548\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 222s 793us/step - loss: 0.1888 - acc: 0.9214 - weighted_accuracy: 0.9060 - val_loss: 0.3078 - val_acc: 0.8686 - val_weighted_accuracy: 0.8530\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 224s 799us/step - loss: 0.1814 - acc: 0.9244 - weighted_accuracy: 0.9100 - val_loss: 0.3139 - val_acc: 0.8690 - val_weighted_accuracy: 0.8505\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 240s 855us/step - loss: 0.1751 - acc: 0.9268 - weighted_accuracy: 0.9130 - val_loss: 0.3178 - val_acc: 0.8688 - val_weighted_accuracy: 0.8546\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 259s 922us/step - loss: 0.1683 - acc: 0.9296 - weighted_accuracy: 0.9166 - val_loss: 0.3196 - val_acc: 0.8700 - val_weighted_accuracy: 0.8489\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 253s 901us/step - loss: 0.1621 - acc: 0.9327 - weighted_accuracy: 0.9202 - val_loss: 0.3239 - val_acc: 0.8677 - val_weighted_accuracy: 0.8523\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 226s 805us/step - loss: 0.1563 - acc: 0.9351 - weighted_accuracy: 0.9229 - val_loss: 0.3344 - val_acc: 0.8678 - val_weighted_accuracy: 0.8506\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 222s 792us/step - loss: 0.1508 - acc: 0.9378 - weighted_accuracy: 0.9262 - val_loss: 0.3477 - val_acc: 0.8649 - val_weighted_accuracy: 0.8471\n",
      "Epoch 16/500\n",
      "280483/280483 [==============================] - 222s 792us/step - loss: 0.1459 - acc: 0.9394 - weighted_accuracy: 0.9282 - val_loss: 0.3594 - val_acc: 0.8649 - val_weighted_accuracy: 0.8482\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 50, 150)      0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 50, 150)      0           embedding_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 50, 150)      600         spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 50, 144)      129024      batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_28[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 50, 50)       0           bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 50, 50)       0           lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 50, 50)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 50, 144)      0           permute_25[0][0]                 \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 50, 144)      0           lambda_67[0][0]                  \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 50, 144)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 50, 144)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 50, 576)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 lambda_69[0][0]                  \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 50, 576)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 lambda_70[0][0]                  \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 50, 144)      374400      concatenate_109[0][0]            \n",
      "                                                                 concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 144)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 144)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 288)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 288)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 576)          0           concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 576)          2304        concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 256)          147712      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256)          1024        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 256)          0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 256)          65792       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256)          1024        dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 256)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 3)            771         dropout_67[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 238s 849us/step - loss: 0.3518 - acc: 0.8446 - weighted_accuracy: 0.8151 - val_loss: 0.3146 - val_acc: 0.8557 - val_weighted_accuracy: 0.8377\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 250s 893us/step - loss: 0.2738 - acc: 0.8799 - weighted_accuracy: 0.8567 - val_loss: 0.3123 - val_acc: 0.8621 - val_weighted_accuracy: 0.8425\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 241s 859us/step - loss: 0.2518 - acc: 0.8921 - weighted_accuracy: 0.8709 - val_loss: 0.3104 - val_acc: 0.8624 - val_weighted_accuracy: 0.8505\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 247s 880us/step - loss: 0.2350 - acc: 0.8997 - weighted_accuracy: 0.8803 - val_loss: 0.3070 - val_acc: 0.8630 - val_weighted_accuracy: 0.8480\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 251s 894us/step - loss: 0.2227 - acc: 0.9057 - weighted_accuracy: 0.8876 - val_loss: 0.3144 - val_acc: 0.8622 - val_weighted_accuracy: 0.8488\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 229s 817us/step - loss: 0.2127 - acc: 0.9105 - weighted_accuracy: 0.8931 - val_loss: 0.3105 - val_acc: 0.8657 - val_weighted_accuracy: 0.8447\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 226s 805us/step - loss: 0.2033 - acc: 0.9144 - weighted_accuracy: 0.8975 - val_loss: 0.3219 - val_acc: 0.8599 - val_weighted_accuracy: 0.8462\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 224s 799us/step - loss: 0.1928 - acc: 0.9197 - weighted_accuracy: 0.9038 - val_loss: 0.3334 - val_acc: 0.8583 - val_weighted_accuracy: 0.8432\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 225s 803us/step - loss: 0.1864 - acc: 0.9225 - weighted_accuracy: 0.9076 - val_loss: 0.3282 - val_acc: 0.8587 - val_weighted_accuracy: 0.8448\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 235s 836us/step - loss: 0.1781 - acc: 0.9261 - weighted_accuracy: 0.9116 - val_loss: 0.3360 - val_acc: 0.8573 - val_weighted_accuracy: 0.8458\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 249s 887us/step - loss: 0.1711 - acc: 0.9288 - weighted_accuracy: 0.9149 - val_loss: 0.3325 - val_acc: 0.8611 - val_weighted_accuracy: 0.8433\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 248s 885us/step - loss: 0.1646 - acc: 0.9319 - weighted_accuracy: 0.9187 - val_loss: 0.3530 - val_acc: 0.8563 - val_weighted_accuracy: 0.8384\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 224s 800us/step - loss: 0.1578 - acc: 0.9344 - weighted_accuracy: 0.9221 - val_loss: 0.3620 - val_acc: 0.8594 - val_weighted_accuracy: 0.8401\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 220s 786us/step - loss: 0.1525 - acc: 0.9370 - weighted_accuracy: 0.9248 - val_loss: 0.3579 - val_acc: 0.8616 - val_weighted_accuracy: 0.8439\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 50, 150)      0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 50, 150)      0           embedding_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 50, 150)      600         spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 50, 144)      129024      batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_32[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 50, 50)       0           bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 50, 50)       0           lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 50, 50)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 50, 144)      0           permute_26[0][0]                 \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 50, 144)      0           lambda_71[0][0]                  \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 50, 144)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 50, 144)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 50, 576)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 lambda_73[0][0]                  \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 50, 576)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 lambda_74[0][0]                  \n",
      "                                                                 multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 50, 144)      374400      concatenate_114[0][0]            \n",
      "                                                                 concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 144)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 144)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 288)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 288)          0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 576)          0           concatenate_116[0][0]            \n",
      "                                                                 concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 576)          2304        concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 256)          147712      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256)          1024        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 256)          0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          65792       dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 256)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 3)            771         dropout_70[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.3520 - acc: 0.8444 - weighted_accuracy: 0.8156 - val_loss: 0.3368 - val_acc: 0.8457 - val_weighted_accuracy: 0.8130\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 220s 783us/step - loss: 0.2737 - acc: 0.8805 - weighted_accuracy: 0.8582 - val_loss: 0.3194 - val_acc: 0.8528 - val_weighted_accuracy: 0.8239\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 246s 878us/step - loss: 0.2513 - acc: 0.8923 - weighted_accuracy: 0.8716 - val_loss: 0.3269 - val_acc: 0.8529 - val_weighted_accuracy: 0.8212\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 241s 858us/step - loss: 0.2350 - acc: 0.8994 - weighted_accuracy: 0.8802 - val_loss: 0.3165 - val_acc: 0.8584 - val_weighted_accuracy: 0.8358\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.2222 - acc: 0.9059 - weighted_accuracy: 0.8878 - val_loss: 0.3306 - val_acc: 0.8535 - val_weighted_accuracy: 0.8236\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.2122 - acc: 0.9101 - weighted_accuracy: 0.8930 - val_loss: 0.3281 - val_acc: 0.8555 - val_weighted_accuracy: 0.8313\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.2024 - acc: 0.9146 - weighted_accuracy: 0.8986 - val_loss: 0.3353 - val_acc: 0.8554 - val_weighted_accuracy: 0.8265\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.1930 - acc: 0.9190 - weighted_accuracy: 0.9038 - val_loss: 0.3483 - val_acc: 0.8528 - val_weighted_accuracy: 0.8268\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 242s 864us/step - loss: 0.1859 - acc: 0.9220 - weighted_accuracy: 0.9075 - val_loss: 0.3408 - val_acc: 0.8513 - val_weighted_accuracy: 0.8225\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 247s 882us/step - loss: 0.1775 - acc: 0.9263 - weighted_accuracy: 0.9127 - val_loss: 0.3534 - val_acc: 0.8551 - val_weighted_accuracy: 0.8322\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 229s 817us/step - loss: 0.1707 - acc: 0.9291 - weighted_accuracy: 0.9160 - val_loss: 0.3606 - val_acc: 0.8547 - val_weighted_accuracy: 0.8315\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 222s 793us/step - loss: 0.1636 - acc: 0.9323 - weighted_accuracy: 0.9196 - val_loss: 0.3625 - val_acc: 0.8552 - val_weighted_accuracy: 0.8317\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 222s 793us/step - loss: 0.1581 - acc: 0.9345 - weighted_accuracy: 0.9224 - val_loss: 0.3688 - val_acc: 0.8567 - val_weighted_accuracy: 0.8391\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 223s 793us/step - loss: 0.1519 - acc: 0.9371 - weighted_accuracy: 0.9257 - val_loss: 0.3870 - val_acc: 0.8534 - val_weighted_accuracy: 0.8331\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 50, 150)      0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 50, 150)      0           embedding_31[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 50, 150)      600         spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 50, 144)      129024      batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_36[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 50, 50)       0           bidirectional_17[0][0]           \n",
      "                                                                 bidirectional_17[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 50, 50)       0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 50, 50)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 50, 144)      0           permute_27[0][0]                 \n",
      "                                                                 bidirectional_17[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 50, 144)      0           lambda_75[0][0]                  \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 50, 144)      0           bidirectional_17[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 50, 144)      0           bidirectional_17[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 50, 144)      0           bidirectional_17[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 50, 144)      0           bidirectional_17[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 50, 576)      0           bidirectional_17[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 lambda_77[0][0]                  \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 50, 576)      0           bidirectional_17[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 lambda_78[0][0]                  \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 50, 144)      374400      concatenate_119[0][0]            \n",
      "                                                                 concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 144)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 144)          0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 144)          0           bidirectional_18[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 144)          0           bidirectional_18[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 288)          0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 288)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 576)          0           concatenate_121[0][0]            \n",
      "                                                                 concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 576)          2304        concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 256)          147712      batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 256)          1024        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 256)          0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          65792       dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 256)          1024        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 256)          0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 3)            771         dropout_73[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 247s 881us/step - loss: 0.3536 - acc: 0.8436 - weighted_accuracy: 0.8141 - val_loss: 0.3051 - val_acc: 0.8626 - val_weighted_accuracy: 0.8504\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 247s 880us/step - loss: 0.2759 - acc: 0.8791 - weighted_accuracy: 0.8563 - val_loss: 0.2915 - val_acc: 0.8681 - val_weighted_accuracy: 0.8413\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 231s 823us/step - loss: 0.2538 - acc: 0.8908 - weighted_accuracy: 0.8700 - val_loss: 0.2859 - val_acc: 0.8722 - val_weighted_accuracy: 0.8571\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.2372 - acc: 0.8986 - weighted_accuracy: 0.8790 - val_loss: 0.3022 - val_acc: 0.8709 - val_weighted_accuracy: 0.8520\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.2254 - acc: 0.9044 - weighted_accuracy: 0.8863 - val_loss: 0.2982 - val_acc: 0.8740 - val_weighted_accuracy: 0.8597\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.2143 - acc: 0.9092 - weighted_accuracy: 0.8925 - val_loss: 0.2909 - val_acc: 0.8747 - val_weighted_accuracy: 0.8596\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 231s 823us/step - loss: 0.2041 - acc: 0.9138 - weighted_accuracy: 0.8974 - val_loss: 0.2992 - val_acc: 0.8759 - val_weighted_accuracy: 0.8592\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 247s 880us/step - loss: 0.1952 - acc: 0.9183 - weighted_accuracy: 0.9028 - val_loss: 0.2965 - val_acc: 0.8737 - val_weighted_accuracy: 0.8585\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 241s 859us/step - loss: 0.1876 - acc: 0.9216 - weighted_accuracy: 0.9072 - val_loss: 0.3058 - val_acc: 0.8743 - val_weighted_accuracy: 0.8610\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.1791 - acc: 0.9250 - weighted_accuracy: 0.9108 - val_loss: 0.3275 - val_acc: 0.8663 - val_weighted_accuracy: 0.8515\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 223s 797us/step - loss: 0.1725 - acc: 0.9282 - weighted_accuracy: 0.9148 - val_loss: 0.3074 - val_acc: 0.8739 - val_weighted_accuracy: 0.8603\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.1654 - acc: 0.9312 - weighted_accuracy: 0.9183 - val_loss: 0.3198 - val_acc: 0.8726 - val_weighted_accuracy: 0.8596\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.1597 - acc: 0.9332 - weighted_accuracy: 0.9208 - val_loss: 0.3196 - val_acc: 0.8719 - val_weighted_accuracy: 0.8580\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 50, 150)      750000      first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 50, 150)      0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 50, 150)      0           embedding_33[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 150)      600         spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 50, 144)      129024      batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_40[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 50, 50)       0           bidirectional_19[0][0]           \n",
      "                                                                 bidirectional_19[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 50, 50)       0           lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 50, 50)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 50, 144)      0           permute_28[0][0]                 \n",
      "                                                                 bidirectional_19[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 50, 144)      0           lambda_79[0][0]                  \n",
      "                                                                 bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 50, 144)      0           bidirectional_19[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 50, 144)      0           bidirectional_19[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 50, 144)      0           bidirectional_19[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 50, 144)      0           bidirectional_19[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 50, 576)      0           bidirectional_19[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 lambda_81[0][0]                  \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 50, 576)      0           bidirectional_19[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 lambda_82[0][0]                  \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 50, 144)      374400      concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 144)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 144)          0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 144)          0           bidirectional_20[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 144)          0           bidirectional_20[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 288)          0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 288)          0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 576)          0           concatenate_126[0][0]            \n",
      "                                                                 concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 576)          2304        concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 256)          147712      batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 256)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 256)          65792       dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 256)          1024        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 256)          0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 3)            771         dropout_76[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,472,651\n",
      "Trainable params: 720,175\n",
      "Non-trainable params: 752,476\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280483 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "280483/280483 [==============================] - 256s 914us/step - loss: 0.3555 - acc: 0.8428 - weighted_accuracy: 0.8137 - val_loss: 0.3123 - val_acc: 0.8631 - val_weighted_accuracy: 0.8400\n",
      "Epoch 2/500\n",
      "280483/280483 [==============================] - 240s 856us/step - loss: 0.2769 - acc: 0.8788 - weighted_accuracy: 0.8567 - val_loss: 0.2823 - val_acc: 0.8714 - val_weighted_accuracy: 0.8486\n",
      "Epoch 3/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.2532 - acc: 0.8913 - weighted_accuracy: 0.8711 - val_loss: 0.2858 - val_acc: 0.8751 - val_weighted_accuracy: 0.8569\n",
      "Epoch 4/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.2373 - acc: 0.8990 - weighted_accuracy: 0.8804 - val_loss: 0.2815 - val_acc: 0.8748 - val_weighted_accuracy: 0.8592\n",
      "Epoch 5/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.2250 - acc: 0.9050 - weighted_accuracy: 0.8876 - val_loss: 0.2775 - val_acc: 0.8779 - val_weighted_accuracy: 0.8575\n",
      "Epoch 6/500\n",
      "280483/280483 [==============================] - 223s 796us/step - loss: 0.2140 - acc: 0.9104 - weighted_accuracy: 0.8940 - val_loss: 0.2878 - val_acc: 0.8738 - val_weighted_accuracy: 0.8569\n",
      "Epoch 7/500\n",
      "280483/280483 [==============================] - 244s 871us/step - loss: 0.2039 - acc: 0.9147 - weighted_accuracy: 0.8991 - val_loss: 0.2784 - val_acc: 0.8788 - val_weighted_accuracy: 0.8592\n",
      "Epoch 8/500\n",
      "280483/280483 [==============================] - 247s 880us/step - loss: 0.1948 - acc: 0.9186 - weighted_accuracy: 0.9034 - val_loss: 0.2849 - val_acc: 0.8784 - val_weighted_accuracy: 0.8600\n",
      "Epoch 9/500\n",
      "280483/280483 [==============================] - 226s 804us/step - loss: 0.1869 - acc: 0.9227 - weighted_accuracy: 0.9084 - val_loss: 0.2992 - val_acc: 0.8770 - val_weighted_accuracy: 0.8590\n",
      "Epoch 10/500\n",
      "280483/280483 [==============================] - 223s 794us/step - loss: 0.1795 - acc: 0.9249 - weighted_accuracy: 0.9114 - val_loss: 0.2946 - val_acc: 0.8800 - val_weighted_accuracy: 0.8603\n",
      "Epoch 11/500\n",
      "280483/280483 [==============================] - 223s 795us/step - loss: 0.1726 - acc: 0.9280 - weighted_accuracy: 0.9152 - val_loss: 0.3039 - val_acc: 0.8789 - val_weighted_accuracy: 0.8576\n",
      "Epoch 12/500\n",
      "280483/280483 [==============================] - 223s 797us/step - loss: 0.1658 - acc: 0.9312 - weighted_accuracy: 0.9186 - val_loss: 0.3033 - val_acc: 0.8767 - val_weighted_accuracy: 0.8575\n",
      "Epoch 13/500\n",
      "280483/280483 [==============================] - 235s 839us/step - loss: 0.1598 - acc: 0.9342 - weighted_accuracy: 0.9224 - val_loss: 0.3135 - val_acc: 0.8758 - val_weighted_accuracy: 0.8594\n",
      "Epoch 14/500\n",
      "280483/280483 [==============================] - 247s 881us/step - loss: 0.1529 - acc: 0.9364 - weighted_accuracy: 0.9250 - val_loss: 0.3189 - val_acc: 0.8744 - val_weighted_accuracy: 0.8627\n",
      "Epoch 15/500\n",
      "280483/280483 [==============================] - 235s 840us/step - loss: 0.1481 - acc: 0.9390 - weighted_accuracy: 0.9281 - val_loss: 0.3138 - val_acc: 0.8763 - val_weighted_accuracy: 0.8594\n",
      "score 0.8335650071958037\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 23s 283us/step\n",
      "80126/80126 [==============================] - 23s 282us/step\n",
      "80126/80126 [==============================] - 23s 288us/step\n",
      "80126/80126 [==============================] - 24s 294us/step\n",
      "80126/80126 [==============================] - 24s 294us/step\n",
      "80126/80126 [==============================] - 23s 292us/step\n",
      "80126/80126 [==============================] - 23s 289us/step\n",
      "80126/80126 [==============================] - 24s 295us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix=meta_embeddings\n",
    "\n",
    "for i in range(4, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_ESIM(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, augments=None, fold_count=fold_count, batch_size=128,\n",
    "        em_train_features=em_train_features,\n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/oofs/\"\n",
    "    output_dir = \"../data/output/\"\n",
    "    onehot_pred_dir = \"../data/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"3Embedding-ESIM-Drop01-NoMeta-NoClassWeighted-NoEM\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": em_test_features[0],\n",
    "                                       \"second_exact_match\": em_test_features[1],\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub = sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
